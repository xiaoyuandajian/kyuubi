// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: spark/connect/relations.proto

package org.apache.kyuubi.engine.spark.connect.proto;

/**
 * <pre>
 * Relation of type [[Join]].
 *
 * `left` and `right` must be present.
 * </pre>
 *
 * Protobuf type {@code spark.connect.Join}
 */
public final class Join extends
    com.google.protobuf.GeneratedMessageV3 implements
    // @@protoc_insertion_point(message_implements:spark.connect.Join)
    JoinOrBuilder {
private static final long serialVersionUID = 0L;
  // Use Join.newBuilder() to construct.
  private Join(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
    super(builder);
  }
  private Join() {
    joinType_ = 0;
    usingColumns_ =
        com.google.protobuf.LazyStringArrayList.emptyList();
  }

  @Override
  @SuppressWarnings({"unused"})
  protected Object newInstance(
      UnusedPrivateParameter unused) {
    return new Join();
  }

  public static final com.google.protobuf.Descriptors.Descriptor
      getDescriptor() {
    return org.apache.spark.connect.proto.Relations.internal_static_spark_connect_Join_descriptor;
  }

  @Override
  protected FieldAccessorTable
      internalGetFieldAccessorTable() {
    return org.apache.spark.connect.proto.Relations.internal_static_spark_connect_Join_fieldAccessorTable
        .ensureFieldAccessorsInitialized(
            org.apache.spark.connect.proto.Join.class, org.apache.spark.connect.proto.Join.Builder.class);
  }

  /**
   * Protobuf enum {@code spark.connect.Join.JoinType}
   */
  public enum JoinType
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>JOIN_TYPE_UNSPECIFIED = 0;</code>
     */
    JOIN_TYPE_UNSPECIFIED(0),
    /**
     * <code>JOIN_TYPE_INNER = 1;</code>
     */
    JOIN_TYPE_INNER(1),
    /**
     * <code>JOIN_TYPE_FULL_OUTER = 2;</code>
     */
    JOIN_TYPE_FULL_OUTER(2),
    /**
     * <code>JOIN_TYPE_LEFT_OUTER = 3;</code>
     */
    JOIN_TYPE_LEFT_OUTER(3),
    /**
     * <code>JOIN_TYPE_RIGHT_OUTER = 4;</code>
     */
    JOIN_TYPE_RIGHT_OUTER(4),
    /**
     * <code>JOIN_TYPE_LEFT_ANTI = 5;</code>
     */
    JOIN_TYPE_LEFT_ANTI(5),
    /**
     * <code>JOIN_TYPE_LEFT_SEMI = 6;</code>
     */
    JOIN_TYPE_LEFT_SEMI(6),
    /**
     * <code>JOIN_TYPE_CROSS = 7;</code>
     */
    JOIN_TYPE_CROSS(7),
    UNRECOGNIZED(-1),
    ;

    /**
     * <code>JOIN_TYPE_UNSPECIFIED = 0;</code>
     */
    public static final int JOIN_TYPE_UNSPECIFIED_VALUE = 0;
    /**
     * <code>JOIN_TYPE_INNER = 1;</code>
     */
    public static final int JOIN_TYPE_INNER_VALUE = 1;
    /**
     * <code>JOIN_TYPE_FULL_OUTER = 2;</code>
     */
    public static final int JOIN_TYPE_FULL_OUTER_VALUE = 2;
    /**
     * <code>JOIN_TYPE_LEFT_OUTER = 3;</code>
     */
    public static final int JOIN_TYPE_LEFT_OUTER_VALUE = 3;
    /**
     * <code>JOIN_TYPE_RIGHT_OUTER = 4;</code>
     */
    public static final int JOIN_TYPE_RIGHT_OUTER_VALUE = 4;
    /**
     * <code>JOIN_TYPE_LEFT_ANTI = 5;</code>
     */
    public static final int JOIN_TYPE_LEFT_ANTI_VALUE = 5;
    /**
     * <code>JOIN_TYPE_LEFT_SEMI = 6;</code>
     */
    public static final int JOIN_TYPE_LEFT_SEMI_VALUE = 6;
    /**
     * <code>JOIN_TYPE_CROSS = 7;</code>
     */
    public static final int JOIN_TYPE_CROSS_VALUE = 7;


    public final int getNumber() {
      if (this == UNRECOGNIZED) {
        throw new IllegalArgumentException(
            "Can't get the number of an unknown enum value.");
      }
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @Deprecated
    public static JoinType valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static JoinType forNumber(int value) {
      switch (value) {
        case 0: return JOIN_TYPE_UNSPECIFIED;
        case 1: return JOIN_TYPE_INNER;
        case 2: return JOIN_TYPE_FULL_OUTER;
        case 3: return JOIN_TYPE_LEFT_OUTER;
        case 4: return JOIN_TYPE_RIGHT_OUTER;
        case 5: return JOIN_TYPE_LEFT_ANTI;
        case 6: return JOIN_TYPE_LEFT_SEMI;
        case 7: return JOIN_TYPE_CROSS;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<JoinType>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        JoinType> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<JoinType>() {
            public JoinType findValueByNumber(int number) {
              return JoinType.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      if (this == UNRECOGNIZED) {
        throw new IllegalStateException(
            "Can't get the descriptor of an unrecognized enum value.");
      }
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.spark.connect.proto.Join.getDescriptor().getEnumTypes().get(0);
    }

    private static final JoinType[] VALUES = values();

    public static JoinType valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      if (desc.getIndex() == -1) {
        return UNRECOGNIZED;
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private JoinType(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:spark.connect.Join.JoinType)
  }

  public interface JoinDataTypeOrBuilder extends
      // @@protoc_insertion_point(interface_extends:spark.connect.Join.JoinDataType)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * If the left data type is a struct.
     * </pre>
     *
     * <code>bool is_left_struct = 1;</code>
     * @return The isLeftStruct.
     */
    boolean getIsLeftStruct();

    /**
     * <pre>
     * If the right data type is a struct.
     * </pre>
     *
     * <code>bool is_right_struct = 2;</code>
     * @return The isRightStruct.
     */
    boolean getIsRightStruct();
  }
  /**
   * Protobuf type {@code spark.connect.Join.JoinDataType}
   */
  public static final class JoinDataType extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:spark.connect.Join.JoinDataType)
      JoinDataTypeOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use JoinDataType.newBuilder() to construct.
    private JoinDataType(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private JoinDataType() {
    }

    @Override
    @SuppressWarnings({"unused"})
    protected Object newInstance(
        UnusedPrivateParameter unused) {
      return new JoinDataType();
    }

    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.spark.connect.proto.Relations.internal_static_spark_connect_Join_JoinDataType_descriptor;
    }

    @Override
    protected FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.spark.connect.proto.Relations.internal_static_spark_connect_Join_JoinDataType_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.spark.connect.proto.Join.JoinDataType.class, org.apache.spark.connect.proto.Join.JoinDataType.Builder.class);
    }

    public static final int IS_LEFT_STRUCT_FIELD_NUMBER = 1;
    private boolean isLeftStruct_ = false;
    /**
     * <pre>
     * If the left data type is a struct.
     * </pre>
     *
     * <code>bool is_left_struct = 1;</code>
     * @return The isLeftStruct.
     */
    @Override
    public boolean getIsLeftStruct() {
      return isLeftStruct_;
    }

    public static final int IS_RIGHT_STRUCT_FIELD_NUMBER = 2;
    private boolean isRightStruct_ = false;
    /**
     * <pre>
     * If the right data type is a struct.
     * </pre>
     *
     * <code>bool is_right_struct = 2;</code>
     * @return The isRightStruct.
     */
    @Override
    public boolean getIsRightStruct() {
      return isRightStruct_;
    }

    private byte memoizedIsInitialized = -1;
    @Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (isLeftStruct_ != false) {
        output.writeBool(1, isLeftStruct_);
      }
      if (isRightStruct_ != false) {
        output.writeBool(2, isRightStruct_);
      }
      getUnknownFields().writeTo(output);
    }

    @Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (isLeftStruct_ != false) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(1, isLeftStruct_);
      }
      if (isRightStruct_ != false) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(2, isRightStruct_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @Override
    public boolean equals(final Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.spark.connect.proto.Join.JoinDataType)) {
        return super.equals(obj);
      }
      org.apache.spark.connect.proto.Join.JoinDataType other = (org.apache.spark.connect.proto.Join.JoinDataType) obj;

      if (getIsLeftStruct()
          != other.getIsLeftStruct()) return false;
      if (getIsRightStruct()
          != other.getIsRightStruct()) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + IS_LEFT_STRUCT_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
          getIsLeftStruct());
      hash = (37 * hash) + IS_RIGHT_STRUCT_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
          getIsRightStruct());
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.spark.connect.proto.Join.JoinDataType parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.connect.proto.Join.JoinDataType parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.connect.proto.Join.JoinDataType parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.connect.proto.Join.JoinDataType parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.connect.proto.Join.JoinDataType parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.connect.proto.Join.JoinDataType parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.connect.proto.Join.JoinDataType parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.spark.connect.proto.Join.JoinDataType parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.spark.connect.proto.Join.JoinDataType parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.spark.connect.proto.Join.JoinDataType parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.spark.connect.proto.Join.JoinDataType parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.spark.connect.proto.Join.JoinDataType parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.spark.connect.proto.Join.JoinDataType prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @Override
    protected Builder newBuilderForType(
        BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code spark.connect.Join.JoinDataType}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:spark.connect.Join.JoinDataType)
        org.apache.spark.connect.proto.Join.JoinDataTypeOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.spark.connect.proto.Relations.internal_static_spark_connect_Join_JoinDataType_descriptor;
      }

      @Override
      protected FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.spark.connect.proto.Relations.internal_static_spark_connect_Join_JoinDataType_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.spark.connect.proto.Join.JoinDataType.class, org.apache.spark.connect.proto.Join.JoinDataType.Builder.class);
      }

      // Construct using org.apache.spark.connect.proto.Join.JoinDataType.newBuilder()
      private Builder() {

      }

      private Builder(
          BuilderParent parent) {
        super(parent);

      }
      @Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        isLeftStruct_ = false;
        isRightStruct_ = false;
        return this;
      }

      @Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.spark.connect.proto.Relations.internal_static_spark_connect_Join_JoinDataType_descriptor;
      }

      @Override
      public org.apache.spark.connect.proto.Join.JoinDataType getDefaultInstanceForType() {
        return org.apache.spark.connect.proto.Join.JoinDataType.getDefaultInstance();
      }

      @Override
      public org.apache.spark.connect.proto.Join.JoinDataType build() {
        org.apache.spark.connect.proto.Join.JoinDataType result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @Override
      public org.apache.spark.connect.proto.Join.JoinDataType buildPartial() {
        org.apache.spark.connect.proto.Join.JoinDataType result = new org.apache.spark.connect.proto.Join.JoinDataType(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.spark.connect.proto.Join.JoinDataType result) {
        int from_bitField0_ = bitField0_;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.isLeftStruct_ = isLeftStruct_;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.isRightStruct_ = isRightStruct_;
        }
      }

      @Override
      public Builder clone() {
        return super.clone();
      }
      @Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return super.setField(field, value);
      }
      @Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return super.addRepeatedField(field, value);
      }
      @Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.spark.connect.proto.Join.JoinDataType) {
          return mergeFrom((org.apache.spark.connect.proto.Join.JoinDataType)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.spark.connect.proto.Join.JoinDataType other) {
        if (other == org.apache.spark.connect.proto.Join.JoinDataType.getDefaultInstance()) return this;
        if (other.getIsLeftStruct() != false) {
          setIsLeftStruct(other.getIsLeftStruct());
        }
        if (other.getIsRightStruct() != false) {
          setIsRightStruct(other.getIsRightStruct());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @Override
      public final boolean isInitialized() {
        return true;
      }

      @Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8: {
                isLeftStruct_ = input.readBool();
                bitField0_ |= 0x00000001;
                break;
              } // case 8
              case 16: {
                isRightStruct_ = input.readBool();
                bitField0_ |= 0x00000002;
                break;
              } // case 16
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private boolean isLeftStruct_ ;
      /**
       * <pre>
       * If the left data type is a struct.
       * </pre>
       *
       * <code>bool is_left_struct = 1;</code>
       * @return The isLeftStruct.
       */
      @Override
      public boolean getIsLeftStruct() {
        return isLeftStruct_;
      }
      /**
       * <pre>
       * If the left data type is a struct.
       * </pre>
       *
       * <code>bool is_left_struct = 1;</code>
       * @param value The isLeftStruct to set.
       * @return This builder for chaining.
       */
      public Builder setIsLeftStruct(boolean value) {

        isLeftStruct_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * If the left data type is a struct.
       * </pre>
       *
       * <code>bool is_left_struct = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearIsLeftStruct() {
        bitField0_ = (bitField0_ & ~0x00000001);
        isLeftStruct_ = false;
        onChanged();
        return this;
      }

      private boolean isRightStruct_ ;
      /**
       * <pre>
       * If the right data type is a struct.
       * </pre>
       *
       * <code>bool is_right_struct = 2;</code>
       * @return The isRightStruct.
       */
      @Override
      public boolean getIsRightStruct() {
        return isRightStruct_;
      }
      /**
       * <pre>
       * If the right data type is a struct.
       * </pre>
       *
       * <code>bool is_right_struct = 2;</code>
       * @param value The isRightStruct to set.
       * @return This builder for chaining.
       */
      public Builder setIsRightStruct(boolean value) {

        isRightStruct_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * If the right data type is a struct.
       * </pre>
       *
       * <code>bool is_right_struct = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearIsRightStruct() {
        bitField0_ = (bitField0_ & ~0x00000002);
        isRightStruct_ = false;
        onChanged();
        return this;
      }
      @Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:spark.connect.Join.JoinDataType)
    }

    // @@protoc_insertion_point(class_scope:spark.connect.Join.JoinDataType)
    private static final org.apache.spark.connect.proto.Join.JoinDataType DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.spark.connect.proto.Join.JoinDataType();
    }

    public static org.apache.spark.connect.proto.Join.JoinDataType getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<JoinDataType>
        PARSER = new com.google.protobuf.AbstractParser<JoinDataType>() {
      @Override
      public JoinDataType parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<JoinDataType> parser() {
      return PARSER;
    }

    @Override
    public com.google.protobuf.Parser<JoinDataType> getParserForType() {
      return PARSER;
    }

    @Override
    public org.apache.spark.connect.proto.Join.JoinDataType getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  private int bitField0_;
  public static final int LEFT_FIELD_NUMBER = 1;
  private org.apache.spark.connect.proto.Relation left_;
  /**
   * <pre>
   * (Required) Left input relation for a Join.
   * </pre>
   *
   * <code>.spark.connect.Relation left = 1;</code>
   * @return Whether the left field is set.
   */
  @Override
  public boolean hasLeft() {
    return left_ != null;
  }
  /**
   * <pre>
   * (Required) Left input relation for a Join.
   * </pre>
   *
   * <code>.spark.connect.Relation left = 1;</code>
   * @return The left.
   */
  @Override
  public org.apache.spark.connect.proto.Relation getLeft() {
    return left_ == null ? org.apache.spark.connect.proto.Relation.getDefaultInstance() : left_;
  }
  /**
   * <pre>
   * (Required) Left input relation for a Join.
   * </pre>
   *
   * <code>.spark.connect.Relation left = 1;</code>
   */
  @Override
  public org.apache.spark.connect.proto.RelationOrBuilder getLeftOrBuilder() {
    return left_ == null ? org.apache.spark.connect.proto.Relation.getDefaultInstance() : left_;
  }

  public static final int RIGHT_FIELD_NUMBER = 2;
  private org.apache.spark.connect.proto.Relation right_;
  /**
   * <pre>
   * (Required) Right input relation for a Join.
   * </pre>
   *
   * <code>.spark.connect.Relation right = 2;</code>
   * @return Whether the right field is set.
   */
  @Override
  public boolean hasRight() {
    return right_ != null;
  }
  /**
   * <pre>
   * (Required) Right input relation for a Join.
   * </pre>
   *
   * <code>.spark.connect.Relation right = 2;</code>
   * @return The right.
   */
  @Override
  public org.apache.spark.connect.proto.Relation getRight() {
    return right_ == null ? org.apache.spark.connect.proto.Relation.getDefaultInstance() : right_;
  }
  /**
   * <pre>
   * (Required) Right input relation for a Join.
   * </pre>
   *
   * <code>.spark.connect.Relation right = 2;</code>
   */
  @Override
  public org.apache.spark.connect.proto.RelationOrBuilder getRightOrBuilder() {
    return right_ == null ? org.apache.spark.connect.proto.Relation.getDefaultInstance() : right_;
  }

  public static final int JOIN_CONDITION_FIELD_NUMBER = 3;
  private org.apache.spark.connect.proto.Expression joinCondition_;
  /**
   * <pre>
   * (Optional) The join condition. Could be unset when `using_columns` is utilized.
   *
   * This field does not co-exist with using_columns.
   * </pre>
   *
   * <code>.spark.connect.Expression join_condition = 3;</code>
   * @return Whether the joinCondition field is set.
   */
  @Override
  public boolean hasJoinCondition() {
    return joinCondition_ != null;
  }
  /**
   * <pre>
   * (Optional) The join condition. Could be unset when `using_columns` is utilized.
   *
   * This field does not co-exist with using_columns.
   * </pre>
   *
   * <code>.spark.connect.Expression join_condition = 3;</code>
   * @return The joinCondition.
   */
  @Override
  public org.apache.spark.connect.proto.Expression getJoinCondition() {
    return joinCondition_ == null ? org.apache.spark.connect.proto.Expression.getDefaultInstance() : joinCondition_;
  }
  /**
   * <pre>
   * (Optional) The join condition. Could be unset when `using_columns` is utilized.
   *
   * This field does not co-exist with using_columns.
   * </pre>
   *
   * <code>.spark.connect.Expression join_condition = 3;</code>
   */
  @Override
  public org.apache.spark.connect.proto.ExpressionOrBuilder getJoinConditionOrBuilder() {
    return joinCondition_ == null ? org.apache.spark.connect.proto.Expression.getDefaultInstance() : joinCondition_;
  }

  public static final int JOIN_TYPE_FIELD_NUMBER = 4;
  private int joinType_ = 0;
  /**
   * <pre>
   * (Required) The join type.
   * </pre>
   *
   * <code>.spark.connect.Join.JoinType join_type = 4;</code>
   * @return The enum numeric value on the wire for joinType.
   */
  @Override public int getJoinTypeValue() {
    return joinType_;
  }
  /**
   * <pre>
   * (Required) The join type.
   * </pre>
   *
   * <code>.spark.connect.Join.JoinType join_type = 4;</code>
   * @return The joinType.
   */
  @Override public org.apache.spark.connect.proto.Join.JoinType getJoinType() {
    org.apache.spark.connect.proto.Join.JoinType result = org.apache.spark.connect.proto.Join.JoinType.forNumber(joinType_);
    return result == null ? org.apache.spark.connect.proto.Join.JoinType.UNRECOGNIZED : result;
  }

  public static final int USING_COLUMNS_FIELD_NUMBER = 5;
  @SuppressWarnings("serial")
  private com.google.protobuf.LazyStringArrayList usingColumns_ =
      com.google.protobuf.LazyStringArrayList.emptyList();
  /**
   * <pre>
   * Optional. using_columns provides a list of columns that should present on both sides of
   * the join inputs that this Join will join on. For example A JOIN B USING col_name is
   * equivalent to A JOIN B on A.col_name = B.col_name.
   *
   * This field does not co-exist with join_condition.
   * </pre>
   *
   * <code>repeated string using_columns = 5;</code>
   * @return A list containing the usingColumns.
   */
  public com.google.protobuf.ProtocolStringList
      getUsingColumnsList() {
    return usingColumns_;
  }
  /**
   * <pre>
   * Optional. using_columns provides a list of columns that should present on both sides of
   * the join inputs that this Join will join on. For example A JOIN B USING col_name is
   * equivalent to A JOIN B on A.col_name = B.col_name.
   *
   * This field does not co-exist with join_condition.
   * </pre>
   *
   * <code>repeated string using_columns = 5;</code>
   * @return The count of usingColumns.
   */
  public int getUsingColumnsCount() {
    return usingColumns_.size();
  }
  /**
   * <pre>
   * Optional. using_columns provides a list of columns that should present on both sides of
   * the join inputs that this Join will join on. For example A JOIN B USING col_name is
   * equivalent to A JOIN B on A.col_name = B.col_name.
   *
   * This field does not co-exist with join_condition.
   * </pre>
   *
   * <code>repeated string using_columns = 5;</code>
   * @param index The index of the element to return.
   * @return The usingColumns at the given index.
   */
  public String getUsingColumns(int index) {
    return usingColumns_.get(index);
  }
  /**
   * <pre>
   * Optional. using_columns provides a list of columns that should present on both sides of
   * the join inputs that this Join will join on. For example A JOIN B USING col_name is
   * equivalent to A JOIN B on A.col_name = B.col_name.
   *
   * This field does not co-exist with join_condition.
   * </pre>
   *
   * <code>repeated string using_columns = 5;</code>
   * @param index The index of the value to return.
   * @return The bytes of the usingColumns at the given index.
   */
  public com.google.protobuf.ByteString
      getUsingColumnsBytes(int index) {
    return usingColumns_.getByteString(index);
  }

  public static final int JOIN_DATA_TYPE_FIELD_NUMBER = 6;
  private org.apache.spark.connect.proto.Join.JoinDataType joinDataType_;
  /**
   * <pre>
   * (Optional) Only used by joinWith. Set the left and right join data types.
   * </pre>
   *
   * <code>optional .spark.connect.Join.JoinDataType join_data_type = 6;</code>
   * @return Whether the joinDataType field is set.
   */
  @Override
  public boolean hasJoinDataType() {
    return ((bitField0_ & 0x00000001) != 0);
  }
  /**
   * <pre>
   * (Optional) Only used by joinWith. Set the left and right join data types.
   * </pre>
   *
   * <code>optional .spark.connect.Join.JoinDataType join_data_type = 6;</code>
   * @return The joinDataType.
   */
  @Override
  public org.apache.spark.connect.proto.Join.JoinDataType getJoinDataType() {
    return joinDataType_ == null ? org.apache.spark.connect.proto.Join.JoinDataType.getDefaultInstance() : joinDataType_;
  }
  /**
   * <pre>
   * (Optional) Only used by joinWith. Set the left and right join data types.
   * </pre>
   *
   * <code>optional .spark.connect.Join.JoinDataType join_data_type = 6;</code>
   */
  @Override
  public org.apache.spark.connect.proto.Join.JoinDataTypeOrBuilder getJoinDataTypeOrBuilder() {
    return joinDataType_ == null ? org.apache.spark.connect.proto.Join.JoinDataType.getDefaultInstance() : joinDataType_;
  }

  private byte memoizedIsInitialized = -1;
  @Override
  public final boolean isInitialized() {
    byte isInitialized = memoizedIsInitialized;
    if (isInitialized == 1) return true;
    if (isInitialized == 0) return false;

    memoizedIsInitialized = 1;
    return true;
  }

  @Override
  public void writeTo(com.google.protobuf.CodedOutputStream output)
                      throws java.io.IOException {
    if (left_ != null) {
      output.writeMessage(1, getLeft());
    }
    if (right_ != null) {
      output.writeMessage(2, getRight());
    }
    if (joinCondition_ != null) {
      output.writeMessage(3, getJoinCondition());
    }
    if (joinType_ != org.apache.spark.connect.proto.Join.JoinType.JOIN_TYPE_UNSPECIFIED.getNumber()) {
      output.writeEnum(4, joinType_);
    }
    for (int i = 0; i < usingColumns_.size(); i++) {
      com.google.protobuf.GeneratedMessageV3.writeString(output, 5, usingColumns_.getRaw(i));
    }
    if (((bitField0_ & 0x00000001) != 0)) {
      output.writeMessage(6, getJoinDataType());
    }
    getUnknownFields().writeTo(output);
  }

  @Override
  public int getSerializedSize() {
    int size = memoizedSize;
    if (size != -1) return size;

    size = 0;
    if (left_ != null) {
      size += com.google.protobuf.CodedOutputStream
        .computeMessageSize(1, getLeft());
    }
    if (right_ != null) {
      size += com.google.protobuf.CodedOutputStream
        .computeMessageSize(2, getRight());
    }
    if (joinCondition_ != null) {
      size += com.google.protobuf.CodedOutputStream
        .computeMessageSize(3, getJoinCondition());
    }
    if (joinType_ != org.apache.spark.connect.proto.Join.JoinType.JOIN_TYPE_UNSPECIFIED.getNumber()) {
      size += com.google.protobuf.CodedOutputStream
        .computeEnumSize(4, joinType_);
    }
    {
      int dataSize = 0;
      for (int i = 0; i < usingColumns_.size(); i++) {
        dataSize += computeStringSizeNoTag(usingColumns_.getRaw(i));
      }
      size += dataSize;
      size += 1 * getUsingColumnsList().size();
    }
    if (((bitField0_ & 0x00000001) != 0)) {
      size += com.google.protobuf.CodedOutputStream
        .computeMessageSize(6, getJoinDataType());
    }
    size += getUnknownFields().getSerializedSize();
    memoizedSize = size;
    return size;
  }

  @Override
  public boolean equals(final Object obj) {
    if (obj == this) {
     return true;
    }
    if (!(obj instanceof org.apache.spark.connect.proto.Join)) {
      return super.equals(obj);
    }
    org.apache.spark.connect.proto.Join other = (org.apache.spark.connect.proto.Join) obj;

    if (hasLeft() != other.hasLeft()) return false;
    if (hasLeft()) {
      if (!getLeft()
          .equals(other.getLeft())) return false;
    }
    if (hasRight() != other.hasRight()) return false;
    if (hasRight()) {
      if (!getRight()
          .equals(other.getRight())) return false;
    }
    if (hasJoinCondition() != other.hasJoinCondition()) return false;
    if (hasJoinCondition()) {
      if (!getJoinCondition()
          .equals(other.getJoinCondition())) return false;
    }
    if (joinType_ != other.joinType_) return false;
    if (!getUsingColumnsList()
        .equals(other.getUsingColumnsList())) return false;
    if (hasJoinDataType() != other.hasJoinDataType()) return false;
    if (hasJoinDataType()) {
      if (!getJoinDataType()
          .equals(other.getJoinDataType())) return false;
    }
    if (!getUnknownFields().equals(other.getUnknownFields())) return false;
    return true;
  }

  @Override
  public int hashCode() {
    if (memoizedHashCode != 0) {
      return memoizedHashCode;
    }
    int hash = 41;
    hash = (19 * hash) + getDescriptor().hashCode();
    if (hasLeft()) {
      hash = (37 * hash) + LEFT_FIELD_NUMBER;
      hash = (53 * hash) + getLeft().hashCode();
    }
    if (hasRight()) {
      hash = (37 * hash) + RIGHT_FIELD_NUMBER;
      hash = (53 * hash) + getRight().hashCode();
    }
    if (hasJoinCondition()) {
      hash = (37 * hash) + JOIN_CONDITION_FIELD_NUMBER;
      hash = (53 * hash) + getJoinCondition().hashCode();
    }
    hash = (37 * hash) + JOIN_TYPE_FIELD_NUMBER;
    hash = (53 * hash) + joinType_;
    if (getUsingColumnsCount() > 0) {
      hash = (37 * hash) + USING_COLUMNS_FIELD_NUMBER;
      hash = (53 * hash) + getUsingColumnsList().hashCode();
    }
    if (hasJoinDataType()) {
      hash = (37 * hash) + JOIN_DATA_TYPE_FIELD_NUMBER;
      hash = (53 * hash) + getJoinDataType().hashCode();
    }
    hash = (29 * hash) + getUnknownFields().hashCode();
    memoizedHashCode = hash;
    return hash;
  }

  public static org.apache.spark.connect.proto.Join parseFrom(
      java.nio.ByteBuffer data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }
  public static org.apache.spark.connect.proto.Join parseFrom(
      java.nio.ByteBuffer data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }
  public static org.apache.spark.connect.proto.Join parseFrom(
      com.google.protobuf.ByteString data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }
  public static org.apache.spark.connect.proto.Join parseFrom(
      com.google.protobuf.ByteString data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }
  public static org.apache.spark.connect.proto.Join parseFrom(byte[] data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }
  public static org.apache.spark.connect.proto.Join parseFrom(
      byte[] data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }
  public static org.apache.spark.connect.proto.Join parseFrom(java.io.InputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input);
  }
  public static org.apache.spark.connect.proto.Join parseFrom(
      java.io.InputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input, extensionRegistry);
  }

  public static org.apache.spark.connect.proto.Join parseDelimitedFrom(java.io.InputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseDelimitedWithIOException(PARSER, input);
  }

  public static org.apache.spark.connect.proto.Join parseDelimitedFrom(
      java.io.InputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
  }
  public static org.apache.spark.connect.proto.Join parseFrom(
      com.google.protobuf.CodedInputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input);
  }
  public static org.apache.spark.connect.proto.Join parseFrom(
      com.google.protobuf.CodedInputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input, extensionRegistry);
  }

  @Override
  public Builder newBuilderForType() { return newBuilder(); }
  public static Builder newBuilder() {
    return DEFAULT_INSTANCE.toBuilder();
  }
  public static Builder newBuilder(org.apache.spark.connect.proto.Join prototype) {
    return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
  }
  @Override
  public Builder toBuilder() {
    return this == DEFAULT_INSTANCE
        ? new Builder() : new Builder().mergeFrom(this);
  }

  @Override
  protected Builder newBuilderForType(
      BuilderParent parent) {
    Builder builder = new Builder(parent);
    return builder;
  }
  /**
   * <pre>
   * Relation of type [[Join]].
   *
   * `left` and `right` must be present.
   * </pre>
   *
   * Protobuf type {@code spark.connect.Join}
   */
  public static final class Builder extends
      com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
      // @@protoc_insertion_point(builder_implements:spark.connect.Join)
      org.apache.spark.connect.proto.JoinOrBuilder {
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.spark.connect.proto.Relations.internal_static_spark_connect_Join_descriptor;
    }

    @Override
    protected FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.spark.connect.proto.Relations.internal_static_spark_connect_Join_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.spark.connect.proto.Join.class, org.apache.spark.connect.proto.Join.Builder.class);
    }

    // Construct using org.apache.spark.connect.proto.Join.newBuilder()
    private Builder() {
      maybeForceBuilderInitialization();
    }

    private Builder(
        BuilderParent parent) {
      super(parent);
      maybeForceBuilderInitialization();
    }
    private void maybeForceBuilderInitialization() {
      if (com.google.protobuf.GeneratedMessageV3
              .alwaysUseFieldBuilders) {
        getLeftFieldBuilder();
        getRightFieldBuilder();
        getJoinConditionFieldBuilder();
        getJoinDataTypeFieldBuilder();
      }
    }
    @Override
    public Builder clear() {
      super.clear();
      bitField0_ = 0;
      left_ = null;
      if (leftBuilder_ != null) {
        leftBuilder_.dispose();
        leftBuilder_ = null;
      }
      right_ = null;
      if (rightBuilder_ != null) {
        rightBuilder_.dispose();
        rightBuilder_ = null;
      }
      joinCondition_ = null;
      if (joinConditionBuilder_ != null) {
        joinConditionBuilder_.dispose();
        joinConditionBuilder_ = null;
      }
      joinType_ = 0;
      usingColumns_ =
          com.google.protobuf.LazyStringArrayList.emptyList();
      joinDataType_ = null;
      if (joinDataTypeBuilder_ != null) {
        joinDataTypeBuilder_.dispose();
        joinDataTypeBuilder_ = null;
      }
      return this;
    }

    @Override
    public com.google.protobuf.Descriptors.Descriptor
        getDescriptorForType() {
      return org.apache.spark.connect.proto.Relations.internal_static_spark_connect_Join_descriptor;
    }

    @Override
    public org.apache.spark.connect.proto.Join getDefaultInstanceForType() {
      return org.apache.spark.connect.proto.Join.getDefaultInstance();
    }

    @Override
    public org.apache.spark.connect.proto.Join build() {
      org.apache.spark.connect.proto.Join result = buildPartial();
      if (!result.isInitialized()) {
        throw newUninitializedMessageException(result);
      }
      return result;
    }

    @Override
    public org.apache.spark.connect.proto.Join buildPartial() {
      org.apache.spark.connect.proto.Join result = new org.apache.spark.connect.proto.Join(this);
      if (bitField0_ != 0) { buildPartial0(result); }
      onBuilt();
      return result;
    }

    private void buildPartial0(org.apache.spark.connect.proto.Join result) {
      int from_bitField0_ = bitField0_;
      if (((from_bitField0_ & 0x00000001) != 0)) {
        result.left_ = leftBuilder_ == null
            ? left_
            : leftBuilder_.build();
      }
      if (((from_bitField0_ & 0x00000002) != 0)) {
        result.right_ = rightBuilder_ == null
            ? right_
            : rightBuilder_.build();
      }
      if (((from_bitField0_ & 0x00000004) != 0)) {
        result.joinCondition_ = joinConditionBuilder_ == null
            ? joinCondition_
            : joinConditionBuilder_.build();
      }
      if (((from_bitField0_ & 0x00000008) != 0)) {
        result.joinType_ = joinType_;
      }
      if (((from_bitField0_ & 0x00000010) != 0)) {
        usingColumns_.makeImmutable();
        result.usingColumns_ = usingColumns_;
      }
      int to_bitField0_ = 0;
      if (((from_bitField0_ & 0x00000020) != 0)) {
        result.joinDataType_ = joinDataTypeBuilder_ == null
            ? joinDataType_
            : joinDataTypeBuilder_.build();
        to_bitField0_ |= 0x00000001;
      }
      result.bitField0_ |= to_bitField0_;
    }

    @Override
    public Builder clone() {
      return super.clone();
    }
    @Override
    public Builder setField(
        com.google.protobuf.Descriptors.FieldDescriptor field,
        Object value) {
      return super.setField(field, value);
    }
    @Override
    public Builder clearField(
        com.google.protobuf.Descriptors.FieldDescriptor field) {
      return super.clearField(field);
    }
    @Override
    public Builder clearOneof(
        com.google.protobuf.Descriptors.OneofDescriptor oneof) {
      return super.clearOneof(oneof);
    }
    @Override
    public Builder setRepeatedField(
        com.google.protobuf.Descriptors.FieldDescriptor field,
        int index, Object value) {
      return super.setRepeatedField(field, index, value);
    }
    @Override
    public Builder addRepeatedField(
        com.google.protobuf.Descriptors.FieldDescriptor field,
        Object value) {
      return super.addRepeatedField(field, value);
    }
    @Override
    public Builder mergeFrom(com.google.protobuf.Message other) {
      if (other instanceof org.apache.spark.connect.proto.Join) {
        return mergeFrom((org.apache.spark.connect.proto.Join)other);
      } else {
        super.mergeFrom(other);
        return this;
      }
    }

    public Builder mergeFrom(org.apache.spark.connect.proto.Join other) {
      if (other == org.apache.spark.connect.proto.Join.getDefaultInstance()) return this;
      if (other.hasLeft()) {
        mergeLeft(other.getLeft());
      }
      if (other.hasRight()) {
        mergeRight(other.getRight());
      }
      if (other.hasJoinCondition()) {
        mergeJoinCondition(other.getJoinCondition());
      }
      if (other.joinType_ != 0) {
        setJoinTypeValue(other.getJoinTypeValue());
      }
      if (!other.usingColumns_.isEmpty()) {
        if (usingColumns_.isEmpty()) {
          usingColumns_ = other.usingColumns_;
          bitField0_ |= 0x00000010;
        } else {
          ensureUsingColumnsIsMutable();
          usingColumns_.addAll(other.usingColumns_);
        }
        onChanged();
      }
      if (other.hasJoinDataType()) {
        mergeJoinDataType(other.getJoinDataType());
      }
      this.mergeUnknownFields(other.getUnknownFields());
      onChanged();
      return this;
    }

    @Override
    public final boolean isInitialized() {
      return true;
    }

    @Override
    public Builder mergeFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      if (extensionRegistry == null) {
        throw new NullPointerException();
      }
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              input.readMessage(
                  getLeftFieldBuilder().getBuilder(),
                  extensionRegistry);
              bitField0_ |= 0x00000001;
              break;
            } // case 10
            case 18: {
              input.readMessage(
                  getRightFieldBuilder().getBuilder(),
                  extensionRegistry);
              bitField0_ |= 0x00000002;
              break;
            } // case 18
            case 26: {
              input.readMessage(
                  getJoinConditionFieldBuilder().getBuilder(),
                  extensionRegistry);
              bitField0_ |= 0x00000004;
              break;
            } // case 26
            case 32: {
              joinType_ = input.readEnum();
              bitField0_ |= 0x00000008;
              break;
            } // case 32
            case 42: {
              String s = input.readStringRequireUtf8();
              ensureUsingColumnsIsMutable();
              usingColumns_.add(s);
              break;
            } // case 42
            case 50: {
              input.readMessage(
                  getJoinDataTypeFieldBuilder().getBuilder(),
                  extensionRegistry);
              bitField0_ |= 0x00000020;
              break;
            } // case 50
            default: {
              if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                done = true; // was an endgroup tag
              }
              break;
            } // default:
          } // switch (tag)
        } // while (!done)
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.unwrapIOException();
      } finally {
        onChanged();
      } // finally
      return this;
    }
    private int bitField0_;

    private org.apache.spark.connect.proto.Relation left_;
    private com.google.protobuf.SingleFieldBuilderV3<
        org.apache.spark.connect.proto.Relation, org.apache.spark.connect.proto.Relation.Builder, org.apache.spark.connect.proto.RelationOrBuilder> leftBuilder_;
    /**
     * <pre>
     * (Required) Left input relation for a Join.
     * </pre>
     *
     * <code>.spark.connect.Relation left = 1;</code>
     * @return Whether the left field is set.
     */
    public boolean hasLeft() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <pre>
     * (Required) Left input relation for a Join.
     * </pre>
     *
     * <code>.spark.connect.Relation left = 1;</code>
     * @return The left.
     */
    public org.apache.spark.connect.proto.Relation getLeft() {
      if (leftBuilder_ == null) {
        return left_ == null ? org.apache.spark.connect.proto.Relation.getDefaultInstance() : left_;
      } else {
        return leftBuilder_.getMessage();
      }
    }
    /**
     * <pre>
     * (Required) Left input relation for a Join.
     * </pre>
     *
     * <code>.spark.connect.Relation left = 1;</code>
     */
    public Builder setLeft(org.apache.spark.connect.proto.Relation value) {
      if (leftBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        left_ = value;
      } else {
        leftBuilder_.setMessage(value);
      }
      bitField0_ |= 0x00000001;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * (Required) Left input relation for a Join.
     * </pre>
     *
     * <code>.spark.connect.Relation left = 1;</code>
     */
    public Builder setLeft(
        org.apache.spark.connect.proto.Relation.Builder builderForValue) {
      if (leftBuilder_ == null) {
        left_ = builderForValue.build();
      } else {
        leftBuilder_.setMessage(builderForValue.build());
      }
      bitField0_ |= 0x00000001;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * (Required) Left input relation for a Join.
     * </pre>
     *
     * <code>.spark.connect.Relation left = 1;</code>
     */
    public Builder mergeLeft(org.apache.spark.connect.proto.Relation value) {
      if (leftBuilder_ == null) {
        if (((bitField0_ & 0x00000001) != 0) &&
          left_ != null &&
          left_ != org.apache.spark.connect.proto.Relation.getDefaultInstance()) {
          getLeftBuilder().mergeFrom(value);
        } else {
          left_ = value;
        }
      } else {
        leftBuilder_.mergeFrom(value);
      }
      bitField0_ |= 0x00000001;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * (Required) Left input relation for a Join.
     * </pre>
     *
     * <code>.spark.connect.Relation left = 1;</code>
     */
    public Builder clearLeft() {
      bitField0_ = (bitField0_ & ~0x00000001);
      left_ = null;
      if (leftBuilder_ != null) {
        leftBuilder_.dispose();
        leftBuilder_ = null;
      }
      onChanged();
      return this;
    }
    /**
     * <pre>
     * (Required) Left input relation for a Join.
     * </pre>
     *
     * <code>.spark.connect.Relation left = 1;</code>
     */
    public org.apache.spark.connect.proto.Relation.Builder getLeftBuilder() {
      bitField0_ |= 0x00000001;
      onChanged();
      return getLeftFieldBuilder().getBuilder();
    }
    /**
     * <pre>
     * (Required) Left input relation for a Join.
     * </pre>
     *
     * <code>.spark.connect.Relation left = 1;</code>
     */
    public org.apache.spark.connect.proto.RelationOrBuilder getLeftOrBuilder() {
      if (leftBuilder_ != null) {
        return leftBuilder_.getMessageOrBuilder();
      } else {
        return left_ == null ?
            org.apache.spark.connect.proto.Relation.getDefaultInstance() : left_;
      }
    }
    /**
     * <pre>
     * (Required) Left input relation for a Join.
     * </pre>
     *
     * <code>.spark.connect.Relation left = 1;</code>
     */
    private com.google.protobuf.SingleFieldBuilderV3<
        org.apache.spark.connect.proto.Relation, org.apache.spark.connect.proto.Relation.Builder, org.apache.spark.connect.proto.RelationOrBuilder> 
        getLeftFieldBuilder() {
      if (leftBuilder_ == null) {
        leftBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
            org.apache.spark.connect.proto.Relation, org.apache.spark.connect.proto.Relation.Builder, org.apache.spark.connect.proto.RelationOrBuilder>(
                getLeft(),
                getParentForChildren(),
                isClean());
        left_ = null;
      }
      return leftBuilder_;
    }

    private org.apache.spark.connect.proto.Relation right_;
    private com.google.protobuf.SingleFieldBuilderV3<
        org.apache.spark.connect.proto.Relation, org.apache.spark.connect.proto.Relation.Builder, org.apache.spark.connect.proto.RelationOrBuilder> rightBuilder_;
    /**
     * <pre>
     * (Required) Right input relation for a Join.
     * </pre>
     *
     * <code>.spark.connect.Relation right = 2;</code>
     * @return Whether the right field is set.
     */
    public boolean hasRight() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <pre>
     * (Required) Right input relation for a Join.
     * </pre>
     *
     * <code>.spark.connect.Relation right = 2;</code>
     * @return The right.
     */
    public org.apache.spark.connect.proto.Relation getRight() {
      if (rightBuilder_ == null) {
        return right_ == null ? org.apache.spark.connect.proto.Relation.getDefaultInstance() : right_;
      } else {
        return rightBuilder_.getMessage();
      }
    }
    /**
     * <pre>
     * (Required) Right input relation for a Join.
     * </pre>
     *
     * <code>.spark.connect.Relation right = 2;</code>
     */
    public Builder setRight(org.apache.spark.connect.proto.Relation value) {
      if (rightBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        right_ = value;
      } else {
        rightBuilder_.setMessage(value);
      }
      bitField0_ |= 0x00000002;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * (Required) Right input relation for a Join.
     * </pre>
     *
     * <code>.spark.connect.Relation right = 2;</code>
     */
    public Builder setRight(
        org.apache.spark.connect.proto.Relation.Builder builderForValue) {
      if (rightBuilder_ == null) {
        right_ = builderForValue.build();
      } else {
        rightBuilder_.setMessage(builderForValue.build());
      }
      bitField0_ |= 0x00000002;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * (Required) Right input relation for a Join.
     * </pre>
     *
     * <code>.spark.connect.Relation right = 2;</code>
     */
    public Builder mergeRight(org.apache.spark.connect.proto.Relation value) {
      if (rightBuilder_ == null) {
        if (((bitField0_ & 0x00000002) != 0) &&
          right_ != null &&
          right_ != org.apache.spark.connect.proto.Relation.getDefaultInstance()) {
          getRightBuilder().mergeFrom(value);
        } else {
          right_ = value;
        }
      } else {
        rightBuilder_.mergeFrom(value);
      }
      bitField0_ |= 0x00000002;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * (Required) Right input relation for a Join.
     * </pre>
     *
     * <code>.spark.connect.Relation right = 2;</code>
     */
    public Builder clearRight() {
      bitField0_ = (bitField0_ & ~0x00000002);
      right_ = null;
      if (rightBuilder_ != null) {
        rightBuilder_.dispose();
        rightBuilder_ = null;
      }
      onChanged();
      return this;
    }
    /**
     * <pre>
     * (Required) Right input relation for a Join.
     * </pre>
     *
     * <code>.spark.connect.Relation right = 2;</code>
     */
    public org.apache.spark.connect.proto.Relation.Builder getRightBuilder() {
      bitField0_ |= 0x00000002;
      onChanged();
      return getRightFieldBuilder().getBuilder();
    }
    /**
     * <pre>
     * (Required) Right input relation for a Join.
     * </pre>
     *
     * <code>.spark.connect.Relation right = 2;</code>
     */
    public org.apache.spark.connect.proto.RelationOrBuilder getRightOrBuilder() {
      if (rightBuilder_ != null) {
        return rightBuilder_.getMessageOrBuilder();
      } else {
        return right_ == null ?
            org.apache.spark.connect.proto.Relation.getDefaultInstance() : right_;
      }
    }
    /**
     * <pre>
     * (Required) Right input relation for a Join.
     * </pre>
     *
     * <code>.spark.connect.Relation right = 2;</code>
     */
    private com.google.protobuf.SingleFieldBuilderV3<
        org.apache.spark.connect.proto.Relation, org.apache.spark.connect.proto.Relation.Builder, org.apache.spark.connect.proto.RelationOrBuilder> 
        getRightFieldBuilder() {
      if (rightBuilder_ == null) {
        rightBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
            org.apache.spark.connect.proto.Relation, org.apache.spark.connect.proto.Relation.Builder, org.apache.spark.connect.proto.RelationOrBuilder>(
                getRight(),
                getParentForChildren(),
                isClean());
        right_ = null;
      }
      return rightBuilder_;
    }

    private org.apache.spark.connect.proto.Expression joinCondition_;
    private com.google.protobuf.SingleFieldBuilderV3<
        org.apache.spark.connect.proto.Expression, org.apache.spark.connect.proto.Expression.Builder, org.apache.spark.connect.proto.ExpressionOrBuilder> joinConditionBuilder_;
    /**
     * <pre>
     * (Optional) The join condition. Could be unset when `using_columns` is utilized.
     *
     * This field does not co-exist with using_columns.
     * </pre>
     *
     * <code>.spark.connect.Expression join_condition = 3;</code>
     * @return Whether the joinCondition field is set.
     */
    public boolean hasJoinCondition() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <pre>
     * (Optional) The join condition. Could be unset when `using_columns` is utilized.
     *
     * This field does not co-exist with using_columns.
     * </pre>
     *
     * <code>.spark.connect.Expression join_condition = 3;</code>
     * @return The joinCondition.
     */
    public org.apache.spark.connect.proto.Expression getJoinCondition() {
      if (joinConditionBuilder_ == null) {
        return joinCondition_ == null ? org.apache.spark.connect.proto.Expression.getDefaultInstance() : joinCondition_;
      } else {
        return joinConditionBuilder_.getMessage();
      }
    }
    /**
     * <pre>
     * (Optional) The join condition. Could be unset when `using_columns` is utilized.
     *
     * This field does not co-exist with using_columns.
     * </pre>
     *
     * <code>.spark.connect.Expression join_condition = 3;</code>
     */
    public Builder setJoinCondition(org.apache.spark.connect.proto.Expression value) {
      if (joinConditionBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        joinCondition_ = value;
      } else {
        joinConditionBuilder_.setMessage(value);
      }
      bitField0_ |= 0x00000004;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * (Optional) The join condition. Could be unset when `using_columns` is utilized.
     *
     * This field does not co-exist with using_columns.
     * </pre>
     *
     * <code>.spark.connect.Expression join_condition = 3;</code>
     */
    public Builder setJoinCondition(
        org.apache.spark.connect.proto.Expression.Builder builderForValue) {
      if (joinConditionBuilder_ == null) {
        joinCondition_ = builderForValue.build();
      } else {
        joinConditionBuilder_.setMessage(builderForValue.build());
      }
      bitField0_ |= 0x00000004;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * (Optional) The join condition. Could be unset when `using_columns` is utilized.
     *
     * This field does not co-exist with using_columns.
     * </pre>
     *
     * <code>.spark.connect.Expression join_condition = 3;</code>
     */
    public Builder mergeJoinCondition(org.apache.spark.connect.proto.Expression value) {
      if (joinConditionBuilder_ == null) {
        if (((bitField0_ & 0x00000004) != 0) &&
          joinCondition_ != null &&
          joinCondition_ != org.apache.spark.connect.proto.Expression.getDefaultInstance()) {
          getJoinConditionBuilder().mergeFrom(value);
        } else {
          joinCondition_ = value;
        }
      } else {
        joinConditionBuilder_.mergeFrom(value);
      }
      bitField0_ |= 0x00000004;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * (Optional) The join condition. Could be unset when `using_columns` is utilized.
     *
     * This field does not co-exist with using_columns.
     * </pre>
     *
     * <code>.spark.connect.Expression join_condition = 3;</code>
     */
    public Builder clearJoinCondition() {
      bitField0_ = (bitField0_ & ~0x00000004);
      joinCondition_ = null;
      if (joinConditionBuilder_ != null) {
        joinConditionBuilder_.dispose();
        joinConditionBuilder_ = null;
      }
      onChanged();
      return this;
    }
    /**
     * <pre>
     * (Optional) The join condition. Could be unset when `using_columns` is utilized.
     *
     * This field does not co-exist with using_columns.
     * </pre>
     *
     * <code>.spark.connect.Expression join_condition = 3;</code>
     */
    public org.apache.spark.connect.proto.Expression.Builder getJoinConditionBuilder() {
      bitField0_ |= 0x00000004;
      onChanged();
      return getJoinConditionFieldBuilder().getBuilder();
    }
    /**
     * <pre>
     * (Optional) The join condition. Could be unset when `using_columns` is utilized.
     *
     * This field does not co-exist with using_columns.
     * </pre>
     *
     * <code>.spark.connect.Expression join_condition = 3;</code>
     */
    public org.apache.spark.connect.proto.ExpressionOrBuilder getJoinConditionOrBuilder() {
      if (joinConditionBuilder_ != null) {
        return joinConditionBuilder_.getMessageOrBuilder();
      } else {
        return joinCondition_ == null ?
            org.apache.spark.connect.proto.Expression.getDefaultInstance() : joinCondition_;
      }
    }
    /**
     * <pre>
     * (Optional) The join condition. Could be unset when `using_columns` is utilized.
     *
     * This field does not co-exist with using_columns.
     * </pre>
     *
     * <code>.spark.connect.Expression join_condition = 3;</code>
     */
    private com.google.protobuf.SingleFieldBuilderV3<
        org.apache.spark.connect.proto.Expression, org.apache.spark.connect.proto.Expression.Builder, org.apache.spark.connect.proto.ExpressionOrBuilder> 
        getJoinConditionFieldBuilder() {
      if (joinConditionBuilder_ == null) {
        joinConditionBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
            org.apache.spark.connect.proto.Expression, org.apache.spark.connect.proto.Expression.Builder, org.apache.spark.connect.proto.ExpressionOrBuilder>(
                getJoinCondition(),
                getParentForChildren(),
                isClean());
        joinCondition_ = null;
      }
      return joinConditionBuilder_;
    }

    private int joinType_ = 0;
    /**
     * <pre>
     * (Required) The join type.
     * </pre>
     *
     * <code>.spark.connect.Join.JoinType join_type = 4;</code>
     * @return The enum numeric value on the wire for joinType.
     */
    @Override public int getJoinTypeValue() {
      return joinType_;
    }
    /**
     * <pre>
     * (Required) The join type.
     * </pre>
     *
     * <code>.spark.connect.Join.JoinType join_type = 4;</code>
     * @param value The enum numeric value on the wire for joinType to set.
     * @return This builder for chaining.
     */
    public Builder setJoinTypeValue(int value) {
      joinType_ = value;
      bitField0_ |= 0x00000008;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * (Required) The join type.
     * </pre>
     *
     * <code>.spark.connect.Join.JoinType join_type = 4;</code>
     * @return The joinType.
     */
    @Override
    public org.apache.spark.connect.proto.Join.JoinType getJoinType() {
      org.apache.spark.connect.proto.Join.JoinType result = org.apache.spark.connect.proto.Join.JoinType.forNumber(joinType_);
      return result == null ? org.apache.spark.connect.proto.Join.JoinType.UNRECOGNIZED : result;
    }
    /**
     * <pre>
     * (Required) The join type.
     * </pre>
     *
     * <code>.spark.connect.Join.JoinType join_type = 4;</code>
     * @param value The joinType to set.
     * @return This builder for chaining.
     */
    public Builder setJoinType(org.apache.spark.connect.proto.Join.JoinType value) {
      if (value == null) {
        throw new NullPointerException();
      }
      bitField0_ |= 0x00000008;
      joinType_ = value.getNumber();
      onChanged();
      return this;
    }
    /**
     * <pre>
     * (Required) The join type.
     * </pre>
     *
     * <code>.spark.connect.Join.JoinType join_type = 4;</code>
     * @return This builder for chaining.
     */
    public Builder clearJoinType() {
      bitField0_ = (bitField0_ & ~0x00000008);
      joinType_ = 0;
      onChanged();
      return this;
    }

    private com.google.protobuf.LazyStringArrayList usingColumns_ =
        com.google.protobuf.LazyStringArrayList.emptyList();
    private void ensureUsingColumnsIsMutable() {
      if (!usingColumns_.isModifiable()) {
        usingColumns_ = new com.google.protobuf.LazyStringArrayList(usingColumns_);
      }
      bitField0_ |= 0x00000010;
    }
    /**
     * <pre>
     * Optional. using_columns provides a list of columns that should present on both sides of
     * the join inputs that this Join will join on. For example A JOIN B USING col_name is
     * equivalent to A JOIN B on A.col_name = B.col_name.
     *
     * This field does not co-exist with join_condition.
     * </pre>
     *
     * <code>repeated string using_columns = 5;</code>
     * @return A list containing the usingColumns.
     */
    public com.google.protobuf.ProtocolStringList
        getUsingColumnsList() {
      usingColumns_.makeImmutable();
      return usingColumns_;
    }
    /**
     * <pre>
     * Optional. using_columns provides a list of columns that should present on both sides of
     * the join inputs that this Join will join on. For example A JOIN B USING col_name is
     * equivalent to A JOIN B on A.col_name = B.col_name.
     *
     * This field does not co-exist with join_condition.
     * </pre>
     *
     * <code>repeated string using_columns = 5;</code>
     * @return The count of usingColumns.
     */
    public int getUsingColumnsCount() {
      return usingColumns_.size();
    }
    /**
     * <pre>
     * Optional. using_columns provides a list of columns that should present on both sides of
     * the join inputs that this Join will join on. For example A JOIN B USING col_name is
     * equivalent to A JOIN B on A.col_name = B.col_name.
     *
     * This field does not co-exist with join_condition.
     * </pre>
     *
     * <code>repeated string using_columns = 5;</code>
     * @param index The index of the element to return.
     * @return The usingColumns at the given index.
     */
    public String getUsingColumns(int index) {
      return usingColumns_.get(index);
    }
    /**
     * <pre>
     * Optional. using_columns provides a list of columns that should present on both sides of
     * the join inputs that this Join will join on. For example A JOIN B USING col_name is
     * equivalent to A JOIN B on A.col_name = B.col_name.
     *
     * This field does not co-exist with join_condition.
     * </pre>
     *
     * <code>repeated string using_columns = 5;</code>
     * @param index The index of the value to return.
     * @return The bytes of the usingColumns at the given index.
     */
    public com.google.protobuf.ByteString
        getUsingColumnsBytes(int index) {
      return usingColumns_.getByteString(index);
    }
    /**
     * <pre>
     * Optional. using_columns provides a list of columns that should present on both sides of
     * the join inputs that this Join will join on. For example A JOIN B USING col_name is
     * equivalent to A JOIN B on A.col_name = B.col_name.
     *
     * This field does not co-exist with join_condition.
     * </pre>
     *
     * <code>repeated string using_columns = 5;</code>
     * @param index The index to set the value at.
     * @param value The usingColumns to set.
     * @return This builder for chaining.
     */
    public Builder setUsingColumns(
        int index, String value) {
      if (value == null) { throw new NullPointerException(); }
      ensureUsingColumnsIsMutable();
      usingColumns_.set(index, value);
      bitField0_ |= 0x00000010;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Optional. using_columns provides a list of columns that should present on both sides of
     * the join inputs that this Join will join on. For example A JOIN B USING col_name is
     * equivalent to A JOIN B on A.col_name = B.col_name.
     *
     * This field does not co-exist with join_condition.
     * </pre>
     *
     * <code>repeated string using_columns = 5;</code>
     * @param value The usingColumns to add.
     * @return This builder for chaining.
     */
    public Builder addUsingColumns(
        String value) {
      if (value == null) { throw new NullPointerException(); }
      ensureUsingColumnsIsMutable();
      usingColumns_.add(value);
      bitField0_ |= 0x00000010;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Optional. using_columns provides a list of columns that should present on both sides of
     * the join inputs that this Join will join on. For example A JOIN B USING col_name is
     * equivalent to A JOIN B on A.col_name = B.col_name.
     *
     * This field does not co-exist with join_condition.
     * </pre>
     *
     * <code>repeated string using_columns = 5;</code>
     * @param values The usingColumns to add.
     * @return This builder for chaining.
     */
    public Builder addAllUsingColumns(
        Iterable<String> values) {
      ensureUsingColumnsIsMutable();
      com.google.protobuf.AbstractMessageLite.Builder.addAll(
          values, usingColumns_);
      bitField0_ |= 0x00000010;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Optional. using_columns provides a list of columns that should present on both sides of
     * the join inputs that this Join will join on. For example A JOIN B USING col_name is
     * equivalent to A JOIN B on A.col_name = B.col_name.
     *
     * This field does not co-exist with join_condition.
     * </pre>
     *
     * <code>repeated string using_columns = 5;</code>
     * @return This builder for chaining.
     */
    public Builder clearUsingColumns() {
      usingColumns_ =
        com.google.protobuf.LazyStringArrayList.emptyList();
      bitField0_ = (bitField0_ & ~0x00000010);;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Optional. using_columns provides a list of columns that should present on both sides of
     * the join inputs that this Join will join on. For example A JOIN B USING col_name is
     * equivalent to A JOIN B on A.col_name = B.col_name.
     *
     * This field does not co-exist with join_condition.
     * </pre>
     *
     * <code>repeated string using_columns = 5;</code>
     * @param value The bytes of the usingColumns to add.
     * @return This builder for chaining.
     */
    public Builder addUsingColumnsBytes(
        com.google.protobuf.ByteString value) {
      if (value == null) { throw new NullPointerException(); }
      checkByteStringIsUtf8(value);
      ensureUsingColumnsIsMutable();
      usingColumns_.add(value);
      bitField0_ |= 0x00000010;
      onChanged();
      return this;
    }

    private org.apache.spark.connect.proto.Join.JoinDataType joinDataType_;
    private com.google.protobuf.SingleFieldBuilderV3<
        org.apache.spark.connect.proto.Join.JoinDataType, org.apache.spark.connect.proto.Join.JoinDataType.Builder, org.apache.spark.connect.proto.Join.JoinDataTypeOrBuilder> joinDataTypeBuilder_;
    /**
     * <pre>
     * (Optional) Only used by joinWith. Set the left and right join data types.
     * </pre>
     *
     * <code>optional .spark.connect.Join.JoinDataType join_data_type = 6;</code>
     * @return Whether the joinDataType field is set.
     */
    public boolean hasJoinDataType() {
      return ((bitField0_ & 0x00000020) != 0);
    }
    /**
     * <pre>
     * (Optional) Only used by joinWith. Set the left and right join data types.
     * </pre>
     *
     * <code>optional .spark.connect.Join.JoinDataType join_data_type = 6;</code>
     * @return The joinDataType.
     */
    public org.apache.spark.connect.proto.Join.JoinDataType getJoinDataType() {
      if (joinDataTypeBuilder_ == null) {
        return joinDataType_ == null ? org.apache.spark.connect.proto.Join.JoinDataType.getDefaultInstance() : joinDataType_;
      } else {
        return joinDataTypeBuilder_.getMessage();
      }
    }
    /**
     * <pre>
     * (Optional) Only used by joinWith. Set the left and right join data types.
     * </pre>
     *
     * <code>optional .spark.connect.Join.JoinDataType join_data_type = 6;</code>
     */
    public Builder setJoinDataType(org.apache.spark.connect.proto.Join.JoinDataType value) {
      if (joinDataTypeBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        joinDataType_ = value;
      } else {
        joinDataTypeBuilder_.setMessage(value);
      }
      bitField0_ |= 0x00000020;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * (Optional) Only used by joinWith. Set the left and right join data types.
     * </pre>
     *
     * <code>optional .spark.connect.Join.JoinDataType join_data_type = 6;</code>
     */
    public Builder setJoinDataType(
        org.apache.spark.connect.proto.Join.JoinDataType.Builder builderForValue) {
      if (joinDataTypeBuilder_ == null) {
        joinDataType_ = builderForValue.build();
      } else {
        joinDataTypeBuilder_.setMessage(builderForValue.build());
      }
      bitField0_ |= 0x00000020;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * (Optional) Only used by joinWith. Set the left and right join data types.
     * </pre>
     *
     * <code>optional .spark.connect.Join.JoinDataType join_data_type = 6;</code>
     */
    public Builder mergeJoinDataType(org.apache.spark.connect.proto.Join.JoinDataType value) {
      if (joinDataTypeBuilder_ == null) {
        if (((bitField0_ & 0x00000020) != 0) &&
          joinDataType_ != null &&
          joinDataType_ != org.apache.spark.connect.proto.Join.JoinDataType.getDefaultInstance()) {
          getJoinDataTypeBuilder().mergeFrom(value);
        } else {
          joinDataType_ = value;
        }
      } else {
        joinDataTypeBuilder_.mergeFrom(value);
      }
      bitField0_ |= 0x00000020;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * (Optional) Only used by joinWith. Set the left and right join data types.
     * </pre>
     *
     * <code>optional .spark.connect.Join.JoinDataType join_data_type = 6;</code>
     */
    public Builder clearJoinDataType() {
      bitField0_ = (bitField0_ & ~0x00000020);
      joinDataType_ = null;
      if (joinDataTypeBuilder_ != null) {
        joinDataTypeBuilder_.dispose();
        joinDataTypeBuilder_ = null;
      }
      onChanged();
      return this;
    }
    /**
     * <pre>
     * (Optional) Only used by joinWith. Set the left and right join data types.
     * </pre>
     *
     * <code>optional .spark.connect.Join.JoinDataType join_data_type = 6;</code>
     */
    public org.apache.spark.connect.proto.Join.JoinDataType.Builder getJoinDataTypeBuilder() {
      bitField0_ |= 0x00000020;
      onChanged();
      return getJoinDataTypeFieldBuilder().getBuilder();
    }
    /**
     * <pre>
     * (Optional) Only used by joinWith. Set the left and right join data types.
     * </pre>
     *
     * <code>optional .spark.connect.Join.JoinDataType join_data_type = 6;</code>
     */
    public org.apache.spark.connect.proto.Join.JoinDataTypeOrBuilder getJoinDataTypeOrBuilder() {
      if (joinDataTypeBuilder_ != null) {
        return joinDataTypeBuilder_.getMessageOrBuilder();
      } else {
        return joinDataType_ == null ?
            org.apache.spark.connect.proto.Join.JoinDataType.getDefaultInstance() : joinDataType_;
      }
    }
    /**
     * <pre>
     * (Optional) Only used by joinWith. Set the left and right join data types.
     * </pre>
     *
     * <code>optional .spark.connect.Join.JoinDataType join_data_type = 6;</code>
     */
    private com.google.protobuf.SingleFieldBuilderV3<
        org.apache.spark.connect.proto.Join.JoinDataType, org.apache.spark.connect.proto.Join.JoinDataType.Builder, org.apache.spark.connect.proto.Join.JoinDataTypeOrBuilder> 
        getJoinDataTypeFieldBuilder() {
      if (joinDataTypeBuilder_ == null) {
        joinDataTypeBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
            org.apache.spark.connect.proto.Join.JoinDataType, org.apache.spark.connect.proto.Join.JoinDataType.Builder, org.apache.spark.connect.proto.Join.JoinDataTypeOrBuilder>(
                getJoinDataType(),
                getParentForChildren(),
                isClean());
        joinDataType_ = null;
      }
      return joinDataTypeBuilder_;
    }
    @Override
    public final Builder setUnknownFields(
        final com.google.protobuf.UnknownFieldSet unknownFields) {
      return super.setUnknownFields(unknownFields);
    }

    @Override
    public final Builder mergeUnknownFields(
        final com.google.protobuf.UnknownFieldSet unknownFields) {
      return super.mergeUnknownFields(unknownFields);
    }


    // @@protoc_insertion_point(builder_scope:spark.connect.Join)
  }

  // @@protoc_insertion_point(class_scope:spark.connect.Join)
  private static final org.apache.spark.connect.proto.Join DEFAULT_INSTANCE;
  static {
    DEFAULT_INSTANCE = new org.apache.spark.connect.proto.Join();
  }

  public static org.apache.spark.connect.proto.Join getDefaultInstance() {
    return DEFAULT_INSTANCE;
  }

  private static final com.google.protobuf.Parser<Join>
      PARSER = new com.google.protobuf.AbstractParser<Join>() {
    @Override
    public Join parsePartialFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      Builder builder = newBuilder();
      try {
        builder.mergeFrom(input, extensionRegistry);
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(builder.buildPartial());
      } catch (com.google.protobuf.UninitializedMessageException e) {
        throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(e)
            .setUnfinishedMessage(builder.buildPartial());
      }
      return builder.buildPartial();
    }
  };

  public static com.google.protobuf.Parser<Join> parser() {
    return PARSER;
  }

  @Override
  public com.google.protobuf.Parser<Join> getParserForType() {
    return PARSER;
  }

  @Override
  public org.apache.spark.connect.proto.Join getDefaultInstanceForType() {
    return DEFAULT_INSTANCE;
  }

}

