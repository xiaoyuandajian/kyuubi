// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: spark/connect/base.proto

package org.apache.kyuubi.engine.spark.connect.proto;

public interface AddArtifactsRequestOrBuilder extends
    // @@protoc_insertion_point(interface_extends:spark.connect.AddArtifactsRequest)
    com.google.protobuf.MessageOrBuilder {

  /**
   * <pre>
   * (Required)
   *
   * The session_id specifies a spark session for a user id (which is specified
   * by user_context.user_id). The session_id is set by the client to be able to
   * collate streaming responses from different queries within the dedicated session.
   * The id should be an UUID string of the format `00112233-4455-6677-8899-aabbccddeeff`
   * </pre>
   *
   * <code>string session_id = 1;</code>
   * @return The sessionId.
   */
  String getSessionId();
  /**
   * <pre>
   * (Required)
   *
   * The session_id specifies a spark session for a user id (which is specified
   * by user_context.user_id). The session_id is set by the client to be able to
   * collate streaming responses from different queries within the dedicated session.
   * The id should be an UUID string of the format `00112233-4455-6677-8899-aabbccddeeff`
   * </pre>
   *
   * <code>string session_id = 1;</code>
   * @return The bytes for sessionId.
   */
  com.google.protobuf.ByteString
      getSessionIdBytes();

  /**
   * <pre>
   * User context
   * </pre>
   *
   * <code>.spark.connect.UserContext user_context = 2;</code>
   * @return Whether the userContext field is set.
   */
  boolean hasUserContext();
  /**
   * <pre>
   * User context
   * </pre>
   *
   * <code>.spark.connect.UserContext user_context = 2;</code>
   * @return The userContext.
   */
  org.apache.spark.connect.proto.UserContext getUserContext();
  /**
   * <pre>
   * User context
   * </pre>
   *
   * <code>.spark.connect.UserContext user_context = 2;</code>
   */
  org.apache.spark.connect.proto.UserContextOrBuilder getUserContextOrBuilder();

  /**
   * <pre>
   * Provides optional information about the client sending the request. This field
   * can be used for language or version specific information and is only intended for
   * logging purposes and will not be interpreted by the server.
   * </pre>
   *
   * <code>optional string client_type = 6;</code>
   * @return Whether the clientType field is set.
   */
  boolean hasClientType();
  /**
   * <pre>
   * Provides optional information about the client sending the request. This field
   * can be used for language or version specific information and is only intended for
   * logging purposes and will not be interpreted by the server.
   * </pre>
   *
   * <code>optional string client_type = 6;</code>
   * @return The clientType.
   */
  String getClientType();
  /**
   * <pre>
   * Provides optional information about the client sending the request. This field
   * can be used for language or version specific information and is only intended for
   * logging purposes and will not be interpreted by the server.
   * </pre>
   *
   * <code>optional string client_type = 6;</code>
   * @return The bytes for clientType.
   */
  com.google.protobuf.ByteString
      getClientTypeBytes();

  /**
   * <code>.spark.connect.AddArtifactsRequest.Batch batch = 3;</code>
   * @return Whether the batch field is set.
   */
  boolean hasBatch();
  /**
   * <code>.spark.connect.AddArtifactsRequest.Batch batch = 3;</code>
   * @return The batch.
   */
  org.apache.spark.connect.proto.AddArtifactsRequest.Batch getBatch();
  /**
   * <code>.spark.connect.AddArtifactsRequest.Batch batch = 3;</code>
   */
  org.apache.spark.connect.proto.AddArtifactsRequest.BatchOrBuilder getBatchOrBuilder();

  /**
   * <pre>
   * The metadata and the initial chunk of a large artifact chunked into multiple requests.
   * The server side is notified about the total size of the large artifact as well as the
   * number of chunks to expect.
   * </pre>
   *
   * <code>.spark.connect.AddArtifactsRequest.BeginChunkedArtifact begin_chunk = 4;</code>
   * @return Whether the beginChunk field is set.
   */
  boolean hasBeginChunk();
  /**
   * <pre>
   * The metadata and the initial chunk of a large artifact chunked into multiple requests.
   * The server side is notified about the total size of the large artifact as well as the
   * number of chunks to expect.
   * </pre>
   *
   * <code>.spark.connect.AddArtifactsRequest.BeginChunkedArtifact begin_chunk = 4;</code>
   * @return The beginChunk.
   */
  org.apache.spark.connect.proto.AddArtifactsRequest.BeginChunkedArtifact getBeginChunk();
  /**
   * <pre>
   * The metadata and the initial chunk of a large artifact chunked into multiple requests.
   * The server side is notified about the total size of the large artifact as well as the
   * number of chunks to expect.
   * </pre>
   *
   * <code>.spark.connect.AddArtifactsRequest.BeginChunkedArtifact begin_chunk = 4;</code>
   */
  org.apache.spark.connect.proto.AddArtifactsRequest.BeginChunkedArtifactOrBuilder getBeginChunkOrBuilder();

  /**
   * <pre>
   * A chunk of an artifact excluding metadata. This can be any chunk of a large artifact
   * excluding the first chunk (which is included in `BeginChunkedArtifact`).
   * </pre>
   *
   * <code>.spark.connect.AddArtifactsRequest.ArtifactChunk chunk = 5;</code>
   * @return Whether the chunk field is set.
   */
  boolean hasChunk();
  /**
   * <pre>
   * A chunk of an artifact excluding metadata. This can be any chunk of a large artifact
   * excluding the first chunk (which is included in `BeginChunkedArtifact`).
   * </pre>
   *
   * <code>.spark.connect.AddArtifactsRequest.ArtifactChunk chunk = 5;</code>
   * @return The chunk.
   */
  org.apache.spark.connect.proto.AddArtifactsRequest.ArtifactChunk getChunk();
  /**
   * <pre>
   * A chunk of an artifact excluding metadata. This can be any chunk of a large artifact
   * excluding the first chunk (which is included in `BeginChunkedArtifact`).
   * </pre>
   *
   * <code>.spark.connect.AddArtifactsRequest.ArtifactChunk chunk = 5;</code>
   */
  org.apache.spark.connect.proto.AddArtifactsRequest.ArtifactChunkOrBuilder getChunkOrBuilder();

  org.apache.spark.connect.proto.AddArtifactsRequest.PayloadCase getPayloadCase();
}
