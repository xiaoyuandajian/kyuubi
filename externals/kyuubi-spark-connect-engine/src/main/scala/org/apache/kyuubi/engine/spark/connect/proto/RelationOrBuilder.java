// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: spark/connect/relations.proto

package org.apache.kyuubi.engine.spark.connect.proto;

public interface RelationOrBuilder extends
    // @@protoc_insertion_point(interface_extends:spark.connect.Relation)
    com.google.protobuf.MessageOrBuilder {

  /**
   * <code>.spark.connect.RelationCommon common = 1;</code>
   * @return Whether the common field is set.
   */
  boolean hasCommon();
  /**
   * <code>.spark.connect.RelationCommon common = 1;</code>
   * @return The common.
   */
  org.apache.spark.connect.proto.RelationCommon getCommon();
  /**
   * <code>.spark.connect.RelationCommon common = 1;</code>
   */
  org.apache.spark.connect.proto.RelationCommonOrBuilder getCommonOrBuilder();

  /**
   * <code>.spark.connect.Read read = 2;</code>
   * @return Whether the read field is set.
   */
  boolean hasRead();
  /**
   * <code>.spark.connect.Read read = 2;</code>
   * @return The read.
   */
  org.apache.spark.connect.proto.Read getRead();
  /**
   * <code>.spark.connect.Read read = 2;</code>
   */
  org.apache.spark.connect.proto.ReadOrBuilder getReadOrBuilder();

  /**
   * <code>.spark.connect.Project project = 3;</code>
   * @return Whether the project field is set.
   */
  boolean hasProject();
  /**
   * <code>.spark.connect.Project project = 3;</code>
   * @return The project.
   */
  org.apache.spark.connect.proto.Project getProject();
  /**
   * <code>.spark.connect.Project project = 3;</code>
   */
  org.apache.spark.connect.proto.ProjectOrBuilder getProjectOrBuilder();

  /**
   * <code>.spark.connect.Filter filter = 4;</code>
   * @return Whether the filter field is set.
   */
  boolean hasFilter();
  /**
   * <code>.spark.connect.Filter filter = 4;</code>
   * @return The filter.
   */
  org.apache.spark.connect.proto.Filter getFilter();
  /**
   * <code>.spark.connect.Filter filter = 4;</code>
   */
  org.apache.spark.connect.proto.FilterOrBuilder getFilterOrBuilder();

  /**
   * <code>.spark.connect.Join join = 5;</code>
   * @return Whether the join field is set.
   */
  boolean hasJoin();
  /**
   * <code>.spark.connect.Join join = 5;</code>
   * @return The join.
   */
  org.apache.spark.connect.proto.Join getJoin();
  /**
   * <code>.spark.connect.Join join = 5;</code>
   */
  org.apache.spark.connect.proto.JoinOrBuilder getJoinOrBuilder();

  /**
   * <code>.spark.connect.SetOperation set_op = 6;</code>
   * @return Whether the setOp field is set.
   */
  boolean hasSetOp();
  /**
   * <code>.spark.connect.SetOperation set_op = 6;</code>
   * @return The setOp.
   */
  org.apache.spark.connect.proto.SetOperation getSetOp();
  /**
   * <code>.spark.connect.SetOperation set_op = 6;</code>
   */
  org.apache.spark.connect.proto.SetOperationOrBuilder getSetOpOrBuilder();

  /**
   * <code>.spark.connect.Sort sort = 7;</code>
   * @return Whether the sort field is set.
   */
  boolean hasSort();
  /**
   * <code>.spark.connect.Sort sort = 7;</code>
   * @return The sort.
   */
  org.apache.spark.connect.proto.Sort getSort();
  /**
   * <code>.spark.connect.Sort sort = 7;</code>
   */
  org.apache.spark.connect.proto.SortOrBuilder getSortOrBuilder();

  /**
   * <code>.spark.connect.Limit limit = 8;</code>
   * @return Whether the limit field is set.
   */
  boolean hasLimit();
  /**
   * <code>.spark.connect.Limit limit = 8;</code>
   * @return The limit.
   */
  org.apache.spark.connect.proto.Limit getLimit();
  /**
   * <code>.spark.connect.Limit limit = 8;</code>
   */
  org.apache.spark.connect.proto.LimitOrBuilder getLimitOrBuilder();

  /**
   * <code>.spark.connect.Aggregate aggregate = 9;</code>
   * @return Whether the aggregate field is set.
   */
  boolean hasAggregate();
  /**
   * <code>.spark.connect.Aggregate aggregate = 9;</code>
   * @return The aggregate.
   */
  org.apache.spark.connect.proto.Aggregate getAggregate();
  /**
   * <code>.spark.connect.Aggregate aggregate = 9;</code>
   */
  org.apache.spark.connect.proto.AggregateOrBuilder getAggregateOrBuilder();

  /**
   * <code>.spark.connect.SQL sql = 10;</code>
   * @return Whether the sql field is set.
   */
  boolean hasSql();
  /**
   * <code>.spark.connect.SQL sql = 10;</code>
   * @return The sql.
   */
  org.apache.spark.connect.proto.SQL getSql();
  /**
   * <code>.spark.connect.SQL sql = 10;</code>
   */
  org.apache.spark.connect.proto.SQLOrBuilder getSqlOrBuilder();

  /**
   * <code>.spark.connect.LocalRelation local_relation = 11;</code>
   * @return Whether the localRelation field is set.
   */
  boolean hasLocalRelation();
  /**
   * <code>.spark.connect.LocalRelation local_relation = 11;</code>
   * @return The localRelation.
   */
  org.apache.spark.connect.proto.LocalRelation getLocalRelation();
  /**
   * <code>.spark.connect.LocalRelation local_relation = 11;</code>
   */
  org.apache.spark.connect.proto.LocalRelationOrBuilder getLocalRelationOrBuilder();

  /**
   * <code>.spark.connect.Sample sample = 12;</code>
   * @return Whether the sample field is set.
   */
  boolean hasSample();
  /**
   * <code>.spark.connect.Sample sample = 12;</code>
   * @return The sample.
   */
  org.apache.spark.connect.proto.Sample getSample();
  /**
   * <code>.spark.connect.Sample sample = 12;</code>
   */
  org.apache.spark.connect.proto.SampleOrBuilder getSampleOrBuilder();

  /**
   * <code>.spark.connect.Offset offset = 13;</code>
   * @return Whether the offset field is set.
   */
  boolean hasOffset();
  /**
   * <code>.spark.connect.Offset offset = 13;</code>
   * @return The offset.
   */
  org.apache.spark.connect.proto.Offset getOffset();
  /**
   * <code>.spark.connect.Offset offset = 13;</code>
   */
  org.apache.spark.connect.proto.OffsetOrBuilder getOffsetOrBuilder();

  /**
   * <code>.spark.connect.Deduplicate deduplicate = 14;</code>
   * @return Whether the deduplicate field is set.
   */
  boolean hasDeduplicate();
  /**
   * <code>.spark.connect.Deduplicate deduplicate = 14;</code>
   * @return The deduplicate.
   */
  org.apache.spark.connect.proto.Deduplicate getDeduplicate();
  /**
   * <code>.spark.connect.Deduplicate deduplicate = 14;</code>
   */
  org.apache.spark.connect.proto.DeduplicateOrBuilder getDeduplicateOrBuilder();

  /**
   * <code>.spark.connect.Range range = 15;</code>
   * @return Whether the range field is set.
   */
  boolean hasRange();
  /**
   * <code>.spark.connect.Range range = 15;</code>
   * @return The range.
   */
  org.apache.spark.connect.proto.Range getRange();
  /**
   * <code>.spark.connect.Range range = 15;</code>
   */
  org.apache.spark.connect.proto.RangeOrBuilder getRangeOrBuilder();

  /**
   * <code>.spark.connect.SubqueryAlias subquery_alias = 16;</code>
   * @return Whether the subqueryAlias field is set.
   */
  boolean hasSubqueryAlias();
  /**
   * <code>.spark.connect.SubqueryAlias subquery_alias = 16;</code>
   * @return The subqueryAlias.
   */
  org.apache.spark.connect.proto.SubqueryAlias getSubqueryAlias();
  /**
   * <code>.spark.connect.SubqueryAlias subquery_alias = 16;</code>
   */
  org.apache.spark.connect.proto.SubqueryAliasOrBuilder getSubqueryAliasOrBuilder();

  /**
   * <code>.spark.connect.Repartition repartition = 17;</code>
   * @return Whether the repartition field is set.
   */
  boolean hasRepartition();
  /**
   * <code>.spark.connect.Repartition repartition = 17;</code>
   * @return The repartition.
   */
  org.apache.spark.connect.proto.Repartition getRepartition();
  /**
   * <code>.spark.connect.Repartition repartition = 17;</code>
   */
  org.apache.spark.connect.proto.RepartitionOrBuilder getRepartitionOrBuilder();

  /**
   * <code>.spark.connect.ToDF to_df = 18;</code>
   * @return Whether the toDf field is set.
   */
  boolean hasToDf();
  /**
   * <code>.spark.connect.ToDF to_df = 18;</code>
   * @return The toDf.
   */
  org.apache.spark.connect.proto.ToDF getToDf();
  /**
   * <code>.spark.connect.ToDF to_df = 18;</code>
   */
  org.apache.spark.connect.proto.ToDFOrBuilder getToDfOrBuilder();

  /**
   * <code>.spark.connect.WithColumnsRenamed with_columns_renamed = 19;</code>
   * @return Whether the withColumnsRenamed field is set.
   */
  boolean hasWithColumnsRenamed();
  /**
   * <code>.spark.connect.WithColumnsRenamed with_columns_renamed = 19;</code>
   * @return The withColumnsRenamed.
   */
  org.apache.spark.connect.proto.WithColumnsRenamed getWithColumnsRenamed();
  /**
   * <code>.spark.connect.WithColumnsRenamed with_columns_renamed = 19;</code>
   */
  org.apache.spark.connect.proto.WithColumnsRenamedOrBuilder getWithColumnsRenamedOrBuilder();

  /**
   * <code>.spark.connect.ShowString show_string = 20;</code>
   * @return Whether the showString field is set.
   */
  boolean hasShowString();
  /**
   * <code>.spark.connect.ShowString show_string = 20;</code>
   * @return The showString.
   */
  org.apache.spark.connect.proto.ShowString getShowString();
  /**
   * <code>.spark.connect.ShowString show_string = 20;</code>
   */
  org.apache.spark.connect.proto.ShowStringOrBuilder getShowStringOrBuilder();

  /**
   * <code>.spark.connect.Drop drop = 21;</code>
   * @return Whether the drop field is set.
   */
  boolean hasDrop();
  /**
   * <code>.spark.connect.Drop drop = 21;</code>
   * @return The drop.
   */
  org.apache.spark.connect.proto.Drop getDrop();
  /**
   * <code>.spark.connect.Drop drop = 21;</code>
   */
  org.apache.spark.connect.proto.DropOrBuilder getDropOrBuilder();

  /**
   * <code>.spark.connect.Tail tail = 22;</code>
   * @return Whether the tail field is set.
   */
  boolean hasTail();
  /**
   * <code>.spark.connect.Tail tail = 22;</code>
   * @return The tail.
   */
  org.apache.spark.connect.proto.Tail getTail();
  /**
   * <code>.spark.connect.Tail tail = 22;</code>
   */
  org.apache.spark.connect.proto.TailOrBuilder getTailOrBuilder();

  /**
   * <code>.spark.connect.WithColumns with_columns = 23;</code>
   * @return Whether the withColumns field is set.
   */
  boolean hasWithColumns();
  /**
   * <code>.spark.connect.WithColumns with_columns = 23;</code>
   * @return The withColumns.
   */
  org.apache.spark.connect.proto.WithColumns getWithColumns();
  /**
   * <code>.spark.connect.WithColumns with_columns = 23;</code>
   */
  org.apache.spark.connect.proto.WithColumnsOrBuilder getWithColumnsOrBuilder();

  /**
   * <code>.spark.connect.Hint hint = 24;</code>
   * @return Whether the hint field is set.
   */
  boolean hasHint();
  /**
   * <code>.spark.connect.Hint hint = 24;</code>
   * @return The hint.
   */
  org.apache.spark.connect.proto.Hint getHint();
  /**
   * <code>.spark.connect.Hint hint = 24;</code>
   */
  org.apache.spark.connect.proto.HintOrBuilder getHintOrBuilder();

  /**
   * <code>.spark.connect.Unpivot unpivot = 25;</code>
   * @return Whether the unpivot field is set.
   */
  boolean hasUnpivot();
  /**
   * <code>.spark.connect.Unpivot unpivot = 25;</code>
   * @return The unpivot.
   */
  org.apache.spark.connect.proto.Unpivot getUnpivot();
  /**
   * <code>.spark.connect.Unpivot unpivot = 25;</code>
   */
  org.apache.spark.connect.proto.UnpivotOrBuilder getUnpivotOrBuilder();

  /**
   * <code>.spark.connect.ToSchema to_schema = 26;</code>
   * @return Whether the toSchema field is set.
   */
  boolean hasToSchema();
  /**
   * <code>.spark.connect.ToSchema to_schema = 26;</code>
   * @return The toSchema.
   */
  org.apache.spark.connect.proto.ToSchema getToSchema();
  /**
   * <code>.spark.connect.ToSchema to_schema = 26;</code>
   */
  org.apache.spark.connect.proto.ToSchemaOrBuilder getToSchemaOrBuilder();

  /**
   * <code>.spark.connect.RepartitionByExpression repartition_by_expression = 27;</code>
   * @return Whether the repartitionByExpression field is set.
   */
  boolean hasRepartitionByExpression();
  /**
   * <code>.spark.connect.RepartitionByExpression repartition_by_expression = 27;</code>
   * @return The repartitionByExpression.
   */
  org.apache.spark.connect.proto.RepartitionByExpression getRepartitionByExpression();
  /**
   * <code>.spark.connect.RepartitionByExpression repartition_by_expression = 27;</code>
   */
  org.apache.spark.connect.proto.RepartitionByExpressionOrBuilder getRepartitionByExpressionOrBuilder();

  /**
   * <code>.spark.connect.MapPartitions map_partitions = 28;</code>
   * @return Whether the mapPartitions field is set.
   */
  boolean hasMapPartitions();
  /**
   * <code>.spark.connect.MapPartitions map_partitions = 28;</code>
   * @return The mapPartitions.
   */
  org.apache.spark.connect.proto.MapPartitions getMapPartitions();
  /**
   * <code>.spark.connect.MapPartitions map_partitions = 28;</code>
   */
  org.apache.spark.connect.proto.MapPartitionsOrBuilder getMapPartitionsOrBuilder();

  /**
   * <code>.spark.connect.CollectMetrics collect_metrics = 29;</code>
   * @return Whether the collectMetrics field is set.
   */
  boolean hasCollectMetrics();
  /**
   * <code>.spark.connect.CollectMetrics collect_metrics = 29;</code>
   * @return The collectMetrics.
   */
  org.apache.spark.connect.proto.CollectMetrics getCollectMetrics();
  /**
   * <code>.spark.connect.CollectMetrics collect_metrics = 29;</code>
   */
  org.apache.spark.connect.proto.CollectMetricsOrBuilder getCollectMetricsOrBuilder();

  /**
   * <code>.spark.connect.Parse parse = 30;</code>
   * @return Whether the parse field is set.
   */
  boolean hasParse();
  /**
   * <code>.spark.connect.Parse parse = 30;</code>
   * @return The parse.
   */
  org.apache.spark.connect.proto.Parse getParse();
  /**
   * <code>.spark.connect.Parse parse = 30;</code>
   */
  org.apache.spark.connect.proto.ParseOrBuilder getParseOrBuilder();

  /**
   * <code>.spark.connect.GroupMap group_map = 31;</code>
   * @return Whether the groupMap field is set.
   */
  boolean hasGroupMap();
  /**
   * <code>.spark.connect.GroupMap group_map = 31;</code>
   * @return The groupMap.
   */
  org.apache.spark.connect.proto.GroupMap getGroupMap();
  /**
   * <code>.spark.connect.GroupMap group_map = 31;</code>
   */
  org.apache.spark.connect.proto.GroupMapOrBuilder getGroupMapOrBuilder();

  /**
   * <code>.spark.connect.CoGroupMap co_group_map = 32;</code>
   * @return Whether the coGroupMap field is set.
   */
  boolean hasCoGroupMap();
  /**
   * <code>.spark.connect.CoGroupMap co_group_map = 32;</code>
   * @return The coGroupMap.
   */
  org.apache.spark.connect.proto.CoGroupMap getCoGroupMap();
  /**
   * <code>.spark.connect.CoGroupMap co_group_map = 32;</code>
   */
  org.apache.spark.connect.proto.CoGroupMapOrBuilder getCoGroupMapOrBuilder();

  /**
   * <code>.spark.connect.WithWatermark with_watermark = 33;</code>
   * @return Whether the withWatermark field is set.
   */
  boolean hasWithWatermark();
  /**
   * <code>.spark.connect.WithWatermark with_watermark = 33;</code>
   * @return The withWatermark.
   */
  org.apache.spark.connect.proto.WithWatermark getWithWatermark();
  /**
   * <code>.spark.connect.WithWatermark with_watermark = 33;</code>
   */
  org.apache.spark.connect.proto.WithWatermarkOrBuilder getWithWatermarkOrBuilder();

  /**
   * <code>.spark.connect.ApplyInPandasWithState apply_in_pandas_with_state = 34;</code>
   * @return Whether the applyInPandasWithState field is set.
   */
  boolean hasApplyInPandasWithState();
  /**
   * <code>.spark.connect.ApplyInPandasWithState apply_in_pandas_with_state = 34;</code>
   * @return The applyInPandasWithState.
   */
  org.apache.spark.connect.proto.ApplyInPandasWithState getApplyInPandasWithState();
  /**
   * <code>.spark.connect.ApplyInPandasWithState apply_in_pandas_with_state = 34;</code>
   */
  org.apache.spark.connect.proto.ApplyInPandasWithStateOrBuilder getApplyInPandasWithStateOrBuilder();

  /**
   * <code>.spark.connect.HtmlString html_string = 35;</code>
   * @return Whether the htmlString field is set.
   */
  boolean hasHtmlString();
  /**
   * <code>.spark.connect.HtmlString html_string = 35;</code>
   * @return The htmlString.
   */
  org.apache.spark.connect.proto.HtmlString getHtmlString();
  /**
   * <code>.spark.connect.HtmlString html_string = 35;</code>
   */
  org.apache.spark.connect.proto.HtmlStringOrBuilder getHtmlStringOrBuilder();

  /**
   * <code>.spark.connect.CachedLocalRelation cached_local_relation = 36;</code>
   * @return Whether the cachedLocalRelation field is set.
   */
  boolean hasCachedLocalRelation();
  /**
   * <code>.spark.connect.CachedLocalRelation cached_local_relation = 36;</code>
   * @return The cachedLocalRelation.
   */
  org.apache.spark.connect.proto.CachedLocalRelation getCachedLocalRelation();
  /**
   * <code>.spark.connect.CachedLocalRelation cached_local_relation = 36;</code>
   */
  org.apache.spark.connect.proto.CachedLocalRelationOrBuilder getCachedLocalRelationOrBuilder();

  /**
   * <code>.spark.connect.CachedRemoteRelation cached_remote_relation = 37;</code>
   * @return Whether the cachedRemoteRelation field is set.
   */
  boolean hasCachedRemoteRelation();
  /**
   * <code>.spark.connect.CachedRemoteRelation cached_remote_relation = 37;</code>
   * @return The cachedRemoteRelation.
   */
  org.apache.spark.connect.proto.CachedRemoteRelation getCachedRemoteRelation();
  /**
   * <code>.spark.connect.CachedRemoteRelation cached_remote_relation = 37;</code>
   */
  org.apache.spark.connect.proto.CachedRemoteRelationOrBuilder getCachedRemoteRelationOrBuilder();

  /**
   * <code>.spark.connect.CommonInlineUserDefinedTableFunction common_inline_user_defined_table_function = 38;</code>
   * @return Whether the commonInlineUserDefinedTableFunction field is set.
   */
  boolean hasCommonInlineUserDefinedTableFunction();
  /**
   * <code>.spark.connect.CommonInlineUserDefinedTableFunction common_inline_user_defined_table_function = 38;</code>
   * @return The commonInlineUserDefinedTableFunction.
   */
  org.apache.spark.connect.proto.CommonInlineUserDefinedTableFunction getCommonInlineUserDefinedTableFunction();
  /**
   * <code>.spark.connect.CommonInlineUserDefinedTableFunction common_inline_user_defined_table_function = 38;</code>
   */
  org.apache.spark.connect.proto.CommonInlineUserDefinedTableFunctionOrBuilder getCommonInlineUserDefinedTableFunctionOrBuilder();

  /**
   * <code>.spark.connect.AsOfJoin as_of_join = 39;</code>
   * @return Whether the asOfJoin field is set.
   */
  boolean hasAsOfJoin();
  /**
   * <code>.spark.connect.AsOfJoin as_of_join = 39;</code>
   * @return The asOfJoin.
   */
  org.apache.spark.connect.proto.AsOfJoin getAsOfJoin();
  /**
   * <code>.spark.connect.AsOfJoin as_of_join = 39;</code>
   */
  org.apache.spark.connect.proto.AsOfJoinOrBuilder getAsOfJoinOrBuilder();

  /**
   * <pre>
   * NA functions
   * </pre>
   *
   * <code>.spark.connect.NAFill fill_na = 90;</code>
   * @return Whether the fillNa field is set.
   */
  boolean hasFillNa();
  /**
   * <pre>
   * NA functions
   * </pre>
   *
   * <code>.spark.connect.NAFill fill_na = 90;</code>
   * @return The fillNa.
   */
  org.apache.spark.connect.proto.NAFill getFillNa();
  /**
   * <pre>
   * NA functions
   * </pre>
   *
   * <code>.spark.connect.NAFill fill_na = 90;</code>
   */
  org.apache.spark.connect.proto.NAFillOrBuilder getFillNaOrBuilder();

  /**
   * <code>.spark.connect.NADrop drop_na = 91;</code>
   * @return Whether the dropNa field is set.
   */
  boolean hasDropNa();
  /**
   * <code>.spark.connect.NADrop drop_na = 91;</code>
   * @return The dropNa.
   */
  org.apache.spark.connect.proto.NADrop getDropNa();
  /**
   * <code>.spark.connect.NADrop drop_na = 91;</code>
   */
  org.apache.spark.connect.proto.NADropOrBuilder getDropNaOrBuilder();

  /**
   * <code>.spark.connect.NAReplace replace = 92;</code>
   * @return Whether the replace field is set.
   */
  boolean hasReplace();
  /**
   * <code>.spark.connect.NAReplace replace = 92;</code>
   * @return The replace.
   */
  org.apache.spark.connect.proto.NAReplace getReplace();
  /**
   * <code>.spark.connect.NAReplace replace = 92;</code>
   */
  org.apache.spark.connect.proto.NAReplaceOrBuilder getReplaceOrBuilder();

  /**
   * <pre>
   * stat functions
   * </pre>
   *
   * <code>.spark.connect.StatSummary summary = 100;</code>
   * @return Whether the summary field is set.
   */
  boolean hasSummary();
  /**
   * <pre>
   * stat functions
   * </pre>
   *
   * <code>.spark.connect.StatSummary summary = 100;</code>
   * @return The summary.
   */
  org.apache.spark.connect.proto.StatSummary getSummary();
  /**
   * <pre>
   * stat functions
   * </pre>
   *
   * <code>.spark.connect.StatSummary summary = 100;</code>
   */
  org.apache.spark.connect.proto.StatSummaryOrBuilder getSummaryOrBuilder();

  /**
   * <code>.spark.connect.StatCrosstab crosstab = 101;</code>
   * @return Whether the crosstab field is set.
   */
  boolean hasCrosstab();
  /**
   * <code>.spark.connect.StatCrosstab crosstab = 101;</code>
   * @return The crosstab.
   */
  org.apache.spark.connect.proto.StatCrosstab getCrosstab();
  /**
   * <code>.spark.connect.StatCrosstab crosstab = 101;</code>
   */
  org.apache.spark.connect.proto.StatCrosstabOrBuilder getCrosstabOrBuilder();

  /**
   * <code>.spark.connect.StatDescribe describe = 102;</code>
   * @return Whether the describe field is set.
   */
  boolean hasDescribe();
  /**
   * <code>.spark.connect.StatDescribe describe = 102;</code>
   * @return The describe.
   */
  org.apache.spark.connect.proto.StatDescribe getDescribe();
  /**
   * <code>.spark.connect.StatDescribe describe = 102;</code>
   */
  org.apache.spark.connect.proto.StatDescribeOrBuilder getDescribeOrBuilder();

  /**
   * <code>.spark.connect.StatCov cov = 103;</code>
   * @return Whether the cov field is set.
   */
  boolean hasCov();
  /**
   * <code>.spark.connect.StatCov cov = 103;</code>
   * @return The cov.
   */
  org.apache.spark.connect.proto.StatCov getCov();
  /**
   * <code>.spark.connect.StatCov cov = 103;</code>
   */
  org.apache.spark.connect.proto.StatCovOrBuilder getCovOrBuilder();

  /**
   * <code>.spark.connect.StatCorr corr = 104;</code>
   * @return Whether the corr field is set.
   */
  boolean hasCorr();
  /**
   * <code>.spark.connect.StatCorr corr = 104;</code>
   * @return The corr.
   */
  org.apache.spark.connect.proto.StatCorr getCorr();
  /**
   * <code>.spark.connect.StatCorr corr = 104;</code>
   */
  org.apache.spark.connect.proto.StatCorrOrBuilder getCorrOrBuilder();

  /**
   * <code>.spark.connect.StatApproxQuantile approx_quantile = 105;</code>
   * @return Whether the approxQuantile field is set.
   */
  boolean hasApproxQuantile();
  /**
   * <code>.spark.connect.StatApproxQuantile approx_quantile = 105;</code>
   * @return The approxQuantile.
   */
  org.apache.spark.connect.proto.StatApproxQuantile getApproxQuantile();
  /**
   * <code>.spark.connect.StatApproxQuantile approx_quantile = 105;</code>
   */
  org.apache.spark.connect.proto.StatApproxQuantileOrBuilder getApproxQuantileOrBuilder();

  /**
   * <code>.spark.connect.StatFreqItems freq_items = 106;</code>
   * @return Whether the freqItems field is set.
   */
  boolean hasFreqItems();
  /**
   * <code>.spark.connect.StatFreqItems freq_items = 106;</code>
   * @return The freqItems.
   */
  org.apache.spark.connect.proto.StatFreqItems getFreqItems();
  /**
   * <code>.spark.connect.StatFreqItems freq_items = 106;</code>
   */
  org.apache.spark.connect.proto.StatFreqItemsOrBuilder getFreqItemsOrBuilder();

  /**
   * <code>.spark.connect.StatSampleBy sample_by = 107;</code>
   * @return Whether the sampleBy field is set.
   */
  boolean hasSampleBy();
  /**
   * <code>.spark.connect.StatSampleBy sample_by = 107;</code>
   * @return The sampleBy.
   */
  org.apache.spark.connect.proto.StatSampleBy getSampleBy();
  /**
   * <code>.spark.connect.StatSampleBy sample_by = 107;</code>
   */
  org.apache.spark.connect.proto.StatSampleByOrBuilder getSampleByOrBuilder();

  /**
   * <pre>
   * Catalog API (experimental / unstable)
   * </pre>
   *
   * <code>.spark.connect.Catalog catalog = 200;</code>
   * @return Whether the catalog field is set.
   */
  boolean hasCatalog();
  /**
   * <pre>
   * Catalog API (experimental / unstable)
   * </pre>
   *
   * <code>.spark.connect.Catalog catalog = 200;</code>
   * @return The catalog.
   */
  org.apache.spark.connect.proto.Catalog getCatalog();
  /**
   * <pre>
   * Catalog API (experimental / unstable)
   * </pre>
   *
   * <code>.spark.connect.Catalog catalog = 200;</code>
   */
  org.apache.spark.connect.proto.CatalogOrBuilder getCatalogOrBuilder();

  /**
   * <pre>
   * This field is used to mark extensions to the protocol. When plugins generate arbitrary
   * relations they can add them here. During the planning the correct resolution is done.
   * </pre>
   *
   * <code>.google.protobuf.Any extension = 998;</code>
   * @return Whether the extension field is set.
   */
  boolean hasExtension();
  /**
   * <pre>
   * This field is used to mark extensions to the protocol. When plugins generate arbitrary
   * relations they can add them here. During the planning the correct resolution is done.
   * </pre>
   *
   * <code>.google.protobuf.Any extension = 998;</code>
   * @return The extension.
   */
  com.google.protobuf.Any getExtension();
  /**
   * <pre>
   * This field is used to mark extensions to the protocol. When plugins generate arbitrary
   * relations they can add them here. During the planning the correct resolution is done.
   * </pre>
   *
   * <code>.google.protobuf.Any extension = 998;</code>
   */
  com.google.protobuf.AnyOrBuilder getExtensionOrBuilder();

  /**
   * <code>.spark.connect.Unknown unknown = 999;</code>
   * @return Whether the unknown field is set.
   */
  boolean hasUnknown();
  /**
   * <code>.spark.connect.Unknown unknown = 999;</code>
   * @return The unknown.
   */
  org.apache.spark.connect.proto.Unknown getUnknown();
  /**
   * <code>.spark.connect.Unknown unknown = 999;</code>
   */
  org.apache.spark.connect.proto.UnknownOrBuilder getUnknownOrBuilder();

  org.apache.spark.connect.proto.Relation.RelTypeCase getRelTypeCase();
}
