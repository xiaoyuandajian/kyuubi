// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: spark/connect/commands.proto

package org.apache.kyuubi.engine.spark.connect.proto;

/**
 * <pre>
 * Response for commands on the streaming query manager.
 * </pre>
 *
 * Protobuf type {@code spark.connect.StreamingQueryManagerCommandResult}
 */
public final class StreamingQueryManagerCommandResult extends
    com.google.protobuf.GeneratedMessageV3 implements
    // @@protoc_insertion_point(message_implements:spark.connect.StreamingQueryManagerCommandResult)
    StreamingQueryManagerCommandResultOrBuilder {
private static final long serialVersionUID = 0L;
  // Use StreamingQueryManagerCommandResult.newBuilder() to construct.
  private StreamingQueryManagerCommandResult(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
    super(builder);
  }
  private StreamingQueryManagerCommandResult() {
  }

  @Override
  @SuppressWarnings({"unused"})
  protected Object newInstance(
      UnusedPrivateParameter unused) {
    return new StreamingQueryManagerCommandResult();
  }

  public static final com.google.protobuf.Descriptors.Descriptor
      getDescriptor() {
    return org.apache.spark.connect.proto.Commands.internal_static_spark_connect_StreamingQueryManagerCommandResult_descriptor;
  }

  @Override
  protected FieldAccessorTable
      internalGetFieldAccessorTable() {
    return org.apache.spark.connect.proto.Commands.internal_static_spark_connect_StreamingQueryManagerCommandResult_fieldAccessorTable
        .ensureFieldAccessorsInitialized(
            org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.class, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.Builder.class);
  }

  public interface ActiveResultOrBuilder extends
      // @@protoc_insertion_point(interface_extends:spark.connect.StreamingQueryManagerCommandResult.ActiveResult)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance active_queries = 1;</code>
     */
    java.util.List<org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance> 
        getActiveQueriesList();
    /**
     * <code>repeated .spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance active_queries = 1;</code>
     */
    org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance getActiveQueries(int index);
    /**
     * <code>repeated .spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance active_queries = 1;</code>
     */
    int getActiveQueriesCount();
    /**
     * <code>repeated .spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance active_queries = 1;</code>
     */
    java.util.List<? extends org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstanceOrBuilder> 
        getActiveQueriesOrBuilderList();
    /**
     * <code>repeated .spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance active_queries = 1;</code>
     */
    org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstanceOrBuilder getActiveQueriesOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code spark.connect.StreamingQueryManagerCommandResult.ActiveResult}
   */
  public static final class ActiveResult extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:spark.connect.StreamingQueryManagerCommandResult.ActiveResult)
      ActiveResultOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ActiveResult.newBuilder() to construct.
    private ActiveResult(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ActiveResult() {
      activeQueries_ = java.util.Collections.emptyList();
    }

    @Override
    @SuppressWarnings({"unused"})
    protected Object newInstance(
        UnusedPrivateParameter unused) {
      return new ActiveResult();
    }

    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.spark.connect.proto.Commands.internal_static_spark_connect_StreamingQueryManagerCommandResult_ActiveResult_descriptor;
    }

    @Override
    protected FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.spark.connect.proto.Commands.internal_static_spark_connect_StreamingQueryManagerCommandResult_ActiveResult_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult.class, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult.Builder.class);
    }

    public static final int ACTIVE_QUERIES_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private java.util.List<org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance> activeQueries_;
    /**
     * <code>repeated .spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance active_queries = 1;</code>
     */
    @Override
    public java.util.List<org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance> getActiveQueriesList() {
      return activeQueries_;
    }
    /**
     * <code>repeated .spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance active_queries = 1;</code>
     */
    @Override
    public java.util.List<? extends org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstanceOrBuilder> 
        getActiveQueriesOrBuilderList() {
      return activeQueries_;
    }
    /**
     * <code>repeated .spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance active_queries = 1;</code>
     */
    @Override
    public int getActiveQueriesCount() {
      return activeQueries_.size();
    }
    /**
     * <code>repeated .spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance active_queries = 1;</code>
     */
    @Override
    public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance getActiveQueries(int index) {
      return activeQueries_.get(index);
    }
    /**
     * <code>repeated .spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance active_queries = 1;</code>
     */
    @Override
    public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstanceOrBuilder getActiveQueriesOrBuilder(
        int index) {
      return activeQueries_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    @Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < activeQueries_.size(); i++) {
        output.writeMessage(1, activeQueries_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    @Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < activeQueries_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, activeQueries_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @Override
    public boolean equals(final Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult)) {
        return super.equals(obj);
      }
      org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult other = (org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult) obj;

      if (!getActiveQueriesList()
          .equals(other.getActiveQueriesList())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getActiveQueriesCount() > 0) {
        hash = (37 * hash) + ACTIVE_QUERIES_FIELD_NUMBER;
        hash = (53 * hash) + getActiveQueriesList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @Override
    protected Builder newBuilderForType(
        BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code spark.connect.StreamingQueryManagerCommandResult.ActiveResult}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:spark.connect.StreamingQueryManagerCommandResult.ActiveResult)
        org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResultOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.spark.connect.proto.Commands.internal_static_spark_connect_StreamingQueryManagerCommandResult_ActiveResult_descriptor;
      }

      @Override
      protected FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.spark.connect.proto.Commands.internal_static_spark_connect_StreamingQueryManagerCommandResult_ActiveResult_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult.class, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult.Builder.class);
      }

      // Construct using org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult.newBuilder()
      private Builder() {

      }

      private Builder(
          BuilderParent parent) {
        super(parent);

      }
      @Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        if (activeQueriesBuilder_ == null) {
          activeQueries_ = java.util.Collections.emptyList();
        } else {
          activeQueries_ = null;
          activeQueriesBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      @Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.spark.connect.proto.Commands.internal_static_spark_connect_StreamingQueryManagerCommandResult_ActiveResult_descriptor;
      }

      @Override
      public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult getDefaultInstanceForType() {
        return org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult.getDefaultInstance();
      }

      @Override
      public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult build() {
        org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @Override
      public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult buildPartial() {
        org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult result = new org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult result) {
        if (activeQueriesBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0)) {
            activeQueries_ = java.util.Collections.unmodifiableList(activeQueries_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.activeQueries_ = activeQueries_;
        } else {
          result.activeQueries_ = activeQueriesBuilder_.build();
        }
      }

      private void buildPartial0(org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult result) {
        int from_bitField0_ = bitField0_;
      }

      @Override
      public Builder clone() {
        return super.clone();
      }
      @Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return super.setField(field, value);
      }
      @Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return super.addRepeatedField(field, value);
      }
      @Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult) {
          return mergeFrom((org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult other) {
        if (other == org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult.getDefaultInstance()) return this;
        if (activeQueriesBuilder_ == null) {
          if (!other.activeQueries_.isEmpty()) {
            if (activeQueries_.isEmpty()) {
              activeQueries_ = other.activeQueries_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureActiveQueriesIsMutable();
              activeQueries_.addAll(other.activeQueries_);
            }
            onChanged();
          }
        } else {
          if (!other.activeQueries_.isEmpty()) {
            if (activeQueriesBuilder_.isEmpty()) {
              activeQueriesBuilder_.dispose();
              activeQueriesBuilder_ = null;
              activeQueries_ = other.activeQueries_;
              bitField0_ = (bitField0_ & ~0x00000001);
              activeQueriesBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getActiveQueriesFieldBuilder() : null;
            } else {
              activeQueriesBuilder_.addAllMessages(other.activeQueries_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @Override
      public final boolean isInitialized() {
        return true;
      }

      @Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance m =
                    input.readMessage(
                        org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance.parser(),
                        extensionRegistry);
                if (activeQueriesBuilder_ == null) {
                  ensureActiveQueriesIsMutable();
                  activeQueries_.add(m);
                } else {
                  activeQueriesBuilder_.addMessage(m);
                }
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private java.util.List<org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance> activeQueries_ =
        java.util.Collections.emptyList();
      private void ensureActiveQueriesIsMutable() {
        if (!((bitField0_ & 0x00000001) != 0)) {
          activeQueries_ = new java.util.ArrayList<org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance>(activeQueries_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance.Builder, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstanceOrBuilder> activeQueriesBuilder_;

      /**
       * <code>repeated .spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance active_queries = 1;</code>
       */
      public java.util.List<org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance> getActiveQueriesList() {
        if (activeQueriesBuilder_ == null) {
          return java.util.Collections.unmodifiableList(activeQueries_);
        } else {
          return activeQueriesBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance active_queries = 1;</code>
       */
      public int getActiveQueriesCount() {
        if (activeQueriesBuilder_ == null) {
          return activeQueries_.size();
        } else {
          return activeQueriesBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance active_queries = 1;</code>
       */
      public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance getActiveQueries(int index) {
        if (activeQueriesBuilder_ == null) {
          return activeQueries_.get(index);
        } else {
          return activeQueriesBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance active_queries = 1;</code>
       */
      public Builder setActiveQueries(
          int index, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance value) {
        if (activeQueriesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureActiveQueriesIsMutable();
          activeQueries_.set(index, value);
          onChanged();
        } else {
          activeQueriesBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance active_queries = 1;</code>
       */
      public Builder setActiveQueries(
          int index, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance.Builder builderForValue) {
        if (activeQueriesBuilder_ == null) {
          ensureActiveQueriesIsMutable();
          activeQueries_.set(index, builderForValue.build());
          onChanged();
        } else {
          activeQueriesBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance active_queries = 1;</code>
       */
      public Builder addActiveQueries(org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance value) {
        if (activeQueriesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureActiveQueriesIsMutable();
          activeQueries_.add(value);
          onChanged();
        } else {
          activeQueriesBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance active_queries = 1;</code>
       */
      public Builder addActiveQueries(
          int index, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance value) {
        if (activeQueriesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureActiveQueriesIsMutable();
          activeQueries_.add(index, value);
          onChanged();
        } else {
          activeQueriesBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance active_queries = 1;</code>
       */
      public Builder addActiveQueries(
          org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance.Builder builderForValue) {
        if (activeQueriesBuilder_ == null) {
          ensureActiveQueriesIsMutable();
          activeQueries_.add(builderForValue.build());
          onChanged();
        } else {
          activeQueriesBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance active_queries = 1;</code>
       */
      public Builder addActiveQueries(
          int index, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance.Builder builderForValue) {
        if (activeQueriesBuilder_ == null) {
          ensureActiveQueriesIsMutable();
          activeQueries_.add(index, builderForValue.build());
          onChanged();
        } else {
          activeQueriesBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance active_queries = 1;</code>
       */
      public Builder addAllActiveQueries(
          Iterable<? extends org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance> values) {
        if (activeQueriesBuilder_ == null) {
          ensureActiveQueriesIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, activeQueries_);
          onChanged();
        } else {
          activeQueriesBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance active_queries = 1;</code>
       */
      public Builder clearActiveQueries() {
        if (activeQueriesBuilder_ == null) {
          activeQueries_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          activeQueriesBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance active_queries = 1;</code>
       */
      public Builder removeActiveQueries(int index) {
        if (activeQueriesBuilder_ == null) {
          ensureActiveQueriesIsMutable();
          activeQueries_.remove(index);
          onChanged();
        } else {
          activeQueriesBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance active_queries = 1;</code>
       */
      public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance.Builder getActiveQueriesBuilder(
          int index) {
        return getActiveQueriesFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance active_queries = 1;</code>
       */
      public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstanceOrBuilder getActiveQueriesOrBuilder(
          int index) {
        if (activeQueriesBuilder_ == null) {
          return activeQueries_.get(index);  } else {
          return activeQueriesBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance active_queries = 1;</code>
       */
      public java.util.List<? extends org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstanceOrBuilder> 
           getActiveQueriesOrBuilderList() {
        if (activeQueriesBuilder_ != null) {
          return activeQueriesBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(activeQueries_);
        }
      }
      /**
       * <code>repeated .spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance active_queries = 1;</code>
       */
      public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance.Builder addActiveQueriesBuilder() {
        return getActiveQueriesFieldBuilder().addBuilder(
            org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance.getDefaultInstance());
      }
      /**
       * <code>repeated .spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance active_queries = 1;</code>
       */
      public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance.Builder addActiveQueriesBuilder(
          int index) {
        return getActiveQueriesFieldBuilder().addBuilder(
            index, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance.getDefaultInstance());
      }
      /**
       * <code>repeated .spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance active_queries = 1;</code>
       */
      public java.util.List<org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance.Builder> 
           getActiveQueriesBuilderList() {
        return getActiveQueriesFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance.Builder, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstanceOrBuilder> 
          getActiveQueriesFieldBuilder() {
        if (activeQueriesBuilder_ == null) {
          activeQueriesBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance.Builder, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstanceOrBuilder>(
                  activeQueries_,
                  ((bitField0_ & 0x00000001) != 0),
                  getParentForChildren(),
                  isClean());
          activeQueries_ = null;
        }
        return activeQueriesBuilder_;
      }
      @Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:spark.connect.StreamingQueryManagerCommandResult.ActiveResult)
    }

    // @@protoc_insertion_point(class_scope:spark.connect.StreamingQueryManagerCommandResult.ActiveResult)
    private static final org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult();
    }

    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<ActiveResult>
        PARSER = new com.google.protobuf.AbstractParser<ActiveResult>() {
      @Override
      public ActiveResult parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<ActiveResult> parser() {
      return PARSER;
    }

    @Override
    public com.google.protobuf.Parser<ActiveResult> getParserForType() {
      return PARSER;
    }

    @Override
    public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface StreamingQueryInstanceOrBuilder extends
      // @@protoc_insertion_point(interface_extends:spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * (Required) The id and runId of this query.
     * </pre>
     *
     * <code>.spark.connect.StreamingQueryInstanceId id = 1;</code>
     * @return Whether the id field is set.
     */
    boolean hasId();
    /**
     * <pre>
     * (Required) The id and runId of this query.
     * </pre>
     *
     * <code>.spark.connect.StreamingQueryInstanceId id = 1;</code>
     * @return The id.
     */
    org.apache.spark.connect.proto.StreamingQueryInstanceId getId();
    /**
     * <pre>
     * (Required) The id and runId of this query.
     * </pre>
     *
     * <code>.spark.connect.StreamingQueryInstanceId id = 1;</code>
     */
    org.apache.spark.connect.proto.StreamingQueryInstanceIdOrBuilder getIdOrBuilder();

    /**
     * <pre>
     * (Optional) The name of this query.
     * </pre>
     *
     * <code>optional string name = 2;</code>
     * @return Whether the name field is set.
     */
    boolean hasName();
    /**
     * <pre>
     * (Optional) The name of this query.
     * </pre>
     *
     * <code>optional string name = 2;</code>
     * @return The name.
     */
    String getName();
    /**
     * <pre>
     * (Optional) The name of this query.
     * </pre>
     *
     * <code>optional string name = 2;</code>
     * @return The bytes for name.
     */
    com.google.protobuf.ByteString
        getNameBytes();
  }
  /**
   * Protobuf type {@code spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance}
   */
  public static final class StreamingQueryInstance extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance)
      StreamingQueryInstanceOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use StreamingQueryInstance.newBuilder() to construct.
    private StreamingQueryInstance(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private StreamingQueryInstance() {
      name_ = "";
    }

    @Override
    @SuppressWarnings({"unused"})
    protected Object newInstance(
        UnusedPrivateParameter unused) {
      return new StreamingQueryInstance();
    }

    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.spark.connect.proto.Commands.internal_static_spark_connect_StreamingQueryManagerCommandResult_StreamingQueryInstance_descriptor;
    }

    @Override
    protected FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.spark.connect.proto.Commands.internal_static_spark_connect_StreamingQueryManagerCommandResult_StreamingQueryInstance_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance.class, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance.Builder.class);
    }

    private int bitField0_;
    public static final int ID_FIELD_NUMBER = 1;
    private org.apache.spark.connect.proto.StreamingQueryInstanceId id_;
    /**
     * <pre>
     * (Required) The id and runId of this query.
     * </pre>
     *
     * <code>.spark.connect.StreamingQueryInstanceId id = 1;</code>
     * @return Whether the id field is set.
     */
    @Override
    public boolean hasId() {
      return id_ != null;
    }
    /**
     * <pre>
     * (Required) The id and runId of this query.
     * </pre>
     *
     * <code>.spark.connect.StreamingQueryInstanceId id = 1;</code>
     * @return The id.
     */
    @Override
    public org.apache.spark.connect.proto.StreamingQueryInstanceId getId() {
      return id_ == null ? org.apache.spark.connect.proto.StreamingQueryInstanceId.getDefaultInstance() : id_;
    }
    /**
     * <pre>
     * (Required) The id and runId of this query.
     * </pre>
     *
     * <code>.spark.connect.StreamingQueryInstanceId id = 1;</code>
     */
    @Override
    public org.apache.spark.connect.proto.StreamingQueryInstanceIdOrBuilder getIdOrBuilder() {
      return id_ == null ? org.apache.spark.connect.proto.StreamingQueryInstanceId.getDefaultInstance() : id_;
    }

    public static final int NAME_FIELD_NUMBER = 2;
    @SuppressWarnings("serial")
    private volatile Object name_ = "";
    /**
     * <pre>
     * (Optional) The name of this query.
     * </pre>
     *
     * <code>optional string name = 2;</code>
     * @return Whether the name field is set.
     */
    @Override
    public boolean hasName() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     * <pre>
     * (Optional) The name of this query.
     * </pre>
     *
     * <code>optional string name = 2;</code>
     * @return The name.
     */
    @Override
    public String getName() {
      Object ref = name_;
      if (ref instanceof String) {
        return (String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        String s = bs.toStringUtf8();
        name_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * (Optional) The name of this query.
     * </pre>
     *
     * <code>optional string name = 2;</code>
     * @return The bytes for name.
     */
    @Override
    public com.google.protobuf.ByteString
        getNameBytes() {
      Object ref = name_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (String) ref);
        name_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    @Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (id_ != null) {
        output.writeMessage(1, getId());
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, name_);
      }
      getUnknownFields().writeTo(output);
    }

    @Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (id_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getId());
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, name_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @Override
    public boolean equals(final Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance)) {
        return super.equals(obj);
      }
      org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance other = (org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance) obj;

      if (hasId() != other.hasId()) return false;
      if (hasId()) {
        if (!getId()
            .equals(other.getId())) return false;
      }
      if (hasName() != other.hasName()) return false;
      if (hasName()) {
        if (!getName()
            .equals(other.getName())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasId()) {
        hash = (37 * hash) + ID_FIELD_NUMBER;
        hash = (53 * hash) + getId().hashCode();
      }
      if (hasName()) {
        hash = (37 * hash) + NAME_FIELD_NUMBER;
        hash = (53 * hash) + getName().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @Override
    protected Builder newBuilderForType(
        BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance)
        org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstanceOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.spark.connect.proto.Commands.internal_static_spark_connect_StreamingQueryManagerCommandResult_StreamingQueryInstance_descriptor;
      }

      @Override
      protected FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.spark.connect.proto.Commands.internal_static_spark_connect_StreamingQueryManagerCommandResult_StreamingQueryInstance_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance.class, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance.Builder.class);
      }

      // Construct using org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance.newBuilder()
      private Builder() {

      }

      private Builder(
          BuilderParent parent) {
        super(parent);

      }
      @Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        id_ = null;
        if (idBuilder_ != null) {
          idBuilder_.dispose();
          idBuilder_ = null;
        }
        name_ = "";
        return this;
      }

      @Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.spark.connect.proto.Commands.internal_static_spark_connect_StreamingQueryManagerCommandResult_StreamingQueryInstance_descriptor;
      }

      @Override
      public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance getDefaultInstanceForType() {
        return org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance.getDefaultInstance();
      }

      @Override
      public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance build() {
        org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @Override
      public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance buildPartial() {
        org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance result = new org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance result) {
        int from_bitField0_ = bitField0_;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.id_ = idBuilder_ == null
              ? id_
              : idBuilder_.build();
        }
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.name_ = name_;
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @Override
      public Builder clone() {
        return super.clone();
      }
      @Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return super.setField(field, value);
      }
      @Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return super.addRepeatedField(field, value);
      }
      @Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance) {
          return mergeFrom((org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance other) {
        if (other == org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance.getDefaultInstance()) return this;
        if (other.hasId()) {
          mergeId(other.getId());
        }
        if (other.hasName()) {
          name_ = other.name_;
          bitField0_ |= 0x00000002;
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @Override
      public final boolean isInitialized() {
        return true;
      }

      @Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getIdFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                name_ = input.readStringRequireUtf8();
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private org.apache.spark.connect.proto.StreamingQueryInstanceId id_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.spark.connect.proto.StreamingQueryInstanceId, org.apache.spark.connect.proto.StreamingQueryInstanceId.Builder, org.apache.spark.connect.proto.StreamingQueryInstanceIdOrBuilder> idBuilder_;
      /**
       * <pre>
       * (Required) The id and runId of this query.
       * </pre>
       *
       * <code>.spark.connect.StreamingQueryInstanceId id = 1;</code>
       * @return Whether the id field is set.
       */
      public boolean hasId() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <pre>
       * (Required) The id and runId of this query.
       * </pre>
       *
       * <code>.spark.connect.StreamingQueryInstanceId id = 1;</code>
       * @return The id.
       */
      public org.apache.spark.connect.proto.StreamingQueryInstanceId getId() {
        if (idBuilder_ == null) {
          return id_ == null ? org.apache.spark.connect.proto.StreamingQueryInstanceId.getDefaultInstance() : id_;
        } else {
          return idBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * (Required) The id and runId of this query.
       * </pre>
       *
       * <code>.spark.connect.StreamingQueryInstanceId id = 1;</code>
       */
      public Builder setId(org.apache.spark.connect.proto.StreamingQueryInstanceId value) {
        if (idBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          id_ = value;
        } else {
          idBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * (Required) The id and runId of this query.
       * </pre>
       *
       * <code>.spark.connect.StreamingQueryInstanceId id = 1;</code>
       */
      public Builder setId(
          org.apache.spark.connect.proto.StreamingQueryInstanceId.Builder builderForValue) {
        if (idBuilder_ == null) {
          id_ = builderForValue.build();
        } else {
          idBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * (Required) The id and runId of this query.
       * </pre>
       *
       * <code>.spark.connect.StreamingQueryInstanceId id = 1;</code>
       */
      public Builder mergeId(org.apache.spark.connect.proto.StreamingQueryInstanceId value) {
        if (idBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            id_ != null &&
            id_ != org.apache.spark.connect.proto.StreamingQueryInstanceId.getDefaultInstance()) {
            getIdBuilder().mergeFrom(value);
          } else {
            id_ = value;
          }
        } else {
          idBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * (Required) The id and runId of this query.
       * </pre>
       *
       * <code>.spark.connect.StreamingQueryInstanceId id = 1;</code>
       */
      public Builder clearId() {
        bitField0_ = (bitField0_ & ~0x00000001);
        id_ = null;
        if (idBuilder_ != null) {
          idBuilder_.dispose();
          idBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <pre>
       * (Required) The id and runId of this query.
       * </pre>
       *
       * <code>.spark.connect.StreamingQueryInstanceId id = 1;</code>
       */
      public org.apache.spark.connect.proto.StreamingQueryInstanceId.Builder getIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getIdFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * (Required) The id and runId of this query.
       * </pre>
       *
       * <code>.spark.connect.StreamingQueryInstanceId id = 1;</code>
       */
      public org.apache.spark.connect.proto.StreamingQueryInstanceIdOrBuilder getIdOrBuilder() {
        if (idBuilder_ != null) {
          return idBuilder_.getMessageOrBuilder();
        } else {
          return id_ == null ?
              org.apache.spark.connect.proto.StreamingQueryInstanceId.getDefaultInstance() : id_;
        }
      }
      /**
       * <pre>
       * (Required) The id and runId of this query.
       * </pre>
       *
       * <code>.spark.connect.StreamingQueryInstanceId id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.spark.connect.proto.StreamingQueryInstanceId, org.apache.spark.connect.proto.StreamingQueryInstanceId.Builder, org.apache.spark.connect.proto.StreamingQueryInstanceIdOrBuilder> 
          getIdFieldBuilder() {
        if (idBuilder_ == null) {
          idBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.spark.connect.proto.StreamingQueryInstanceId, org.apache.spark.connect.proto.StreamingQueryInstanceId.Builder, org.apache.spark.connect.proto.StreamingQueryInstanceIdOrBuilder>(
                  getId(),
                  getParentForChildren(),
                  isClean());
          id_ = null;
        }
        return idBuilder_;
      }

      private Object name_ = "";
      /**
       * <pre>
       * (Optional) The name of this query.
       * </pre>
       *
       * <code>optional string name = 2;</code>
       * @return Whether the name field is set.
       */
      public boolean hasName() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       * <pre>
       * (Optional) The name of this query.
       * </pre>
       *
       * <code>optional string name = 2;</code>
       * @return The name.
       */
      public String getName() {
        Object ref = name_;
        if (!(ref instanceof String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          String s = bs.toStringUtf8();
          name_ = s;
          return s;
        } else {
          return (String) ref;
        }
      }
      /**
       * <pre>
       * (Optional) The name of this query.
       * </pre>
       *
       * <code>optional string name = 2;</code>
       * @return The bytes for name.
       */
      public com.google.protobuf.ByteString
          getNameBytes() {
        Object ref = name_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (String) ref);
          name_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * (Optional) The name of this query.
       * </pre>
       *
       * <code>optional string name = 2;</code>
       * @param value The name to set.
       * @return This builder for chaining.
       */
      public Builder setName(
          String value) {
        if (value == null) { throw new NullPointerException(); }
        name_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * (Optional) The name of this query.
       * </pre>
       *
       * <code>optional string name = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearName() {
        name_ = getDefaultInstance().getName();
        bitField0_ = (bitField0_ & ~0x00000002);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * (Optional) The name of this query.
       * </pre>
       *
       * <code>optional string name = 2;</code>
       * @param value The bytes for name to set.
       * @return This builder for chaining.
       */
      public Builder setNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        checkByteStringIsUtf8(value);
        name_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      @Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance)
    }

    // @@protoc_insertion_point(class_scope:spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance)
    private static final org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance();
    }

    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<StreamingQueryInstance>
        PARSER = new com.google.protobuf.AbstractParser<StreamingQueryInstance>() {
      @Override
      public StreamingQueryInstance parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<StreamingQueryInstance> parser() {
      return PARSER;
    }

    @Override
    public com.google.protobuf.Parser<StreamingQueryInstance> getParserForType() {
      return PARSER;
    }

    @Override
    public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface AwaitAnyTerminationResultOrBuilder extends
      // @@protoc_insertion_point(interface_extends:spark.connect.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>bool terminated = 1;</code>
     * @return The terminated.
     */
    boolean getTerminated();
  }
  /**
   * Protobuf type {@code spark.connect.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult}
   */
  public static final class AwaitAnyTerminationResult extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:spark.connect.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult)
      AwaitAnyTerminationResultOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use AwaitAnyTerminationResult.newBuilder() to construct.
    private AwaitAnyTerminationResult(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private AwaitAnyTerminationResult() {
    }

    @Override
    @SuppressWarnings({"unused"})
    protected Object newInstance(
        UnusedPrivateParameter unused) {
      return new AwaitAnyTerminationResult();
    }

    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.spark.connect.proto.Commands.internal_static_spark_connect_StreamingQueryManagerCommandResult_AwaitAnyTerminationResult_descriptor;
    }

    @Override
    protected FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.spark.connect.proto.Commands.internal_static_spark_connect_StreamingQueryManagerCommandResult_AwaitAnyTerminationResult_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult.class, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult.Builder.class);
    }

    public static final int TERMINATED_FIELD_NUMBER = 1;
    private boolean terminated_ = false;
    /**
     * <code>bool terminated = 1;</code>
     * @return The terminated.
     */
    @Override
    public boolean getTerminated() {
      return terminated_;
    }

    private byte memoizedIsInitialized = -1;
    @Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (terminated_ != false) {
        output.writeBool(1, terminated_);
      }
      getUnknownFields().writeTo(output);
    }

    @Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (terminated_ != false) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(1, terminated_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @Override
    public boolean equals(final Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult)) {
        return super.equals(obj);
      }
      org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult other = (org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult) obj;

      if (getTerminated()
          != other.getTerminated()) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + TERMINATED_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
          getTerminated());
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @Override
    protected Builder newBuilderForType(
        BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code spark.connect.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:spark.connect.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult)
        org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResultOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.spark.connect.proto.Commands.internal_static_spark_connect_StreamingQueryManagerCommandResult_AwaitAnyTerminationResult_descriptor;
      }

      @Override
      protected FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.spark.connect.proto.Commands.internal_static_spark_connect_StreamingQueryManagerCommandResult_AwaitAnyTerminationResult_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult.class, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult.Builder.class);
      }

      // Construct using org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult.newBuilder()
      private Builder() {

      }

      private Builder(
          BuilderParent parent) {
        super(parent);

      }
      @Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        terminated_ = false;
        return this;
      }

      @Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.spark.connect.proto.Commands.internal_static_spark_connect_StreamingQueryManagerCommandResult_AwaitAnyTerminationResult_descriptor;
      }

      @Override
      public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult getDefaultInstanceForType() {
        return org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult.getDefaultInstance();
      }

      @Override
      public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult build() {
        org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @Override
      public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult buildPartial() {
        org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult result = new org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult result) {
        int from_bitField0_ = bitField0_;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.terminated_ = terminated_;
        }
      }

      @Override
      public Builder clone() {
        return super.clone();
      }
      @Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return super.setField(field, value);
      }
      @Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return super.addRepeatedField(field, value);
      }
      @Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult) {
          return mergeFrom((org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult other) {
        if (other == org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult.getDefaultInstance()) return this;
        if (other.getTerminated() != false) {
          setTerminated(other.getTerminated());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @Override
      public final boolean isInitialized() {
        return true;
      }

      @Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8: {
                terminated_ = input.readBool();
                bitField0_ |= 0x00000001;
                break;
              } // case 8
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private boolean terminated_ ;
      /**
       * <code>bool terminated = 1;</code>
       * @return The terminated.
       */
      @Override
      public boolean getTerminated() {
        return terminated_;
      }
      /**
       * <code>bool terminated = 1;</code>
       * @param value The terminated to set.
       * @return This builder for chaining.
       */
      public Builder setTerminated(boolean value) {

        terminated_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>bool terminated = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearTerminated() {
        bitField0_ = (bitField0_ & ~0x00000001);
        terminated_ = false;
        onChanged();
        return this;
      }
      @Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:spark.connect.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult)
    }

    // @@protoc_insertion_point(class_scope:spark.connect.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult)
    private static final org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult();
    }

    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<AwaitAnyTerminationResult>
        PARSER = new com.google.protobuf.AbstractParser<AwaitAnyTerminationResult>() {
      @Override
      public AwaitAnyTerminationResult parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<AwaitAnyTerminationResult> parser() {
      return PARSER;
    }

    @Override
    public com.google.protobuf.Parser<AwaitAnyTerminationResult> getParserForType() {
      return PARSER;
    }

    @Override
    public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface StreamingQueryListenerInstanceOrBuilder extends
      // @@protoc_insertion_point(interface_extends:spark.connect.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>bytes listener_payload = 1;</code>
     * @return The listenerPayload.
     */
    com.google.protobuf.ByteString getListenerPayload();
  }
  /**
   * Protobuf type {@code spark.connect.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance}
   */
  public static final class StreamingQueryListenerInstance extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:spark.connect.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance)
      StreamingQueryListenerInstanceOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use StreamingQueryListenerInstance.newBuilder() to construct.
    private StreamingQueryListenerInstance(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private StreamingQueryListenerInstance() {
      listenerPayload_ = com.google.protobuf.ByteString.EMPTY;
    }

    @Override
    @SuppressWarnings({"unused"})
    protected Object newInstance(
        UnusedPrivateParameter unused) {
      return new StreamingQueryListenerInstance();
    }

    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.spark.connect.proto.Commands.internal_static_spark_connect_StreamingQueryManagerCommandResult_StreamingQueryListenerInstance_descriptor;
    }

    @Override
    protected FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.spark.connect.proto.Commands.internal_static_spark_connect_StreamingQueryManagerCommandResult_StreamingQueryListenerInstance_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance.class, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance.Builder.class);
    }

    public static final int LISTENER_PAYLOAD_FIELD_NUMBER = 1;
    private com.google.protobuf.ByteString listenerPayload_ = com.google.protobuf.ByteString.EMPTY;
    /**
     * <code>bytes listener_payload = 1;</code>
     * @return The listenerPayload.
     */
    @Override
    public com.google.protobuf.ByteString getListenerPayload() {
      return listenerPayload_;
    }

    private byte memoizedIsInitialized = -1;
    @Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (!listenerPayload_.isEmpty()) {
        output.writeBytes(1, listenerPayload_);
      }
      getUnknownFields().writeTo(output);
    }

    @Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (!listenerPayload_.isEmpty()) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, listenerPayload_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @Override
    public boolean equals(final Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance)) {
        return super.equals(obj);
      }
      org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance other = (org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance) obj;

      if (!getListenerPayload()
          .equals(other.getListenerPayload())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + LISTENER_PAYLOAD_FIELD_NUMBER;
      hash = (53 * hash) + getListenerPayload().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @Override
    protected Builder newBuilderForType(
        BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code spark.connect.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:spark.connect.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance)
        org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryListenerInstanceOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.spark.connect.proto.Commands.internal_static_spark_connect_StreamingQueryManagerCommandResult_StreamingQueryListenerInstance_descriptor;
      }

      @Override
      protected FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.spark.connect.proto.Commands.internal_static_spark_connect_StreamingQueryManagerCommandResult_StreamingQueryListenerInstance_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance.class, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance.Builder.class);
      }

      // Construct using org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance.newBuilder()
      private Builder() {

      }

      private Builder(
          BuilderParent parent) {
        super(parent);

      }
      @Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        listenerPayload_ = com.google.protobuf.ByteString.EMPTY;
        return this;
      }

      @Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.spark.connect.proto.Commands.internal_static_spark_connect_StreamingQueryManagerCommandResult_StreamingQueryListenerInstance_descriptor;
      }

      @Override
      public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance getDefaultInstanceForType() {
        return org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance.getDefaultInstance();
      }

      @Override
      public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance build() {
        org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @Override
      public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance buildPartial() {
        org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance result = new org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance result) {
        int from_bitField0_ = bitField0_;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.listenerPayload_ = listenerPayload_;
        }
      }

      @Override
      public Builder clone() {
        return super.clone();
      }
      @Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return super.setField(field, value);
      }
      @Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return super.addRepeatedField(field, value);
      }
      @Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance) {
          return mergeFrom((org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance other) {
        if (other == org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance.getDefaultInstance()) return this;
        if (other.getListenerPayload() != com.google.protobuf.ByteString.EMPTY) {
          setListenerPayload(other.getListenerPayload());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @Override
      public final boolean isInitialized() {
        return true;
      }

      @Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                listenerPayload_ = input.readBytes();
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private com.google.protobuf.ByteString listenerPayload_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>bytes listener_payload = 1;</code>
       * @return The listenerPayload.
       */
      @Override
      public com.google.protobuf.ByteString getListenerPayload() {
        return listenerPayload_;
      }
      /**
       * <code>bytes listener_payload = 1;</code>
       * @param value The listenerPayload to set.
       * @return This builder for chaining.
       */
      public Builder setListenerPayload(com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        listenerPayload_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <code>bytes listener_payload = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearListenerPayload() {
        bitField0_ = (bitField0_ & ~0x00000001);
        listenerPayload_ = getDefaultInstance().getListenerPayload();
        onChanged();
        return this;
      }
      @Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:spark.connect.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance)
    }

    // @@protoc_insertion_point(class_scope:spark.connect.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance)
    private static final org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance();
    }

    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<StreamingQueryListenerInstance>
        PARSER = new com.google.protobuf.AbstractParser<StreamingQueryListenerInstance>() {
      @Override
      public StreamingQueryListenerInstance parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<StreamingQueryListenerInstance> parser() {
      return PARSER;
    }

    @Override
    public com.google.protobuf.Parser<StreamingQueryListenerInstance> getParserForType() {
      return PARSER;
    }

    @Override
    public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ListStreamingQueryListenerResultOrBuilder extends
      // @@protoc_insertion_point(interface_extends:spark.connect.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * (Required) Reference IDs of listener instances.
     * </pre>
     *
     * <code>repeated string listener_ids = 1;</code>
     * @return A list containing the listenerIds.
     */
    java.util.List<String>
        getListenerIdsList();
    /**
     * <pre>
     * (Required) Reference IDs of listener instances.
     * </pre>
     *
     * <code>repeated string listener_ids = 1;</code>
     * @return The count of listenerIds.
     */
    int getListenerIdsCount();
    /**
     * <pre>
     * (Required) Reference IDs of listener instances.
     * </pre>
     *
     * <code>repeated string listener_ids = 1;</code>
     * @param index The index of the element to return.
     * @return The listenerIds at the given index.
     */
    String getListenerIds(int index);
    /**
     * <pre>
     * (Required) Reference IDs of listener instances.
     * </pre>
     *
     * <code>repeated string listener_ids = 1;</code>
     * @param index The index of the value to return.
     * @return The bytes of the listenerIds at the given index.
     */
    com.google.protobuf.ByteString
        getListenerIdsBytes(int index);
  }
  /**
   * Protobuf type {@code spark.connect.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult}
   */
  public static final class ListStreamingQueryListenerResult extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:spark.connect.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult)
      ListStreamingQueryListenerResultOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ListStreamingQueryListenerResult.newBuilder() to construct.
    private ListStreamingQueryListenerResult(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ListStreamingQueryListenerResult() {
      listenerIds_ =
          com.google.protobuf.LazyStringArrayList.emptyList();
    }

    @Override
    @SuppressWarnings({"unused"})
    protected Object newInstance(
        UnusedPrivateParameter unused) {
      return new ListStreamingQueryListenerResult();
    }

    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.spark.connect.proto.Commands.internal_static_spark_connect_StreamingQueryManagerCommandResult_ListStreamingQueryListenerResult_descriptor;
    }

    @Override
    protected FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.spark.connect.proto.Commands.internal_static_spark_connect_StreamingQueryManagerCommandResult_ListStreamingQueryListenerResult_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult.class, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult.Builder.class);
    }

    public static final int LISTENER_IDS_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private com.google.protobuf.LazyStringArrayList listenerIds_ =
        com.google.protobuf.LazyStringArrayList.emptyList();
    /**
     * <pre>
     * (Required) Reference IDs of listener instances.
     * </pre>
     *
     * <code>repeated string listener_ids = 1;</code>
     * @return A list containing the listenerIds.
     */
    public com.google.protobuf.ProtocolStringList
        getListenerIdsList() {
      return listenerIds_;
    }
    /**
     * <pre>
     * (Required) Reference IDs of listener instances.
     * </pre>
     *
     * <code>repeated string listener_ids = 1;</code>
     * @return The count of listenerIds.
     */
    public int getListenerIdsCount() {
      return listenerIds_.size();
    }
    /**
     * <pre>
     * (Required) Reference IDs of listener instances.
     * </pre>
     *
     * <code>repeated string listener_ids = 1;</code>
     * @param index The index of the element to return.
     * @return The listenerIds at the given index.
     */
    public String getListenerIds(int index) {
      return listenerIds_.get(index);
    }
    /**
     * <pre>
     * (Required) Reference IDs of listener instances.
     * </pre>
     *
     * <code>repeated string listener_ids = 1;</code>
     * @param index The index of the value to return.
     * @return The bytes of the listenerIds at the given index.
     */
    public com.google.protobuf.ByteString
        getListenerIdsBytes(int index) {
      return listenerIds_.getByteString(index);
    }

    private byte memoizedIsInitialized = -1;
    @Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < listenerIds_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, listenerIds_.getRaw(i));
      }
      getUnknownFields().writeTo(output);
    }

    @Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      {
        int dataSize = 0;
        for (int i = 0; i < listenerIds_.size(); i++) {
          dataSize += computeStringSizeNoTag(listenerIds_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getListenerIdsList().size();
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @Override
    public boolean equals(final Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult)) {
        return super.equals(obj);
      }
      org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult other = (org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult) obj;

      if (!getListenerIdsList()
          .equals(other.getListenerIdsList())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getListenerIdsCount() > 0) {
        hash = (37 * hash) + LISTENER_IDS_FIELD_NUMBER;
        hash = (53 * hash) + getListenerIdsList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @Override
    protected Builder newBuilderForType(
        BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code spark.connect.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:spark.connect.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult)
        org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResultOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.spark.connect.proto.Commands.internal_static_spark_connect_StreamingQueryManagerCommandResult_ListStreamingQueryListenerResult_descriptor;
      }

      @Override
      protected FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.spark.connect.proto.Commands.internal_static_spark_connect_StreamingQueryManagerCommandResult_ListStreamingQueryListenerResult_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult.class, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult.Builder.class);
      }

      // Construct using org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult.newBuilder()
      private Builder() {

      }

      private Builder(
          BuilderParent parent) {
        super(parent);

      }
      @Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        listenerIds_ =
            com.google.protobuf.LazyStringArrayList.emptyList();
        return this;
      }

      @Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.spark.connect.proto.Commands.internal_static_spark_connect_StreamingQueryManagerCommandResult_ListStreamingQueryListenerResult_descriptor;
      }

      @Override
      public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult getDefaultInstanceForType() {
        return org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult.getDefaultInstance();
      }

      @Override
      public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult build() {
        org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @Override
      public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult buildPartial() {
        org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult result = new org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult result) {
        int from_bitField0_ = bitField0_;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          listenerIds_.makeImmutable();
          result.listenerIds_ = listenerIds_;
        }
      }

      @Override
      public Builder clone() {
        return super.clone();
      }
      @Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return super.setField(field, value);
      }
      @Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return super.addRepeatedField(field, value);
      }
      @Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult) {
          return mergeFrom((org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult other) {
        if (other == org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult.getDefaultInstance()) return this;
        if (!other.listenerIds_.isEmpty()) {
          if (listenerIds_.isEmpty()) {
            listenerIds_ = other.listenerIds_;
            bitField0_ |= 0x00000001;
          } else {
            ensureListenerIdsIsMutable();
            listenerIds_.addAll(other.listenerIds_);
          }
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @Override
      public final boolean isInitialized() {
        return true;
      }

      @Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                String s = input.readStringRequireUtf8();
                ensureListenerIdsIsMutable();
                listenerIds_.add(s);
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private com.google.protobuf.LazyStringArrayList listenerIds_ =
          com.google.protobuf.LazyStringArrayList.emptyList();
      private void ensureListenerIdsIsMutable() {
        if (!listenerIds_.isModifiable()) {
          listenerIds_ = new com.google.protobuf.LazyStringArrayList(listenerIds_);
        }
        bitField0_ |= 0x00000001;
      }
      /**
       * <pre>
       * (Required) Reference IDs of listener instances.
       * </pre>
       *
       * <code>repeated string listener_ids = 1;</code>
       * @return A list containing the listenerIds.
       */
      public com.google.protobuf.ProtocolStringList
          getListenerIdsList() {
        listenerIds_.makeImmutable();
        return listenerIds_;
      }
      /**
       * <pre>
       * (Required) Reference IDs of listener instances.
       * </pre>
       *
       * <code>repeated string listener_ids = 1;</code>
       * @return The count of listenerIds.
       */
      public int getListenerIdsCount() {
        return listenerIds_.size();
      }
      /**
       * <pre>
       * (Required) Reference IDs of listener instances.
       * </pre>
       *
       * <code>repeated string listener_ids = 1;</code>
       * @param index The index of the element to return.
       * @return The listenerIds at the given index.
       */
      public String getListenerIds(int index) {
        return listenerIds_.get(index);
      }
      /**
       * <pre>
       * (Required) Reference IDs of listener instances.
       * </pre>
       *
       * <code>repeated string listener_ids = 1;</code>
       * @param index The index of the value to return.
       * @return The bytes of the listenerIds at the given index.
       */
      public com.google.protobuf.ByteString
          getListenerIdsBytes(int index) {
        return listenerIds_.getByteString(index);
      }
      /**
       * <pre>
       * (Required) Reference IDs of listener instances.
       * </pre>
       *
       * <code>repeated string listener_ids = 1;</code>
       * @param index The index to set the value at.
       * @param value The listenerIds to set.
       * @return This builder for chaining.
       */
      public Builder setListenerIds(
          int index, String value) {
        if (value == null) { throw new NullPointerException(); }
        ensureListenerIdsIsMutable();
        listenerIds_.set(index, value);
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * (Required) Reference IDs of listener instances.
       * </pre>
       *
       * <code>repeated string listener_ids = 1;</code>
       * @param value The listenerIds to add.
       * @return This builder for chaining.
       */
      public Builder addListenerIds(
          String value) {
        if (value == null) { throw new NullPointerException(); }
        ensureListenerIdsIsMutable();
        listenerIds_.add(value);
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * (Required) Reference IDs of listener instances.
       * </pre>
       *
       * <code>repeated string listener_ids = 1;</code>
       * @param values The listenerIds to add.
       * @return This builder for chaining.
       */
      public Builder addAllListenerIds(
          Iterable<String> values) {
        ensureListenerIdsIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, listenerIds_);
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * (Required) Reference IDs of listener instances.
       * </pre>
       *
       * <code>repeated string listener_ids = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearListenerIds() {
        listenerIds_ =
          com.google.protobuf.LazyStringArrayList.emptyList();
        bitField0_ = (bitField0_ & ~0x00000001);;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * (Required) Reference IDs of listener instances.
       * </pre>
       *
       * <code>repeated string listener_ids = 1;</code>
       * @param value The bytes of the listenerIds to add.
       * @return This builder for chaining.
       */
      public Builder addListenerIdsBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        checkByteStringIsUtf8(value);
        ensureListenerIdsIsMutable();
        listenerIds_.add(value);
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      @Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:spark.connect.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult)
    }

    // @@protoc_insertion_point(class_scope:spark.connect.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult)
    private static final org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult();
    }

    public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<ListStreamingQueryListenerResult>
        PARSER = new com.google.protobuf.AbstractParser<ListStreamingQueryListenerResult>() {
      @Override
      public ListStreamingQueryListenerResult parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<ListStreamingQueryListenerResult> parser() {
      return PARSER;
    }

    @Override
    public com.google.protobuf.Parser<ListStreamingQueryListenerResult> getParserForType() {
      return PARSER;
    }

    @Override
    public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  private int resultTypeCase_ = 0;
  @SuppressWarnings("serial")
  private Object resultType_;
  public enum ResultTypeCase
      implements com.google.protobuf.Internal.EnumLite,
          InternalOneOfEnum {
    ACTIVE(1),
    QUERY(2),
    AWAIT_ANY_TERMINATION(3),
    RESET_TERMINATED(4),
    ADD_LISTENER(5),
    REMOVE_LISTENER(6),
    LIST_LISTENERS(7),
    RESULTTYPE_NOT_SET(0);
    private final int value;
    private ResultTypeCase(int value) {
      this.value = value;
    }
    /**
     * @param value The number of the enum to look for.
     * @return The enum associated with the given number.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @Deprecated
    public static ResultTypeCase valueOf(int value) {
      return forNumber(value);
    }

    public static ResultTypeCase forNumber(int value) {
      switch (value) {
        case 1: return ACTIVE;
        case 2: return QUERY;
        case 3: return AWAIT_ANY_TERMINATION;
        case 4: return RESET_TERMINATED;
        case 5: return ADD_LISTENER;
        case 6: return REMOVE_LISTENER;
        case 7: return LIST_LISTENERS;
        case 0: return RESULTTYPE_NOT_SET;
        default: return null;
      }
    }
    public int getNumber() {
      return this.value;
    }
  };

  public ResultTypeCase
  getResultTypeCase() {
    return ResultTypeCase.forNumber(
        resultTypeCase_);
  }

  public static final int ACTIVE_FIELD_NUMBER = 1;
  /**
   * <code>.spark.connect.StreamingQueryManagerCommandResult.ActiveResult active = 1;</code>
   * @return Whether the active field is set.
   */
  @Override
  public boolean hasActive() {
    return resultTypeCase_ == 1;
  }
  /**
   * <code>.spark.connect.StreamingQueryManagerCommandResult.ActiveResult active = 1;</code>
   * @return The active.
   */
  @Override
  public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult getActive() {
    if (resultTypeCase_ == 1) {
       return (org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult) resultType_;
    }
    return org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult.getDefaultInstance();
  }
  /**
   * <code>.spark.connect.StreamingQueryManagerCommandResult.ActiveResult active = 1;</code>
   */
  @Override
  public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResultOrBuilder getActiveOrBuilder() {
    if (resultTypeCase_ == 1) {
       return (org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult) resultType_;
    }
    return org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult.getDefaultInstance();
  }

  public static final int QUERY_FIELD_NUMBER = 2;
  /**
   * <code>.spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance query = 2;</code>
   * @return Whether the query field is set.
   */
  @Override
  public boolean hasQuery() {
    return resultTypeCase_ == 2;
  }
  /**
   * <code>.spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance query = 2;</code>
   * @return The query.
   */
  @Override
  public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance getQuery() {
    if (resultTypeCase_ == 2) {
       return (org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance) resultType_;
    }
    return org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance.getDefaultInstance();
  }
  /**
   * <code>.spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance query = 2;</code>
   */
  @Override
  public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstanceOrBuilder getQueryOrBuilder() {
    if (resultTypeCase_ == 2) {
       return (org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance) resultType_;
    }
    return org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance.getDefaultInstance();
  }

  public static final int AWAIT_ANY_TERMINATION_FIELD_NUMBER = 3;
  /**
   * <code>.spark.connect.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult await_any_termination = 3;</code>
   * @return Whether the awaitAnyTermination field is set.
   */
  @Override
  public boolean hasAwaitAnyTermination() {
    return resultTypeCase_ == 3;
  }
  /**
   * <code>.spark.connect.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult await_any_termination = 3;</code>
   * @return The awaitAnyTermination.
   */
  @Override
  public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult getAwaitAnyTermination() {
    if (resultTypeCase_ == 3) {
       return (org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult) resultType_;
    }
    return org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult.getDefaultInstance();
  }
  /**
   * <code>.spark.connect.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult await_any_termination = 3;</code>
   */
  @Override
  public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResultOrBuilder getAwaitAnyTerminationOrBuilder() {
    if (resultTypeCase_ == 3) {
       return (org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult) resultType_;
    }
    return org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult.getDefaultInstance();
  }

  public static final int RESET_TERMINATED_FIELD_NUMBER = 4;
  /**
   * <code>bool reset_terminated = 4;</code>
   * @return Whether the resetTerminated field is set.
   */
  @Override
  public boolean hasResetTerminated() {
    return resultTypeCase_ == 4;
  }
  /**
   * <code>bool reset_terminated = 4;</code>
   * @return The resetTerminated.
   */
  @Override
  public boolean getResetTerminated() {
    if (resultTypeCase_ == 4) {
      return (Boolean) resultType_;
    }
    return false;
  }

  public static final int ADD_LISTENER_FIELD_NUMBER = 5;
  /**
   * <code>bool add_listener = 5;</code>
   * @return Whether the addListener field is set.
   */
  @Override
  public boolean hasAddListener() {
    return resultTypeCase_ == 5;
  }
  /**
   * <code>bool add_listener = 5;</code>
   * @return The addListener.
   */
  @Override
  public boolean getAddListener() {
    if (resultTypeCase_ == 5) {
      return (Boolean) resultType_;
    }
    return false;
  }

  public static final int REMOVE_LISTENER_FIELD_NUMBER = 6;
  /**
   * <code>bool remove_listener = 6;</code>
   * @return Whether the removeListener field is set.
   */
  @Override
  public boolean hasRemoveListener() {
    return resultTypeCase_ == 6;
  }
  /**
   * <code>bool remove_listener = 6;</code>
   * @return The removeListener.
   */
  @Override
  public boolean getRemoveListener() {
    if (resultTypeCase_ == 6) {
      return (Boolean) resultType_;
    }
    return false;
  }

  public static final int LIST_LISTENERS_FIELD_NUMBER = 7;
  /**
   * <code>.spark.connect.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult list_listeners = 7;</code>
   * @return Whether the listListeners field is set.
   */
  @Override
  public boolean hasListListeners() {
    return resultTypeCase_ == 7;
  }
  /**
   * <code>.spark.connect.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult list_listeners = 7;</code>
   * @return The listListeners.
   */
  @Override
  public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult getListListeners() {
    if (resultTypeCase_ == 7) {
       return (org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult) resultType_;
    }
    return org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult.getDefaultInstance();
  }
  /**
   * <code>.spark.connect.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult list_listeners = 7;</code>
   */
  @Override
  public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResultOrBuilder getListListenersOrBuilder() {
    if (resultTypeCase_ == 7) {
       return (org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult) resultType_;
    }
    return org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult.getDefaultInstance();
  }

  private byte memoizedIsInitialized = -1;
  @Override
  public final boolean isInitialized() {
    byte isInitialized = memoizedIsInitialized;
    if (isInitialized == 1) return true;
    if (isInitialized == 0) return false;

    memoizedIsInitialized = 1;
    return true;
  }

  @Override
  public void writeTo(com.google.protobuf.CodedOutputStream output)
                      throws java.io.IOException {
    if (resultTypeCase_ == 1) {
      output.writeMessage(1, (org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult) resultType_);
    }
    if (resultTypeCase_ == 2) {
      output.writeMessage(2, (org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance) resultType_);
    }
    if (resultTypeCase_ == 3) {
      output.writeMessage(3, (org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult) resultType_);
    }
    if (resultTypeCase_ == 4) {
      output.writeBool(
          4, (boolean)((Boolean) resultType_));
    }
    if (resultTypeCase_ == 5) {
      output.writeBool(
          5, (boolean)((Boolean) resultType_));
    }
    if (resultTypeCase_ == 6) {
      output.writeBool(
          6, (boolean)((Boolean) resultType_));
    }
    if (resultTypeCase_ == 7) {
      output.writeMessage(7, (org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult) resultType_);
    }
    getUnknownFields().writeTo(output);
  }

  @Override
  public int getSerializedSize() {
    int size = memoizedSize;
    if (size != -1) return size;

    size = 0;
    if (resultTypeCase_ == 1) {
      size += com.google.protobuf.CodedOutputStream
        .computeMessageSize(1, (org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult) resultType_);
    }
    if (resultTypeCase_ == 2) {
      size += com.google.protobuf.CodedOutputStream
        .computeMessageSize(2, (org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance) resultType_);
    }
    if (resultTypeCase_ == 3) {
      size += com.google.protobuf.CodedOutputStream
        .computeMessageSize(3, (org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult) resultType_);
    }
    if (resultTypeCase_ == 4) {
      size += com.google.protobuf.CodedOutputStream
        .computeBoolSize(
            4, (boolean)((Boolean) resultType_));
    }
    if (resultTypeCase_ == 5) {
      size += com.google.protobuf.CodedOutputStream
        .computeBoolSize(
            5, (boolean)((Boolean) resultType_));
    }
    if (resultTypeCase_ == 6) {
      size += com.google.protobuf.CodedOutputStream
        .computeBoolSize(
            6, (boolean)((Boolean) resultType_));
    }
    if (resultTypeCase_ == 7) {
      size += com.google.protobuf.CodedOutputStream
        .computeMessageSize(7, (org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult) resultType_);
    }
    size += getUnknownFields().getSerializedSize();
    memoizedSize = size;
    return size;
  }

  @Override
  public boolean equals(final Object obj) {
    if (obj == this) {
     return true;
    }
    if (!(obj instanceof org.apache.spark.connect.proto.StreamingQueryManagerCommandResult)) {
      return super.equals(obj);
    }
    org.apache.spark.connect.proto.StreamingQueryManagerCommandResult other = (org.apache.spark.connect.proto.StreamingQueryManagerCommandResult) obj;

    if (!getResultTypeCase().equals(other.getResultTypeCase())) return false;
    switch (resultTypeCase_) {
      case 1:
        if (!getActive()
            .equals(other.getActive())) return false;
        break;
      case 2:
        if (!getQuery()
            .equals(other.getQuery())) return false;
        break;
      case 3:
        if (!getAwaitAnyTermination()
            .equals(other.getAwaitAnyTermination())) return false;
        break;
      case 4:
        if (getResetTerminated()
            != other.getResetTerminated()) return false;
        break;
      case 5:
        if (getAddListener()
            != other.getAddListener()) return false;
        break;
      case 6:
        if (getRemoveListener()
            != other.getRemoveListener()) return false;
        break;
      case 7:
        if (!getListListeners()
            .equals(other.getListListeners())) return false;
        break;
      case 0:
      default:
    }
    if (!getUnknownFields().equals(other.getUnknownFields())) return false;
    return true;
  }

  @Override
  public int hashCode() {
    if (memoizedHashCode != 0) {
      return memoizedHashCode;
    }
    int hash = 41;
    hash = (19 * hash) + getDescriptor().hashCode();
    switch (resultTypeCase_) {
      case 1:
        hash = (37 * hash) + ACTIVE_FIELD_NUMBER;
        hash = (53 * hash) + getActive().hashCode();
        break;
      case 2:
        hash = (37 * hash) + QUERY_FIELD_NUMBER;
        hash = (53 * hash) + getQuery().hashCode();
        break;
      case 3:
        hash = (37 * hash) + AWAIT_ANY_TERMINATION_FIELD_NUMBER;
        hash = (53 * hash) + getAwaitAnyTermination().hashCode();
        break;
      case 4:
        hash = (37 * hash) + RESET_TERMINATED_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
            getResetTerminated());
        break;
      case 5:
        hash = (37 * hash) + ADD_LISTENER_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
            getAddListener());
        break;
      case 6:
        hash = (37 * hash) + REMOVE_LISTENER_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
            getRemoveListener());
        break;
      case 7:
        hash = (37 * hash) + LIST_LISTENERS_FIELD_NUMBER;
        hash = (53 * hash) + getListListeners().hashCode();
        break;
      case 0:
      default:
    }
    hash = (29 * hash) + getUnknownFields().hashCode();
    memoizedHashCode = hash;
    return hash;
  }

  public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult parseFrom(
      java.nio.ByteBuffer data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }
  public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult parseFrom(
      java.nio.ByteBuffer data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }
  public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult parseFrom(
      com.google.protobuf.ByteString data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }
  public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult parseFrom(
      com.google.protobuf.ByteString data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }
  public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult parseFrom(byte[] data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }
  public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult parseFrom(
      byte[] data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }
  public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult parseFrom(java.io.InputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input);
  }
  public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult parseFrom(
      java.io.InputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input, extensionRegistry);
  }

  public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult parseDelimitedFrom(java.io.InputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseDelimitedWithIOException(PARSER, input);
  }

  public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult parseDelimitedFrom(
      java.io.InputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
  }
  public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult parseFrom(
      com.google.protobuf.CodedInputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input);
  }
  public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult parseFrom(
      com.google.protobuf.CodedInputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input, extensionRegistry);
  }

  @Override
  public Builder newBuilderForType() { return newBuilder(); }
  public static Builder newBuilder() {
    return DEFAULT_INSTANCE.toBuilder();
  }
  public static Builder newBuilder(org.apache.spark.connect.proto.StreamingQueryManagerCommandResult prototype) {
    return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
  }
  @Override
  public Builder toBuilder() {
    return this == DEFAULT_INSTANCE
        ? new Builder() : new Builder().mergeFrom(this);
  }

  @Override
  protected Builder newBuilderForType(
      BuilderParent parent) {
    Builder builder = new Builder(parent);
    return builder;
  }
  /**
   * <pre>
   * Response for commands on the streaming query manager.
   * </pre>
   *
   * Protobuf type {@code spark.connect.StreamingQueryManagerCommandResult}
   */
  public static final class Builder extends
      com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
      // @@protoc_insertion_point(builder_implements:spark.connect.StreamingQueryManagerCommandResult)
      org.apache.spark.connect.proto.StreamingQueryManagerCommandResultOrBuilder {
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.spark.connect.proto.Commands.internal_static_spark_connect_StreamingQueryManagerCommandResult_descriptor;
    }

    @Override
    protected FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.spark.connect.proto.Commands.internal_static_spark_connect_StreamingQueryManagerCommandResult_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.class, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.Builder.class);
    }

    // Construct using org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.newBuilder()
    private Builder() {

    }

    private Builder(
        BuilderParent parent) {
      super(parent);

    }
    @Override
    public Builder clear() {
      super.clear();
      bitField0_ = 0;
      if (activeBuilder_ != null) {
        activeBuilder_.clear();
      }
      if (queryBuilder_ != null) {
        queryBuilder_.clear();
      }
      if (awaitAnyTerminationBuilder_ != null) {
        awaitAnyTerminationBuilder_.clear();
      }
      if (listListenersBuilder_ != null) {
        listListenersBuilder_.clear();
      }
      resultTypeCase_ = 0;
      resultType_ = null;
      return this;
    }

    @Override
    public com.google.protobuf.Descriptors.Descriptor
        getDescriptorForType() {
      return org.apache.spark.connect.proto.Commands.internal_static_spark_connect_StreamingQueryManagerCommandResult_descriptor;
    }

    @Override
    public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult getDefaultInstanceForType() {
      return org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.getDefaultInstance();
    }

    @Override
    public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult build() {
      org.apache.spark.connect.proto.StreamingQueryManagerCommandResult result = buildPartial();
      if (!result.isInitialized()) {
        throw newUninitializedMessageException(result);
      }
      return result;
    }

    @Override
    public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult buildPartial() {
      org.apache.spark.connect.proto.StreamingQueryManagerCommandResult result = new org.apache.spark.connect.proto.StreamingQueryManagerCommandResult(this);
      if (bitField0_ != 0) { buildPartial0(result); }
      buildPartialOneofs(result);
      onBuilt();
      return result;
    }

    private void buildPartial0(org.apache.spark.connect.proto.StreamingQueryManagerCommandResult result) {
      int from_bitField0_ = bitField0_;
    }

    private void buildPartialOneofs(org.apache.spark.connect.proto.StreamingQueryManagerCommandResult result) {
      result.resultTypeCase_ = resultTypeCase_;
      result.resultType_ = this.resultType_;
      if (resultTypeCase_ == 1 &&
          activeBuilder_ != null) {
        result.resultType_ = activeBuilder_.build();
      }
      if (resultTypeCase_ == 2 &&
          queryBuilder_ != null) {
        result.resultType_ = queryBuilder_.build();
      }
      if (resultTypeCase_ == 3 &&
          awaitAnyTerminationBuilder_ != null) {
        result.resultType_ = awaitAnyTerminationBuilder_.build();
      }
      if (resultTypeCase_ == 7 &&
          listListenersBuilder_ != null) {
        result.resultType_ = listListenersBuilder_.build();
      }
    }

    @Override
    public Builder clone() {
      return super.clone();
    }
    @Override
    public Builder setField(
        com.google.protobuf.Descriptors.FieldDescriptor field,
        Object value) {
      return super.setField(field, value);
    }
    @Override
    public Builder clearField(
        com.google.protobuf.Descriptors.FieldDescriptor field) {
      return super.clearField(field);
    }
    @Override
    public Builder clearOneof(
        com.google.protobuf.Descriptors.OneofDescriptor oneof) {
      return super.clearOneof(oneof);
    }
    @Override
    public Builder setRepeatedField(
        com.google.protobuf.Descriptors.FieldDescriptor field,
        int index, Object value) {
      return super.setRepeatedField(field, index, value);
    }
    @Override
    public Builder addRepeatedField(
        com.google.protobuf.Descriptors.FieldDescriptor field,
        Object value) {
      return super.addRepeatedField(field, value);
    }
    @Override
    public Builder mergeFrom(com.google.protobuf.Message other) {
      if (other instanceof org.apache.spark.connect.proto.StreamingQueryManagerCommandResult) {
        return mergeFrom((org.apache.spark.connect.proto.StreamingQueryManagerCommandResult)other);
      } else {
        super.mergeFrom(other);
        return this;
      }
    }

    public Builder mergeFrom(org.apache.spark.connect.proto.StreamingQueryManagerCommandResult other) {
      if (other == org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.getDefaultInstance()) return this;
      switch (other.getResultTypeCase()) {
        case ACTIVE: {
          mergeActive(other.getActive());
          break;
        }
        case QUERY: {
          mergeQuery(other.getQuery());
          break;
        }
        case AWAIT_ANY_TERMINATION: {
          mergeAwaitAnyTermination(other.getAwaitAnyTermination());
          break;
        }
        case RESET_TERMINATED: {
          setResetTerminated(other.getResetTerminated());
          break;
        }
        case ADD_LISTENER: {
          setAddListener(other.getAddListener());
          break;
        }
        case REMOVE_LISTENER: {
          setRemoveListener(other.getRemoveListener());
          break;
        }
        case LIST_LISTENERS: {
          mergeListListeners(other.getListListeners());
          break;
        }
        case RESULTTYPE_NOT_SET: {
          break;
        }
      }
      this.mergeUnknownFields(other.getUnknownFields());
      onChanged();
      return this;
    }

    @Override
    public final boolean isInitialized() {
      return true;
    }

    @Override
    public Builder mergeFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      if (extensionRegistry == null) {
        throw new NullPointerException();
      }
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              input.readMessage(
                  getActiveFieldBuilder().getBuilder(),
                  extensionRegistry);
              resultTypeCase_ = 1;
              break;
            } // case 10
            case 18: {
              input.readMessage(
                  getQueryFieldBuilder().getBuilder(),
                  extensionRegistry);
              resultTypeCase_ = 2;
              break;
            } // case 18
            case 26: {
              input.readMessage(
                  getAwaitAnyTerminationFieldBuilder().getBuilder(),
                  extensionRegistry);
              resultTypeCase_ = 3;
              break;
            } // case 26
            case 32: {
              resultType_ = input.readBool();
              resultTypeCase_ = 4;
              break;
            } // case 32
            case 40: {
              resultType_ = input.readBool();
              resultTypeCase_ = 5;
              break;
            } // case 40
            case 48: {
              resultType_ = input.readBool();
              resultTypeCase_ = 6;
              break;
            } // case 48
            case 58: {
              input.readMessage(
                  getListListenersFieldBuilder().getBuilder(),
                  extensionRegistry);
              resultTypeCase_ = 7;
              break;
            } // case 58
            default: {
              if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                done = true; // was an endgroup tag
              }
              break;
            } // default:
          } // switch (tag)
        } // while (!done)
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.unwrapIOException();
      } finally {
        onChanged();
      } // finally
      return this;
    }
    private int resultTypeCase_ = 0;
    private Object resultType_;
    public ResultTypeCase
        getResultTypeCase() {
      return ResultTypeCase.forNumber(
          resultTypeCase_);
    }

    public Builder clearResultType() {
      resultTypeCase_ = 0;
      resultType_ = null;
      onChanged();
      return this;
    }

    private int bitField0_;

    private com.google.protobuf.SingleFieldBuilderV3<
        org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult.Builder, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResultOrBuilder> activeBuilder_;
    /**
     * <code>.spark.connect.StreamingQueryManagerCommandResult.ActiveResult active = 1;</code>
     * @return Whether the active field is set.
     */
    @Override
    public boolean hasActive() {
      return resultTypeCase_ == 1;
    }
    /**
     * <code>.spark.connect.StreamingQueryManagerCommandResult.ActiveResult active = 1;</code>
     * @return The active.
     */
    @Override
    public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult getActive() {
      if (activeBuilder_ == null) {
        if (resultTypeCase_ == 1) {
          return (org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult) resultType_;
        }
        return org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult.getDefaultInstance();
      } else {
        if (resultTypeCase_ == 1) {
          return activeBuilder_.getMessage();
        }
        return org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult.getDefaultInstance();
      }
    }
    /**
     * <code>.spark.connect.StreamingQueryManagerCommandResult.ActiveResult active = 1;</code>
     */
    public Builder setActive(org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult value) {
      if (activeBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        resultType_ = value;
        onChanged();
      } else {
        activeBuilder_.setMessage(value);
      }
      resultTypeCase_ = 1;
      return this;
    }
    /**
     * <code>.spark.connect.StreamingQueryManagerCommandResult.ActiveResult active = 1;</code>
     */
    public Builder setActive(
        org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult.Builder builderForValue) {
      if (activeBuilder_ == null) {
        resultType_ = builderForValue.build();
        onChanged();
      } else {
        activeBuilder_.setMessage(builderForValue.build());
      }
      resultTypeCase_ = 1;
      return this;
    }
    /**
     * <code>.spark.connect.StreamingQueryManagerCommandResult.ActiveResult active = 1;</code>
     */
    public Builder mergeActive(org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult value) {
      if (activeBuilder_ == null) {
        if (resultTypeCase_ == 1 &&
            resultType_ != org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult.getDefaultInstance()) {
          resultType_ = org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult.newBuilder((org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult) resultType_)
              .mergeFrom(value).buildPartial();
        } else {
          resultType_ = value;
        }
        onChanged();
      } else {
        if (resultTypeCase_ == 1) {
          activeBuilder_.mergeFrom(value);
        } else {
          activeBuilder_.setMessage(value);
        }
      }
      resultTypeCase_ = 1;
      return this;
    }
    /**
     * <code>.spark.connect.StreamingQueryManagerCommandResult.ActiveResult active = 1;</code>
     */
    public Builder clearActive() {
      if (activeBuilder_ == null) {
        if (resultTypeCase_ == 1) {
          resultTypeCase_ = 0;
          resultType_ = null;
          onChanged();
        }
      } else {
        if (resultTypeCase_ == 1) {
          resultTypeCase_ = 0;
          resultType_ = null;
        }
        activeBuilder_.clear();
      }
      return this;
    }
    /**
     * <code>.spark.connect.StreamingQueryManagerCommandResult.ActiveResult active = 1;</code>
     */
    public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult.Builder getActiveBuilder() {
      return getActiveFieldBuilder().getBuilder();
    }
    /**
     * <code>.spark.connect.StreamingQueryManagerCommandResult.ActiveResult active = 1;</code>
     */
    @Override
    public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResultOrBuilder getActiveOrBuilder() {
      if ((resultTypeCase_ == 1) && (activeBuilder_ != null)) {
        return activeBuilder_.getMessageOrBuilder();
      } else {
        if (resultTypeCase_ == 1) {
          return (org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult) resultType_;
        }
        return org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult.getDefaultInstance();
      }
    }
    /**
     * <code>.spark.connect.StreamingQueryManagerCommandResult.ActiveResult active = 1;</code>
     */
    private com.google.protobuf.SingleFieldBuilderV3<
        org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult.Builder, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResultOrBuilder> 
        getActiveFieldBuilder() {
      if (activeBuilder_ == null) {
        if (!(resultTypeCase_ == 1)) {
          resultType_ = org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult.getDefaultInstance();
        }
        activeBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
            org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult.Builder, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResultOrBuilder>(
                (org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ActiveResult) resultType_,
                getParentForChildren(),
                isClean());
        resultType_ = null;
      }
      resultTypeCase_ = 1;
      onChanged();
      return activeBuilder_;
    }

    private com.google.protobuf.SingleFieldBuilderV3<
        org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance.Builder, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstanceOrBuilder> queryBuilder_;
    /**
     * <code>.spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance query = 2;</code>
     * @return Whether the query field is set.
     */
    @Override
    public boolean hasQuery() {
      return resultTypeCase_ == 2;
    }
    /**
     * <code>.spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance query = 2;</code>
     * @return The query.
     */
    @Override
    public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance getQuery() {
      if (queryBuilder_ == null) {
        if (resultTypeCase_ == 2) {
          return (org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance) resultType_;
        }
        return org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance.getDefaultInstance();
      } else {
        if (resultTypeCase_ == 2) {
          return queryBuilder_.getMessage();
        }
        return org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance.getDefaultInstance();
      }
    }
    /**
     * <code>.spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance query = 2;</code>
     */
    public Builder setQuery(org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance value) {
      if (queryBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        resultType_ = value;
        onChanged();
      } else {
        queryBuilder_.setMessage(value);
      }
      resultTypeCase_ = 2;
      return this;
    }
    /**
     * <code>.spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance query = 2;</code>
     */
    public Builder setQuery(
        org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance.Builder builderForValue) {
      if (queryBuilder_ == null) {
        resultType_ = builderForValue.build();
        onChanged();
      } else {
        queryBuilder_.setMessage(builderForValue.build());
      }
      resultTypeCase_ = 2;
      return this;
    }
    /**
     * <code>.spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance query = 2;</code>
     */
    public Builder mergeQuery(org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance value) {
      if (queryBuilder_ == null) {
        if (resultTypeCase_ == 2 &&
            resultType_ != org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance.getDefaultInstance()) {
          resultType_ = org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance.newBuilder((org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance) resultType_)
              .mergeFrom(value).buildPartial();
        } else {
          resultType_ = value;
        }
        onChanged();
      } else {
        if (resultTypeCase_ == 2) {
          queryBuilder_.mergeFrom(value);
        } else {
          queryBuilder_.setMessage(value);
        }
      }
      resultTypeCase_ = 2;
      return this;
    }
    /**
     * <code>.spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance query = 2;</code>
     */
    public Builder clearQuery() {
      if (queryBuilder_ == null) {
        if (resultTypeCase_ == 2) {
          resultTypeCase_ = 0;
          resultType_ = null;
          onChanged();
        }
      } else {
        if (resultTypeCase_ == 2) {
          resultTypeCase_ = 0;
          resultType_ = null;
        }
        queryBuilder_.clear();
      }
      return this;
    }
    /**
     * <code>.spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance query = 2;</code>
     */
    public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance.Builder getQueryBuilder() {
      return getQueryFieldBuilder().getBuilder();
    }
    /**
     * <code>.spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance query = 2;</code>
     */
    @Override
    public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstanceOrBuilder getQueryOrBuilder() {
      if ((resultTypeCase_ == 2) && (queryBuilder_ != null)) {
        return queryBuilder_.getMessageOrBuilder();
      } else {
        if (resultTypeCase_ == 2) {
          return (org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance) resultType_;
        }
        return org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance.getDefaultInstance();
      }
    }
    /**
     * <code>.spark.connect.StreamingQueryManagerCommandResult.StreamingQueryInstance query = 2;</code>
     */
    private com.google.protobuf.SingleFieldBuilderV3<
        org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance.Builder, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstanceOrBuilder> 
        getQueryFieldBuilder() {
      if (queryBuilder_ == null) {
        if (!(resultTypeCase_ == 2)) {
          resultType_ = org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance.getDefaultInstance();
        }
        queryBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
            org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance.Builder, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstanceOrBuilder>(
                (org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.StreamingQueryInstance) resultType_,
                getParentForChildren(),
                isClean());
        resultType_ = null;
      }
      resultTypeCase_ = 2;
      onChanged();
      return queryBuilder_;
    }

    private com.google.protobuf.SingleFieldBuilderV3<
        org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult.Builder, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResultOrBuilder> awaitAnyTerminationBuilder_;
    /**
     * <code>.spark.connect.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult await_any_termination = 3;</code>
     * @return Whether the awaitAnyTermination field is set.
     */
    @Override
    public boolean hasAwaitAnyTermination() {
      return resultTypeCase_ == 3;
    }
    /**
     * <code>.spark.connect.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult await_any_termination = 3;</code>
     * @return The awaitAnyTermination.
     */
    @Override
    public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult getAwaitAnyTermination() {
      if (awaitAnyTerminationBuilder_ == null) {
        if (resultTypeCase_ == 3) {
          return (org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult) resultType_;
        }
        return org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult.getDefaultInstance();
      } else {
        if (resultTypeCase_ == 3) {
          return awaitAnyTerminationBuilder_.getMessage();
        }
        return org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult.getDefaultInstance();
      }
    }
    /**
     * <code>.spark.connect.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult await_any_termination = 3;</code>
     */
    public Builder setAwaitAnyTermination(org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult value) {
      if (awaitAnyTerminationBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        resultType_ = value;
        onChanged();
      } else {
        awaitAnyTerminationBuilder_.setMessage(value);
      }
      resultTypeCase_ = 3;
      return this;
    }
    /**
     * <code>.spark.connect.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult await_any_termination = 3;</code>
     */
    public Builder setAwaitAnyTermination(
        org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult.Builder builderForValue) {
      if (awaitAnyTerminationBuilder_ == null) {
        resultType_ = builderForValue.build();
        onChanged();
      } else {
        awaitAnyTerminationBuilder_.setMessage(builderForValue.build());
      }
      resultTypeCase_ = 3;
      return this;
    }
    /**
     * <code>.spark.connect.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult await_any_termination = 3;</code>
     */
    public Builder mergeAwaitAnyTermination(org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult value) {
      if (awaitAnyTerminationBuilder_ == null) {
        if (resultTypeCase_ == 3 &&
            resultType_ != org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult.getDefaultInstance()) {
          resultType_ = org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult.newBuilder((org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult) resultType_)
              .mergeFrom(value).buildPartial();
        } else {
          resultType_ = value;
        }
        onChanged();
      } else {
        if (resultTypeCase_ == 3) {
          awaitAnyTerminationBuilder_.mergeFrom(value);
        } else {
          awaitAnyTerminationBuilder_.setMessage(value);
        }
      }
      resultTypeCase_ = 3;
      return this;
    }
    /**
     * <code>.spark.connect.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult await_any_termination = 3;</code>
     */
    public Builder clearAwaitAnyTermination() {
      if (awaitAnyTerminationBuilder_ == null) {
        if (resultTypeCase_ == 3) {
          resultTypeCase_ = 0;
          resultType_ = null;
          onChanged();
        }
      } else {
        if (resultTypeCase_ == 3) {
          resultTypeCase_ = 0;
          resultType_ = null;
        }
        awaitAnyTerminationBuilder_.clear();
      }
      return this;
    }
    /**
     * <code>.spark.connect.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult await_any_termination = 3;</code>
     */
    public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult.Builder getAwaitAnyTerminationBuilder() {
      return getAwaitAnyTerminationFieldBuilder().getBuilder();
    }
    /**
     * <code>.spark.connect.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult await_any_termination = 3;</code>
     */
    @Override
    public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResultOrBuilder getAwaitAnyTerminationOrBuilder() {
      if ((resultTypeCase_ == 3) && (awaitAnyTerminationBuilder_ != null)) {
        return awaitAnyTerminationBuilder_.getMessageOrBuilder();
      } else {
        if (resultTypeCase_ == 3) {
          return (org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult) resultType_;
        }
        return org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult.getDefaultInstance();
      }
    }
    /**
     * <code>.spark.connect.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult await_any_termination = 3;</code>
     */
    private com.google.protobuf.SingleFieldBuilderV3<
        org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult.Builder, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResultOrBuilder> 
        getAwaitAnyTerminationFieldBuilder() {
      if (awaitAnyTerminationBuilder_ == null) {
        if (!(resultTypeCase_ == 3)) {
          resultType_ = org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult.getDefaultInstance();
        }
        awaitAnyTerminationBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
            org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult.Builder, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResultOrBuilder>(
                (org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult) resultType_,
                getParentForChildren(),
                isClean());
        resultType_ = null;
      }
      resultTypeCase_ = 3;
      onChanged();
      return awaitAnyTerminationBuilder_;
    }

    /**
     * <code>bool reset_terminated = 4;</code>
     * @return Whether the resetTerminated field is set.
     */
    public boolean hasResetTerminated() {
      return resultTypeCase_ == 4;
    }
    /**
     * <code>bool reset_terminated = 4;</code>
     * @return The resetTerminated.
     */
    public boolean getResetTerminated() {
      if (resultTypeCase_ == 4) {
        return (Boolean) resultType_;
      }
      return false;
    }
    /**
     * <code>bool reset_terminated = 4;</code>
     * @param value The resetTerminated to set.
     * @return This builder for chaining.
     */
    public Builder setResetTerminated(boolean value) {

      resultTypeCase_ = 4;
      resultType_ = value;
      onChanged();
      return this;
    }
    /**
     * <code>bool reset_terminated = 4;</code>
     * @return This builder for chaining.
     */
    public Builder clearResetTerminated() {
      if (resultTypeCase_ == 4) {
        resultTypeCase_ = 0;
        resultType_ = null;
        onChanged();
      }
      return this;
    }

    /**
     * <code>bool add_listener = 5;</code>
     * @return Whether the addListener field is set.
     */
    public boolean hasAddListener() {
      return resultTypeCase_ == 5;
    }
    /**
     * <code>bool add_listener = 5;</code>
     * @return The addListener.
     */
    public boolean getAddListener() {
      if (resultTypeCase_ == 5) {
        return (Boolean) resultType_;
      }
      return false;
    }
    /**
     * <code>bool add_listener = 5;</code>
     * @param value The addListener to set.
     * @return This builder for chaining.
     */
    public Builder setAddListener(boolean value) {

      resultTypeCase_ = 5;
      resultType_ = value;
      onChanged();
      return this;
    }
    /**
     * <code>bool add_listener = 5;</code>
     * @return This builder for chaining.
     */
    public Builder clearAddListener() {
      if (resultTypeCase_ == 5) {
        resultTypeCase_ = 0;
        resultType_ = null;
        onChanged();
      }
      return this;
    }

    /**
     * <code>bool remove_listener = 6;</code>
     * @return Whether the removeListener field is set.
     */
    public boolean hasRemoveListener() {
      return resultTypeCase_ == 6;
    }
    /**
     * <code>bool remove_listener = 6;</code>
     * @return The removeListener.
     */
    public boolean getRemoveListener() {
      if (resultTypeCase_ == 6) {
        return (Boolean) resultType_;
      }
      return false;
    }
    /**
     * <code>bool remove_listener = 6;</code>
     * @param value The removeListener to set.
     * @return This builder for chaining.
     */
    public Builder setRemoveListener(boolean value) {

      resultTypeCase_ = 6;
      resultType_ = value;
      onChanged();
      return this;
    }
    /**
     * <code>bool remove_listener = 6;</code>
     * @return This builder for chaining.
     */
    public Builder clearRemoveListener() {
      if (resultTypeCase_ == 6) {
        resultTypeCase_ = 0;
        resultType_ = null;
        onChanged();
      }
      return this;
    }

    private com.google.protobuf.SingleFieldBuilderV3<
        org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult.Builder, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResultOrBuilder> listListenersBuilder_;
    /**
     * <code>.spark.connect.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult list_listeners = 7;</code>
     * @return Whether the listListeners field is set.
     */
    @Override
    public boolean hasListListeners() {
      return resultTypeCase_ == 7;
    }
    /**
     * <code>.spark.connect.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult list_listeners = 7;</code>
     * @return The listListeners.
     */
    @Override
    public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult getListListeners() {
      if (listListenersBuilder_ == null) {
        if (resultTypeCase_ == 7) {
          return (org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult) resultType_;
        }
        return org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult.getDefaultInstance();
      } else {
        if (resultTypeCase_ == 7) {
          return listListenersBuilder_.getMessage();
        }
        return org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult.getDefaultInstance();
      }
    }
    /**
     * <code>.spark.connect.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult list_listeners = 7;</code>
     */
    public Builder setListListeners(org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult value) {
      if (listListenersBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        resultType_ = value;
        onChanged();
      } else {
        listListenersBuilder_.setMessage(value);
      }
      resultTypeCase_ = 7;
      return this;
    }
    /**
     * <code>.spark.connect.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult list_listeners = 7;</code>
     */
    public Builder setListListeners(
        org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult.Builder builderForValue) {
      if (listListenersBuilder_ == null) {
        resultType_ = builderForValue.build();
        onChanged();
      } else {
        listListenersBuilder_.setMessage(builderForValue.build());
      }
      resultTypeCase_ = 7;
      return this;
    }
    /**
     * <code>.spark.connect.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult list_listeners = 7;</code>
     */
    public Builder mergeListListeners(org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult value) {
      if (listListenersBuilder_ == null) {
        if (resultTypeCase_ == 7 &&
            resultType_ != org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult.getDefaultInstance()) {
          resultType_ = org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult.newBuilder((org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult) resultType_)
              .mergeFrom(value).buildPartial();
        } else {
          resultType_ = value;
        }
        onChanged();
      } else {
        if (resultTypeCase_ == 7) {
          listListenersBuilder_.mergeFrom(value);
        } else {
          listListenersBuilder_.setMessage(value);
        }
      }
      resultTypeCase_ = 7;
      return this;
    }
    /**
     * <code>.spark.connect.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult list_listeners = 7;</code>
     */
    public Builder clearListListeners() {
      if (listListenersBuilder_ == null) {
        if (resultTypeCase_ == 7) {
          resultTypeCase_ = 0;
          resultType_ = null;
          onChanged();
        }
      } else {
        if (resultTypeCase_ == 7) {
          resultTypeCase_ = 0;
          resultType_ = null;
        }
        listListenersBuilder_.clear();
      }
      return this;
    }
    /**
     * <code>.spark.connect.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult list_listeners = 7;</code>
     */
    public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult.Builder getListListenersBuilder() {
      return getListListenersFieldBuilder().getBuilder();
    }
    /**
     * <code>.spark.connect.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult list_listeners = 7;</code>
     */
    @Override
    public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResultOrBuilder getListListenersOrBuilder() {
      if ((resultTypeCase_ == 7) && (listListenersBuilder_ != null)) {
        return listListenersBuilder_.getMessageOrBuilder();
      } else {
        if (resultTypeCase_ == 7) {
          return (org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult) resultType_;
        }
        return org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult.getDefaultInstance();
      }
    }
    /**
     * <code>.spark.connect.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult list_listeners = 7;</code>
     */
    private com.google.protobuf.SingleFieldBuilderV3<
        org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult.Builder, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResultOrBuilder> 
        getListListenersFieldBuilder() {
      if (listListenersBuilder_ == null) {
        if (!(resultTypeCase_ == 7)) {
          resultType_ = org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult.getDefaultInstance();
        }
        listListenersBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
            org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult.Builder, org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResultOrBuilder>(
                (org.apache.spark.connect.proto.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult) resultType_,
                getParentForChildren(),
                isClean());
        resultType_ = null;
      }
      resultTypeCase_ = 7;
      onChanged();
      return listListenersBuilder_;
    }
    @Override
    public final Builder setUnknownFields(
        final com.google.protobuf.UnknownFieldSet unknownFields) {
      return super.setUnknownFields(unknownFields);
    }

    @Override
    public final Builder mergeUnknownFields(
        final com.google.protobuf.UnknownFieldSet unknownFields) {
      return super.mergeUnknownFields(unknownFields);
    }


    // @@protoc_insertion_point(builder_scope:spark.connect.StreamingQueryManagerCommandResult)
  }

  // @@protoc_insertion_point(class_scope:spark.connect.StreamingQueryManagerCommandResult)
  private static final org.apache.spark.connect.proto.StreamingQueryManagerCommandResult DEFAULT_INSTANCE;
  static {
    DEFAULT_INSTANCE = new org.apache.spark.connect.proto.StreamingQueryManagerCommandResult();
  }

  public static org.apache.spark.connect.proto.StreamingQueryManagerCommandResult getDefaultInstance() {
    return DEFAULT_INSTANCE;
  }

  private static final com.google.protobuf.Parser<StreamingQueryManagerCommandResult>
      PARSER = new com.google.protobuf.AbstractParser<StreamingQueryManagerCommandResult>() {
    @Override
    public StreamingQueryManagerCommandResult parsePartialFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      Builder builder = newBuilder();
      try {
        builder.mergeFrom(input, extensionRegistry);
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(builder.buildPartial());
      } catch (com.google.protobuf.UninitializedMessageException e) {
        throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(e)
            .setUnfinishedMessage(builder.buildPartial());
      }
      return builder.buildPartial();
    }
  };

  public static com.google.protobuf.Parser<StreamingQueryManagerCommandResult> parser() {
    return PARSER;
  }

  @Override
  public com.google.protobuf.Parser<StreamingQueryManagerCommandResult> getParserForType() {
    return PARSER;
  }

  @Override
  public org.apache.spark.connect.proto.StreamingQueryManagerCommandResult getDefaultInstanceForType() {
    return DEFAULT_INSTANCE;
  }

}

