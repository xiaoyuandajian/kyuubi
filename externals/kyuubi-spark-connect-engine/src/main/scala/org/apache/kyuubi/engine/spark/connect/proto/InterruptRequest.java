// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: spark/connect/base.proto

package org.apache.kyuubi.engine.spark.connect.proto;

/**
 * Protobuf type {@code spark.connect.InterruptRequest}
 */
public final class InterruptRequest extends
    com.google.protobuf.GeneratedMessageV3 implements
    // @@protoc_insertion_point(message_implements:spark.connect.InterruptRequest)
    InterruptRequestOrBuilder {
private static final long serialVersionUID = 0L;
  // Use InterruptRequest.newBuilder() to construct.
  private InterruptRequest(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
    super(builder);
  }
  private InterruptRequest() {
    sessionId_ = "";
    clientType_ = "";
    interruptType_ = 0;
  }

  @Override
  @SuppressWarnings({"unused"})
  protected Object newInstance(
      UnusedPrivateParameter unused) {
    return new InterruptRequest();
  }

  public static final com.google.protobuf.Descriptors.Descriptor
      getDescriptor() {
    return org.apache.spark.connect.proto.Base.internal_static_spark_connect_InterruptRequest_descriptor;
  }

  @Override
  protected FieldAccessorTable
      internalGetFieldAccessorTable() {
    return org.apache.spark.connect.proto.Base.internal_static_spark_connect_InterruptRequest_fieldAccessorTable
        .ensureFieldAccessorsInitialized(
            org.apache.spark.connect.proto.InterruptRequest.class, org.apache.spark.connect.proto.InterruptRequest.Builder.class);
  }

  /**
   * Protobuf enum {@code spark.connect.InterruptRequest.InterruptType}
   */
  public enum InterruptType
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>INTERRUPT_TYPE_UNSPECIFIED = 0;</code>
     */
    INTERRUPT_TYPE_UNSPECIFIED(0),
    /**
     * <pre>
     * Interrupt all running executions within the session with the provided session_id.
     * </pre>
     *
     * <code>INTERRUPT_TYPE_ALL = 1;</code>
     */
    INTERRUPT_TYPE_ALL(1),
    /**
     * <pre>
     * Interrupt all running executions within the session with the provided operation_tag.
     * </pre>
     *
     * <code>INTERRUPT_TYPE_TAG = 2;</code>
     */
    INTERRUPT_TYPE_TAG(2),
    /**
     * <pre>
     * Interrupt the running execution within the session with the provided operation_id.
     * </pre>
     *
     * <code>INTERRUPT_TYPE_OPERATION_ID = 3;</code>
     */
    INTERRUPT_TYPE_OPERATION_ID(3),
    UNRECOGNIZED(-1),
    ;

    /**
     * <code>INTERRUPT_TYPE_UNSPECIFIED = 0;</code>
     */
    public static final int INTERRUPT_TYPE_UNSPECIFIED_VALUE = 0;
    /**
     * <pre>
     * Interrupt all running executions within the session with the provided session_id.
     * </pre>
     *
     * <code>INTERRUPT_TYPE_ALL = 1;</code>
     */
    public static final int INTERRUPT_TYPE_ALL_VALUE = 1;
    /**
     * <pre>
     * Interrupt all running executions within the session with the provided operation_tag.
     * </pre>
     *
     * <code>INTERRUPT_TYPE_TAG = 2;</code>
     */
    public static final int INTERRUPT_TYPE_TAG_VALUE = 2;
    /**
     * <pre>
     * Interrupt the running execution within the session with the provided operation_id.
     * </pre>
     *
     * <code>INTERRUPT_TYPE_OPERATION_ID = 3;</code>
     */
    public static final int INTERRUPT_TYPE_OPERATION_ID_VALUE = 3;


    public final int getNumber() {
      if (this == UNRECOGNIZED) {
        throw new IllegalArgumentException(
            "Can't get the number of an unknown enum value.");
      }
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @Deprecated
    public static InterruptType valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static InterruptType forNumber(int value) {
      switch (value) {
        case 0: return INTERRUPT_TYPE_UNSPECIFIED;
        case 1: return INTERRUPT_TYPE_ALL;
        case 2: return INTERRUPT_TYPE_TAG;
        case 3: return INTERRUPT_TYPE_OPERATION_ID;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<InterruptType>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        InterruptType> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<InterruptType>() {
            public InterruptType findValueByNumber(int number) {
              return InterruptType.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      if (this == UNRECOGNIZED) {
        throw new IllegalStateException(
            "Can't get the descriptor of an unrecognized enum value.");
      }
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.spark.connect.proto.InterruptRequest.getDescriptor().getEnumTypes().get(0);
    }

    private static final InterruptType[] VALUES = values();

    public static InterruptType valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      if (desc.getIndex() == -1) {
        return UNRECOGNIZED;
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private InterruptType(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:spark.connect.InterruptRequest.InterruptType)
  }

  private int bitField0_;
  private int interruptCase_ = 0;
  @SuppressWarnings("serial")
  private Object interrupt_;
  public enum InterruptCase
      implements com.google.protobuf.Internal.EnumLite,
          InternalOneOfEnum {
    OPERATION_TAG(5),
    OPERATION_ID(6),
    INTERRUPT_NOT_SET(0);
    private final int value;
    private InterruptCase(int value) {
      this.value = value;
    }
    /**
     * @param value The number of the enum to look for.
     * @return The enum associated with the given number.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @Deprecated
    public static InterruptCase valueOf(int value) {
      return forNumber(value);
    }

    public static InterruptCase forNumber(int value) {
      switch (value) {
        case 5: return OPERATION_TAG;
        case 6: return OPERATION_ID;
        case 0: return INTERRUPT_NOT_SET;
        default: return null;
      }
    }
    public int getNumber() {
      return this.value;
    }
  };

  public InterruptCase
  getInterruptCase() {
    return InterruptCase.forNumber(
        interruptCase_);
  }

  public static final int SESSION_ID_FIELD_NUMBER = 1;
  @SuppressWarnings("serial")
  private volatile Object sessionId_ = "";
  /**
   * <pre>
   * (Required)
   *
   * The session_id specifies a spark session for a user id (which is specified
   * by user_context.user_id). The session_id is set by the client to be able to
   * collate streaming responses from different queries within the dedicated session.
   * The id should be an UUID string of the format `00112233-4455-6677-8899-aabbccddeeff`
   * </pre>
   *
   * <code>string session_id = 1;</code>
   * @return The sessionId.
   */
  @Override
  public String getSessionId() {
    Object ref = sessionId_;
    if (ref instanceof String) {
      return (String) ref;
    } else {
      com.google.protobuf.ByteString bs = 
          (com.google.protobuf.ByteString) ref;
      String s = bs.toStringUtf8();
      sessionId_ = s;
      return s;
    }
  }
  /**
   * <pre>
   * (Required)
   *
   * The session_id specifies a spark session for a user id (which is specified
   * by user_context.user_id). The session_id is set by the client to be able to
   * collate streaming responses from different queries within the dedicated session.
   * The id should be an UUID string of the format `00112233-4455-6677-8899-aabbccddeeff`
   * </pre>
   *
   * <code>string session_id = 1;</code>
   * @return The bytes for sessionId.
   */
  @Override
  public com.google.protobuf.ByteString
      getSessionIdBytes() {
    Object ref = sessionId_;
    if (ref instanceof String) {
      com.google.protobuf.ByteString b = 
          com.google.protobuf.ByteString.copyFromUtf8(
              (String) ref);
      sessionId_ = b;
      return b;
    } else {
      return (com.google.protobuf.ByteString) ref;
    }
  }

  public static final int USER_CONTEXT_FIELD_NUMBER = 2;
  private org.apache.spark.connect.proto.UserContext userContext_;
  /**
   * <pre>
   * (Required) User context
   * </pre>
   *
   * <code>.spark.connect.UserContext user_context = 2;</code>
   * @return Whether the userContext field is set.
   */
  @Override
  public boolean hasUserContext() {
    return userContext_ != null;
  }
  /**
   * <pre>
   * (Required) User context
   * </pre>
   *
   * <code>.spark.connect.UserContext user_context = 2;</code>
   * @return The userContext.
   */
  @Override
  public org.apache.spark.connect.proto.UserContext getUserContext() {
    return userContext_ == null ? org.apache.spark.connect.proto.UserContext.getDefaultInstance() : userContext_;
  }
  /**
   * <pre>
   * (Required) User context
   * </pre>
   *
   * <code>.spark.connect.UserContext user_context = 2;</code>
   */
  @Override
  public org.apache.spark.connect.proto.UserContextOrBuilder getUserContextOrBuilder() {
    return userContext_ == null ? org.apache.spark.connect.proto.UserContext.getDefaultInstance() : userContext_;
  }

  public static final int CLIENT_TYPE_FIELD_NUMBER = 3;
  @SuppressWarnings("serial")
  private volatile Object clientType_ = "";
  /**
   * <pre>
   * Provides optional information about the client sending the request. This field
   * can be used for language or version specific information and is only intended for
   * logging purposes and will not be interpreted by the server.
   * </pre>
   *
   * <code>optional string client_type = 3;</code>
   * @return Whether the clientType field is set.
   */
  @Override
  public boolean hasClientType() {
    return ((bitField0_ & 0x00000001) != 0);
  }
  /**
   * <pre>
   * Provides optional information about the client sending the request. This field
   * can be used for language or version specific information and is only intended for
   * logging purposes and will not be interpreted by the server.
   * </pre>
   *
   * <code>optional string client_type = 3;</code>
   * @return The clientType.
   */
  @Override
  public String getClientType() {
    Object ref = clientType_;
    if (ref instanceof String) {
      return (String) ref;
    } else {
      com.google.protobuf.ByteString bs = 
          (com.google.protobuf.ByteString) ref;
      String s = bs.toStringUtf8();
      clientType_ = s;
      return s;
    }
  }
  /**
   * <pre>
   * Provides optional information about the client sending the request. This field
   * can be used for language or version specific information and is only intended for
   * logging purposes and will not be interpreted by the server.
   * </pre>
   *
   * <code>optional string client_type = 3;</code>
   * @return The bytes for clientType.
   */
  @Override
  public com.google.protobuf.ByteString
      getClientTypeBytes() {
    Object ref = clientType_;
    if (ref instanceof String) {
      com.google.protobuf.ByteString b = 
          com.google.protobuf.ByteString.copyFromUtf8(
              (String) ref);
      clientType_ = b;
      return b;
    } else {
      return (com.google.protobuf.ByteString) ref;
    }
  }

  public static final int INTERRUPT_TYPE_FIELD_NUMBER = 4;
  private int interruptType_ = 0;
  /**
   * <pre>
   * (Required) The type of interrupt to execute.
   * </pre>
   *
   * <code>.spark.connect.InterruptRequest.InterruptType interrupt_type = 4;</code>
   * @return The enum numeric value on the wire for interruptType.
   */
  @Override public int getInterruptTypeValue() {
    return interruptType_;
  }
  /**
   * <pre>
   * (Required) The type of interrupt to execute.
   * </pre>
   *
   * <code>.spark.connect.InterruptRequest.InterruptType interrupt_type = 4;</code>
   * @return The interruptType.
   */
  @Override public org.apache.spark.connect.proto.InterruptRequest.InterruptType getInterruptType() {
    org.apache.spark.connect.proto.InterruptRequest.InterruptType result = org.apache.spark.connect.proto.InterruptRequest.InterruptType.forNumber(interruptType_);
    return result == null ? org.apache.spark.connect.proto.InterruptRequest.InterruptType.UNRECOGNIZED : result;
  }

  public static final int OPERATION_TAG_FIELD_NUMBER = 5;
  /**
   * <pre>
   * if interrupt_tag == INTERRUPT_TYPE_TAG, interrupt operation with this tag.
   * </pre>
   *
   * <code>string operation_tag = 5;</code>
   * @return Whether the operationTag field is set.
   */
  public boolean hasOperationTag() {
    return interruptCase_ == 5;
  }
  /**
   * <pre>
   * if interrupt_tag == INTERRUPT_TYPE_TAG, interrupt operation with this tag.
   * </pre>
   *
   * <code>string operation_tag = 5;</code>
   * @return The operationTag.
   */
  public String getOperationTag() {
    Object ref = "";
    if (interruptCase_ == 5) {
      ref = interrupt_;
    }
    if (ref instanceof String) {
      return (String) ref;
    } else {
      com.google.protobuf.ByteString bs = 
          (com.google.protobuf.ByteString) ref;
      String s = bs.toStringUtf8();
      if (interruptCase_ == 5) {
        interrupt_ = s;
      }
      return s;
    }
  }
  /**
   * <pre>
   * if interrupt_tag == INTERRUPT_TYPE_TAG, interrupt operation with this tag.
   * </pre>
   *
   * <code>string operation_tag = 5;</code>
   * @return The bytes for operationTag.
   */
  public com.google.protobuf.ByteString
      getOperationTagBytes() {
    Object ref = "";
    if (interruptCase_ == 5) {
      ref = interrupt_;
    }
    if (ref instanceof String) {
      com.google.protobuf.ByteString b = 
          com.google.protobuf.ByteString.copyFromUtf8(
              (String) ref);
      if (interruptCase_ == 5) {
        interrupt_ = b;
      }
      return b;
    } else {
      return (com.google.protobuf.ByteString) ref;
    }
  }

  public static final int OPERATION_ID_FIELD_NUMBER = 6;
  /**
   * <pre>
   * if interrupt_tag == INTERRUPT_TYPE_OPERATION_ID, interrupt operation with this operation_id.
   * </pre>
   *
   * <code>string operation_id = 6;</code>
   * @return Whether the operationId field is set.
   */
  public boolean hasOperationId() {
    return interruptCase_ == 6;
  }
  /**
   * <pre>
   * if interrupt_tag == INTERRUPT_TYPE_OPERATION_ID, interrupt operation with this operation_id.
   * </pre>
   *
   * <code>string operation_id = 6;</code>
   * @return The operationId.
   */
  public String getOperationId() {
    Object ref = "";
    if (interruptCase_ == 6) {
      ref = interrupt_;
    }
    if (ref instanceof String) {
      return (String) ref;
    } else {
      com.google.protobuf.ByteString bs = 
          (com.google.protobuf.ByteString) ref;
      String s = bs.toStringUtf8();
      if (interruptCase_ == 6) {
        interrupt_ = s;
      }
      return s;
    }
  }
  /**
   * <pre>
   * if interrupt_tag == INTERRUPT_TYPE_OPERATION_ID, interrupt operation with this operation_id.
   * </pre>
   *
   * <code>string operation_id = 6;</code>
   * @return The bytes for operationId.
   */
  public com.google.protobuf.ByteString
      getOperationIdBytes() {
    Object ref = "";
    if (interruptCase_ == 6) {
      ref = interrupt_;
    }
    if (ref instanceof String) {
      com.google.protobuf.ByteString b = 
          com.google.protobuf.ByteString.copyFromUtf8(
              (String) ref);
      if (interruptCase_ == 6) {
        interrupt_ = b;
      }
      return b;
    } else {
      return (com.google.protobuf.ByteString) ref;
    }
  }

  private byte memoizedIsInitialized = -1;
  @Override
  public final boolean isInitialized() {
    byte isInitialized = memoizedIsInitialized;
    if (isInitialized == 1) return true;
    if (isInitialized == 0) return false;

    memoizedIsInitialized = 1;
    return true;
  }

  @Override
  public void writeTo(com.google.protobuf.CodedOutputStream output)
                      throws java.io.IOException {
    if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(sessionId_)) {
      com.google.protobuf.GeneratedMessageV3.writeString(output, 1, sessionId_);
    }
    if (userContext_ != null) {
      output.writeMessage(2, getUserContext());
    }
    if (((bitField0_ & 0x00000001) != 0)) {
      com.google.protobuf.GeneratedMessageV3.writeString(output, 3, clientType_);
    }
    if (interruptType_ != org.apache.spark.connect.proto.InterruptRequest.InterruptType.INTERRUPT_TYPE_UNSPECIFIED.getNumber()) {
      output.writeEnum(4, interruptType_);
    }
    if (interruptCase_ == 5) {
      com.google.protobuf.GeneratedMessageV3.writeString(output, 5, interrupt_);
    }
    if (interruptCase_ == 6) {
      com.google.protobuf.GeneratedMessageV3.writeString(output, 6, interrupt_);
    }
    getUnknownFields().writeTo(output);
  }

  @Override
  public int getSerializedSize() {
    int size = memoizedSize;
    if (size != -1) return size;

    size = 0;
    if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(sessionId_)) {
      size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, sessionId_);
    }
    if (userContext_ != null) {
      size += com.google.protobuf.CodedOutputStream
        .computeMessageSize(2, getUserContext());
    }
    if (((bitField0_ & 0x00000001) != 0)) {
      size += com.google.protobuf.GeneratedMessageV3.computeStringSize(3, clientType_);
    }
    if (interruptType_ != org.apache.spark.connect.proto.InterruptRequest.InterruptType.INTERRUPT_TYPE_UNSPECIFIED.getNumber()) {
      size += com.google.protobuf.CodedOutputStream
        .computeEnumSize(4, interruptType_);
    }
    if (interruptCase_ == 5) {
      size += com.google.protobuf.GeneratedMessageV3.computeStringSize(5, interrupt_);
    }
    if (interruptCase_ == 6) {
      size += com.google.protobuf.GeneratedMessageV3.computeStringSize(6, interrupt_);
    }
    size += getUnknownFields().getSerializedSize();
    memoizedSize = size;
    return size;
  }

  @Override
  public boolean equals(final Object obj) {
    if (obj == this) {
     return true;
    }
    if (!(obj instanceof org.apache.spark.connect.proto.InterruptRequest)) {
      return super.equals(obj);
    }
    org.apache.spark.connect.proto.InterruptRequest other = (org.apache.spark.connect.proto.InterruptRequest) obj;

    if (!getSessionId()
        .equals(other.getSessionId())) return false;
    if (hasUserContext() != other.hasUserContext()) return false;
    if (hasUserContext()) {
      if (!getUserContext()
          .equals(other.getUserContext())) return false;
    }
    if (hasClientType() != other.hasClientType()) return false;
    if (hasClientType()) {
      if (!getClientType()
          .equals(other.getClientType())) return false;
    }
    if (interruptType_ != other.interruptType_) return false;
    if (!getInterruptCase().equals(other.getInterruptCase())) return false;
    switch (interruptCase_) {
      case 5:
        if (!getOperationTag()
            .equals(other.getOperationTag())) return false;
        break;
      case 6:
        if (!getOperationId()
            .equals(other.getOperationId())) return false;
        break;
      case 0:
      default:
    }
    if (!getUnknownFields().equals(other.getUnknownFields())) return false;
    return true;
  }

  @Override
  public int hashCode() {
    if (memoizedHashCode != 0) {
      return memoizedHashCode;
    }
    int hash = 41;
    hash = (19 * hash) + getDescriptor().hashCode();
    hash = (37 * hash) + SESSION_ID_FIELD_NUMBER;
    hash = (53 * hash) + getSessionId().hashCode();
    if (hasUserContext()) {
      hash = (37 * hash) + USER_CONTEXT_FIELD_NUMBER;
      hash = (53 * hash) + getUserContext().hashCode();
    }
    if (hasClientType()) {
      hash = (37 * hash) + CLIENT_TYPE_FIELD_NUMBER;
      hash = (53 * hash) + getClientType().hashCode();
    }
    hash = (37 * hash) + INTERRUPT_TYPE_FIELD_NUMBER;
    hash = (53 * hash) + interruptType_;
    switch (interruptCase_) {
      case 5:
        hash = (37 * hash) + OPERATION_TAG_FIELD_NUMBER;
        hash = (53 * hash) + getOperationTag().hashCode();
        break;
      case 6:
        hash = (37 * hash) + OPERATION_ID_FIELD_NUMBER;
        hash = (53 * hash) + getOperationId().hashCode();
        break;
      case 0:
      default:
    }
    hash = (29 * hash) + getUnknownFields().hashCode();
    memoizedHashCode = hash;
    return hash;
  }

  public static org.apache.spark.connect.proto.InterruptRequest parseFrom(
      java.nio.ByteBuffer data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }
  public static org.apache.spark.connect.proto.InterruptRequest parseFrom(
      java.nio.ByteBuffer data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }
  public static org.apache.spark.connect.proto.InterruptRequest parseFrom(
      com.google.protobuf.ByteString data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }
  public static org.apache.spark.connect.proto.InterruptRequest parseFrom(
      com.google.protobuf.ByteString data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }
  public static org.apache.spark.connect.proto.InterruptRequest parseFrom(byte[] data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }
  public static org.apache.spark.connect.proto.InterruptRequest parseFrom(
      byte[] data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }
  public static org.apache.spark.connect.proto.InterruptRequest parseFrom(java.io.InputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input);
  }
  public static org.apache.spark.connect.proto.InterruptRequest parseFrom(
      java.io.InputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input, extensionRegistry);
  }

  public static org.apache.spark.connect.proto.InterruptRequest parseDelimitedFrom(java.io.InputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseDelimitedWithIOException(PARSER, input);
  }

  public static org.apache.spark.connect.proto.InterruptRequest parseDelimitedFrom(
      java.io.InputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
  }
  public static org.apache.spark.connect.proto.InterruptRequest parseFrom(
      com.google.protobuf.CodedInputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input);
  }
  public static org.apache.spark.connect.proto.InterruptRequest parseFrom(
      com.google.protobuf.CodedInputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input, extensionRegistry);
  }

  @Override
  public Builder newBuilderForType() { return newBuilder(); }
  public static Builder newBuilder() {
    return DEFAULT_INSTANCE.toBuilder();
  }
  public static Builder newBuilder(org.apache.spark.connect.proto.InterruptRequest prototype) {
    return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
  }
  @Override
  public Builder toBuilder() {
    return this == DEFAULT_INSTANCE
        ? new Builder() : new Builder().mergeFrom(this);
  }

  @Override
  protected Builder newBuilderForType(
      BuilderParent parent) {
    Builder builder = new Builder(parent);
    return builder;
  }
  /**
   * Protobuf type {@code spark.connect.InterruptRequest}
   */
  public static final class Builder extends
      com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
      // @@protoc_insertion_point(builder_implements:spark.connect.InterruptRequest)
      org.apache.spark.connect.proto.InterruptRequestOrBuilder {
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.spark.connect.proto.Base.internal_static_spark_connect_InterruptRequest_descriptor;
    }

    @Override
    protected FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.spark.connect.proto.Base.internal_static_spark_connect_InterruptRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.spark.connect.proto.InterruptRequest.class, org.apache.spark.connect.proto.InterruptRequest.Builder.class);
    }

    // Construct using org.apache.spark.connect.proto.InterruptRequest.newBuilder()
    private Builder() {

    }

    private Builder(
        BuilderParent parent) {
      super(parent);

    }
    @Override
    public Builder clear() {
      super.clear();
      bitField0_ = 0;
      sessionId_ = "";
      userContext_ = null;
      if (userContextBuilder_ != null) {
        userContextBuilder_.dispose();
        userContextBuilder_ = null;
      }
      clientType_ = "";
      interruptType_ = 0;
      interruptCase_ = 0;
      interrupt_ = null;
      return this;
    }

    @Override
    public com.google.protobuf.Descriptors.Descriptor
        getDescriptorForType() {
      return org.apache.spark.connect.proto.Base.internal_static_spark_connect_InterruptRequest_descriptor;
    }

    @Override
    public org.apache.spark.connect.proto.InterruptRequest getDefaultInstanceForType() {
      return org.apache.spark.connect.proto.InterruptRequest.getDefaultInstance();
    }

    @Override
    public org.apache.spark.connect.proto.InterruptRequest build() {
      org.apache.spark.connect.proto.InterruptRequest result = buildPartial();
      if (!result.isInitialized()) {
        throw newUninitializedMessageException(result);
      }
      return result;
    }

    @Override
    public org.apache.spark.connect.proto.InterruptRequest buildPartial() {
      org.apache.spark.connect.proto.InterruptRequest result = new org.apache.spark.connect.proto.InterruptRequest(this);
      if (bitField0_ != 0) { buildPartial0(result); }
      buildPartialOneofs(result);
      onBuilt();
      return result;
    }

    private void buildPartial0(org.apache.spark.connect.proto.InterruptRequest result) {
      int from_bitField0_ = bitField0_;
      if (((from_bitField0_ & 0x00000001) != 0)) {
        result.sessionId_ = sessionId_;
      }
      if (((from_bitField0_ & 0x00000002) != 0)) {
        result.userContext_ = userContextBuilder_ == null
            ? userContext_
            : userContextBuilder_.build();
      }
      int to_bitField0_ = 0;
      if (((from_bitField0_ & 0x00000004) != 0)) {
        result.clientType_ = clientType_;
        to_bitField0_ |= 0x00000001;
      }
      if (((from_bitField0_ & 0x00000008) != 0)) {
        result.interruptType_ = interruptType_;
      }
      result.bitField0_ |= to_bitField0_;
    }

    private void buildPartialOneofs(org.apache.spark.connect.proto.InterruptRequest result) {
      result.interruptCase_ = interruptCase_;
      result.interrupt_ = this.interrupt_;
    }

    @Override
    public Builder clone() {
      return super.clone();
    }
    @Override
    public Builder setField(
        com.google.protobuf.Descriptors.FieldDescriptor field,
        Object value) {
      return super.setField(field, value);
    }
    @Override
    public Builder clearField(
        com.google.protobuf.Descriptors.FieldDescriptor field) {
      return super.clearField(field);
    }
    @Override
    public Builder clearOneof(
        com.google.protobuf.Descriptors.OneofDescriptor oneof) {
      return super.clearOneof(oneof);
    }
    @Override
    public Builder setRepeatedField(
        com.google.protobuf.Descriptors.FieldDescriptor field,
        int index, Object value) {
      return super.setRepeatedField(field, index, value);
    }
    @Override
    public Builder addRepeatedField(
        com.google.protobuf.Descriptors.FieldDescriptor field,
        Object value) {
      return super.addRepeatedField(field, value);
    }
    @Override
    public Builder mergeFrom(com.google.protobuf.Message other) {
      if (other instanceof org.apache.spark.connect.proto.InterruptRequest) {
        return mergeFrom((org.apache.spark.connect.proto.InterruptRequest)other);
      } else {
        super.mergeFrom(other);
        return this;
      }
    }

    public Builder mergeFrom(org.apache.spark.connect.proto.InterruptRequest other) {
      if (other == org.apache.spark.connect.proto.InterruptRequest.getDefaultInstance()) return this;
      if (!other.getSessionId().isEmpty()) {
        sessionId_ = other.sessionId_;
        bitField0_ |= 0x00000001;
        onChanged();
      }
      if (other.hasUserContext()) {
        mergeUserContext(other.getUserContext());
      }
      if (other.hasClientType()) {
        clientType_ = other.clientType_;
        bitField0_ |= 0x00000004;
        onChanged();
      }
      if (other.interruptType_ != 0) {
        setInterruptTypeValue(other.getInterruptTypeValue());
      }
      switch (other.getInterruptCase()) {
        case OPERATION_TAG: {
          interruptCase_ = 5;
          interrupt_ = other.interrupt_;
          onChanged();
          break;
        }
        case OPERATION_ID: {
          interruptCase_ = 6;
          interrupt_ = other.interrupt_;
          onChanged();
          break;
        }
        case INTERRUPT_NOT_SET: {
          break;
        }
      }
      this.mergeUnknownFields(other.getUnknownFields());
      onChanged();
      return this;
    }

    @Override
    public final boolean isInitialized() {
      return true;
    }

    @Override
    public Builder mergeFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      if (extensionRegistry == null) {
        throw new NullPointerException();
      }
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              sessionId_ = input.readStringRequireUtf8();
              bitField0_ |= 0x00000001;
              break;
            } // case 10
            case 18: {
              input.readMessage(
                  getUserContextFieldBuilder().getBuilder(),
                  extensionRegistry);
              bitField0_ |= 0x00000002;
              break;
            } // case 18
            case 26: {
              clientType_ = input.readStringRequireUtf8();
              bitField0_ |= 0x00000004;
              break;
            } // case 26
            case 32: {
              interruptType_ = input.readEnum();
              bitField0_ |= 0x00000008;
              break;
            } // case 32
            case 42: {
              String s = input.readStringRequireUtf8();
              interruptCase_ = 5;
              interrupt_ = s;
              break;
            } // case 42
            case 50: {
              String s = input.readStringRequireUtf8();
              interruptCase_ = 6;
              interrupt_ = s;
              break;
            } // case 50
            default: {
              if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                done = true; // was an endgroup tag
              }
              break;
            } // default:
          } // switch (tag)
        } // while (!done)
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.unwrapIOException();
      } finally {
        onChanged();
      } // finally
      return this;
    }
    private int interruptCase_ = 0;
    private Object interrupt_;
    public InterruptCase
        getInterruptCase() {
      return InterruptCase.forNumber(
          interruptCase_);
    }

    public Builder clearInterrupt() {
      interruptCase_ = 0;
      interrupt_ = null;
      onChanged();
      return this;
    }

    private int bitField0_;

    private Object sessionId_ = "";
    /**
     * <pre>
     * (Required)
     *
     * The session_id specifies a spark session for a user id (which is specified
     * by user_context.user_id). The session_id is set by the client to be able to
     * collate streaming responses from different queries within the dedicated session.
     * The id should be an UUID string of the format `00112233-4455-6677-8899-aabbccddeeff`
     * </pre>
     *
     * <code>string session_id = 1;</code>
     * @return The sessionId.
     */
    public String getSessionId() {
      Object ref = sessionId_;
      if (!(ref instanceof String)) {
        com.google.protobuf.ByteString bs =
            (com.google.protobuf.ByteString) ref;
        String s = bs.toStringUtf8();
        sessionId_ = s;
        return s;
      } else {
        return (String) ref;
      }
    }
    /**
     * <pre>
     * (Required)
     *
     * The session_id specifies a spark session for a user id (which is specified
     * by user_context.user_id). The session_id is set by the client to be able to
     * collate streaming responses from different queries within the dedicated session.
     * The id should be an UUID string of the format `00112233-4455-6677-8899-aabbccddeeff`
     * </pre>
     *
     * <code>string session_id = 1;</code>
     * @return The bytes for sessionId.
     */
    public com.google.protobuf.ByteString
        getSessionIdBytes() {
      Object ref = sessionId_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (String) ref);
        sessionId_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }
    /**
     * <pre>
     * (Required)
     *
     * The session_id specifies a spark session for a user id (which is specified
     * by user_context.user_id). The session_id is set by the client to be able to
     * collate streaming responses from different queries within the dedicated session.
     * The id should be an UUID string of the format `00112233-4455-6677-8899-aabbccddeeff`
     * </pre>
     *
     * <code>string session_id = 1;</code>
     * @param value The sessionId to set.
     * @return This builder for chaining.
     */
    public Builder setSessionId(
        String value) {
      if (value == null) { throw new NullPointerException(); }
      sessionId_ = value;
      bitField0_ |= 0x00000001;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * (Required)
     *
     * The session_id specifies a spark session for a user id (which is specified
     * by user_context.user_id). The session_id is set by the client to be able to
     * collate streaming responses from different queries within the dedicated session.
     * The id should be an UUID string of the format `00112233-4455-6677-8899-aabbccddeeff`
     * </pre>
     *
     * <code>string session_id = 1;</code>
     * @return This builder for chaining.
     */
    public Builder clearSessionId() {
      sessionId_ = getDefaultInstance().getSessionId();
      bitField0_ = (bitField0_ & ~0x00000001);
      onChanged();
      return this;
    }
    /**
     * <pre>
     * (Required)
     *
     * The session_id specifies a spark session for a user id (which is specified
     * by user_context.user_id). The session_id is set by the client to be able to
     * collate streaming responses from different queries within the dedicated session.
     * The id should be an UUID string of the format `00112233-4455-6677-8899-aabbccddeeff`
     * </pre>
     *
     * <code>string session_id = 1;</code>
     * @param value The bytes for sessionId to set.
     * @return This builder for chaining.
     */
    public Builder setSessionIdBytes(
        com.google.protobuf.ByteString value) {
      if (value == null) { throw new NullPointerException(); }
      checkByteStringIsUtf8(value);
      sessionId_ = value;
      bitField0_ |= 0x00000001;
      onChanged();
      return this;
    }

    private org.apache.spark.connect.proto.UserContext userContext_;
    private com.google.protobuf.SingleFieldBuilderV3<
        org.apache.spark.connect.proto.UserContext, org.apache.spark.connect.proto.UserContext.Builder, org.apache.spark.connect.proto.UserContextOrBuilder> userContextBuilder_;
    /**
     * <pre>
     * (Required) User context
     * </pre>
     *
     * <code>.spark.connect.UserContext user_context = 2;</code>
     * @return Whether the userContext field is set.
     */
    public boolean hasUserContext() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     * <pre>
     * (Required) User context
     * </pre>
     *
     * <code>.spark.connect.UserContext user_context = 2;</code>
     * @return The userContext.
     */
    public org.apache.spark.connect.proto.UserContext getUserContext() {
      if (userContextBuilder_ == null) {
        return userContext_ == null ? org.apache.spark.connect.proto.UserContext.getDefaultInstance() : userContext_;
      } else {
        return userContextBuilder_.getMessage();
      }
    }
    /**
     * <pre>
     * (Required) User context
     * </pre>
     *
     * <code>.spark.connect.UserContext user_context = 2;</code>
     */
    public Builder setUserContext(org.apache.spark.connect.proto.UserContext value) {
      if (userContextBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        userContext_ = value;
      } else {
        userContextBuilder_.setMessage(value);
      }
      bitField0_ |= 0x00000002;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * (Required) User context
     * </pre>
     *
     * <code>.spark.connect.UserContext user_context = 2;</code>
     */
    public Builder setUserContext(
        org.apache.spark.connect.proto.UserContext.Builder builderForValue) {
      if (userContextBuilder_ == null) {
        userContext_ = builderForValue.build();
      } else {
        userContextBuilder_.setMessage(builderForValue.build());
      }
      bitField0_ |= 0x00000002;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * (Required) User context
     * </pre>
     *
     * <code>.spark.connect.UserContext user_context = 2;</code>
     */
    public Builder mergeUserContext(org.apache.spark.connect.proto.UserContext value) {
      if (userContextBuilder_ == null) {
        if (((bitField0_ & 0x00000002) != 0) &&
          userContext_ != null &&
          userContext_ != org.apache.spark.connect.proto.UserContext.getDefaultInstance()) {
          getUserContextBuilder().mergeFrom(value);
        } else {
          userContext_ = value;
        }
      } else {
        userContextBuilder_.mergeFrom(value);
      }
      bitField0_ |= 0x00000002;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * (Required) User context
     * </pre>
     *
     * <code>.spark.connect.UserContext user_context = 2;</code>
     */
    public Builder clearUserContext() {
      bitField0_ = (bitField0_ & ~0x00000002);
      userContext_ = null;
      if (userContextBuilder_ != null) {
        userContextBuilder_.dispose();
        userContextBuilder_ = null;
      }
      onChanged();
      return this;
    }
    /**
     * <pre>
     * (Required) User context
     * </pre>
     *
     * <code>.spark.connect.UserContext user_context = 2;</code>
     */
    public org.apache.spark.connect.proto.UserContext.Builder getUserContextBuilder() {
      bitField0_ |= 0x00000002;
      onChanged();
      return getUserContextFieldBuilder().getBuilder();
    }
    /**
     * <pre>
     * (Required) User context
     * </pre>
     *
     * <code>.spark.connect.UserContext user_context = 2;</code>
     */
    public org.apache.spark.connect.proto.UserContextOrBuilder getUserContextOrBuilder() {
      if (userContextBuilder_ != null) {
        return userContextBuilder_.getMessageOrBuilder();
      } else {
        return userContext_ == null ?
            org.apache.spark.connect.proto.UserContext.getDefaultInstance() : userContext_;
      }
    }
    /**
     * <pre>
     * (Required) User context
     * </pre>
     *
     * <code>.spark.connect.UserContext user_context = 2;</code>
     */
    private com.google.protobuf.SingleFieldBuilderV3<
        org.apache.spark.connect.proto.UserContext, org.apache.spark.connect.proto.UserContext.Builder, org.apache.spark.connect.proto.UserContextOrBuilder> 
        getUserContextFieldBuilder() {
      if (userContextBuilder_ == null) {
        userContextBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
            org.apache.spark.connect.proto.UserContext, org.apache.spark.connect.proto.UserContext.Builder, org.apache.spark.connect.proto.UserContextOrBuilder>(
                getUserContext(),
                getParentForChildren(),
                isClean());
        userContext_ = null;
      }
      return userContextBuilder_;
    }

    private Object clientType_ = "";
    /**
     * <pre>
     * Provides optional information about the client sending the request. This field
     * can be used for language or version specific information and is only intended for
     * logging purposes and will not be interpreted by the server.
     * </pre>
     *
     * <code>optional string client_type = 3;</code>
     * @return Whether the clientType field is set.
     */
    public boolean hasClientType() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     * <pre>
     * Provides optional information about the client sending the request. This field
     * can be used for language or version specific information and is only intended for
     * logging purposes and will not be interpreted by the server.
     * </pre>
     *
     * <code>optional string client_type = 3;</code>
     * @return The clientType.
     */
    public String getClientType() {
      Object ref = clientType_;
      if (!(ref instanceof String)) {
        com.google.protobuf.ByteString bs =
            (com.google.protobuf.ByteString) ref;
        String s = bs.toStringUtf8();
        clientType_ = s;
        return s;
      } else {
        return (String) ref;
      }
    }
    /**
     * <pre>
     * Provides optional information about the client sending the request. This field
     * can be used for language or version specific information and is only intended for
     * logging purposes and will not be interpreted by the server.
     * </pre>
     *
     * <code>optional string client_type = 3;</code>
     * @return The bytes for clientType.
     */
    public com.google.protobuf.ByteString
        getClientTypeBytes() {
      Object ref = clientType_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (String) ref);
        clientType_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }
    /**
     * <pre>
     * Provides optional information about the client sending the request. This field
     * can be used for language or version specific information and is only intended for
     * logging purposes and will not be interpreted by the server.
     * </pre>
     *
     * <code>optional string client_type = 3;</code>
     * @param value The clientType to set.
     * @return This builder for chaining.
     */
    public Builder setClientType(
        String value) {
      if (value == null) { throw new NullPointerException(); }
      clientType_ = value;
      bitField0_ |= 0x00000004;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Provides optional information about the client sending the request. This field
     * can be used for language or version specific information and is only intended for
     * logging purposes and will not be interpreted by the server.
     * </pre>
     *
     * <code>optional string client_type = 3;</code>
     * @return This builder for chaining.
     */
    public Builder clearClientType() {
      clientType_ = getDefaultInstance().getClientType();
      bitField0_ = (bitField0_ & ~0x00000004);
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Provides optional information about the client sending the request. This field
     * can be used for language or version specific information and is only intended for
     * logging purposes and will not be interpreted by the server.
     * </pre>
     *
     * <code>optional string client_type = 3;</code>
     * @param value The bytes for clientType to set.
     * @return This builder for chaining.
     */
    public Builder setClientTypeBytes(
        com.google.protobuf.ByteString value) {
      if (value == null) { throw new NullPointerException(); }
      checkByteStringIsUtf8(value);
      clientType_ = value;
      bitField0_ |= 0x00000004;
      onChanged();
      return this;
    }

    private int interruptType_ = 0;
    /**
     * <pre>
     * (Required) The type of interrupt to execute.
     * </pre>
     *
     * <code>.spark.connect.InterruptRequest.InterruptType interrupt_type = 4;</code>
     * @return The enum numeric value on the wire for interruptType.
     */
    @Override public int getInterruptTypeValue() {
      return interruptType_;
    }
    /**
     * <pre>
     * (Required) The type of interrupt to execute.
     * </pre>
     *
     * <code>.spark.connect.InterruptRequest.InterruptType interrupt_type = 4;</code>
     * @param value The enum numeric value on the wire for interruptType to set.
     * @return This builder for chaining.
     */
    public Builder setInterruptTypeValue(int value) {
      interruptType_ = value;
      bitField0_ |= 0x00000008;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * (Required) The type of interrupt to execute.
     * </pre>
     *
     * <code>.spark.connect.InterruptRequest.InterruptType interrupt_type = 4;</code>
     * @return The interruptType.
     */
    @Override
    public org.apache.spark.connect.proto.InterruptRequest.InterruptType getInterruptType() {
      org.apache.spark.connect.proto.InterruptRequest.InterruptType result = org.apache.spark.connect.proto.InterruptRequest.InterruptType.forNumber(interruptType_);
      return result == null ? org.apache.spark.connect.proto.InterruptRequest.InterruptType.UNRECOGNIZED : result;
    }
    /**
     * <pre>
     * (Required) The type of interrupt to execute.
     * </pre>
     *
     * <code>.spark.connect.InterruptRequest.InterruptType interrupt_type = 4;</code>
     * @param value The interruptType to set.
     * @return This builder for chaining.
     */
    public Builder setInterruptType(org.apache.spark.connect.proto.InterruptRequest.InterruptType value) {
      if (value == null) {
        throw new NullPointerException();
      }
      bitField0_ |= 0x00000008;
      interruptType_ = value.getNumber();
      onChanged();
      return this;
    }
    /**
     * <pre>
     * (Required) The type of interrupt to execute.
     * </pre>
     *
     * <code>.spark.connect.InterruptRequest.InterruptType interrupt_type = 4;</code>
     * @return This builder for chaining.
     */
    public Builder clearInterruptType() {
      bitField0_ = (bitField0_ & ~0x00000008);
      interruptType_ = 0;
      onChanged();
      return this;
    }

    /**
     * <pre>
     * if interrupt_tag == INTERRUPT_TYPE_TAG, interrupt operation with this tag.
     * </pre>
     *
     * <code>string operation_tag = 5;</code>
     * @return Whether the operationTag field is set.
     */
    @Override
    public boolean hasOperationTag() {
      return interruptCase_ == 5;
    }
    /**
     * <pre>
     * if interrupt_tag == INTERRUPT_TYPE_TAG, interrupt operation with this tag.
     * </pre>
     *
     * <code>string operation_tag = 5;</code>
     * @return The operationTag.
     */
    @Override
    public String getOperationTag() {
      Object ref = "";
      if (interruptCase_ == 5) {
        ref = interrupt_;
      }
      if (!(ref instanceof String)) {
        com.google.protobuf.ByteString bs =
            (com.google.protobuf.ByteString) ref;
        String s = bs.toStringUtf8();
        if (interruptCase_ == 5) {
          interrupt_ = s;
        }
        return s;
      } else {
        return (String) ref;
      }
    }
    /**
     * <pre>
     * if interrupt_tag == INTERRUPT_TYPE_TAG, interrupt operation with this tag.
     * </pre>
     *
     * <code>string operation_tag = 5;</code>
     * @return The bytes for operationTag.
     */
    @Override
    public com.google.protobuf.ByteString
        getOperationTagBytes() {
      Object ref = "";
      if (interruptCase_ == 5) {
        ref = interrupt_;
      }
      if (ref instanceof String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (String) ref);
        if (interruptCase_ == 5) {
          interrupt_ = b;
        }
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }
    /**
     * <pre>
     * if interrupt_tag == INTERRUPT_TYPE_TAG, interrupt operation with this tag.
     * </pre>
     *
     * <code>string operation_tag = 5;</code>
     * @param value The operationTag to set.
     * @return This builder for chaining.
     */
    public Builder setOperationTag(
        String value) {
      if (value == null) { throw new NullPointerException(); }
      interruptCase_ = 5;
      interrupt_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * if interrupt_tag == INTERRUPT_TYPE_TAG, interrupt operation with this tag.
     * </pre>
     *
     * <code>string operation_tag = 5;</code>
     * @return This builder for chaining.
     */
    public Builder clearOperationTag() {
      if (interruptCase_ == 5) {
        interruptCase_ = 0;
        interrupt_ = null;
        onChanged();
      }
      return this;
    }
    /**
     * <pre>
     * if interrupt_tag == INTERRUPT_TYPE_TAG, interrupt operation with this tag.
     * </pre>
     *
     * <code>string operation_tag = 5;</code>
     * @param value The bytes for operationTag to set.
     * @return This builder for chaining.
     */
    public Builder setOperationTagBytes(
        com.google.protobuf.ByteString value) {
      if (value == null) { throw new NullPointerException(); }
      checkByteStringIsUtf8(value);
      interruptCase_ = 5;
      interrupt_ = value;
      onChanged();
      return this;
    }

    /**
     * <pre>
     * if interrupt_tag == INTERRUPT_TYPE_OPERATION_ID, interrupt operation with this operation_id.
     * </pre>
     *
     * <code>string operation_id = 6;</code>
     * @return Whether the operationId field is set.
     */
    @Override
    public boolean hasOperationId() {
      return interruptCase_ == 6;
    }
    /**
     * <pre>
     * if interrupt_tag == INTERRUPT_TYPE_OPERATION_ID, interrupt operation with this operation_id.
     * </pre>
     *
     * <code>string operation_id = 6;</code>
     * @return The operationId.
     */
    @Override
    public String getOperationId() {
      Object ref = "";
      if (interruptCase_ == 6) {
        ref = interrupt_;
      }
      if (!(ref instanceof String)) {
        com.google.protobuf.ByteString bs =
            (com.google.protobuf.ByteString) ref;
        String s = bs.toStringUtf8();
        if (interruptCase_ == 6) {
          interrupt_ = s;
        }
        return s;
      } else {
        return (String) ref;
      }
    }
    /**
     * <pre>
     * if interrupt_tag == INTERRUPT_TYPE_OPERATION_ID, interrupt operation with this operation_id.
     * </pre>
     *
     * <code>string operation_id = 6;</code>
     * @return The bytes for operationId.
     */
    @Override
    public com.google.protobuf.ByteString
        getOperationIdBytes() {
      Object ref = "";
      if (interruptCase_ == 6) {
        ref = interrupt_;
      }
      if (ref instanceof String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (String) ref);
        if (interruptCase_ == 6) {
          interrupt_ = b;
        }
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }
    /**
     * <pre>
     * if interrupt_tag == INTERRUPT_TYPE_OPERATION_ID, interrupt operation with this operation_id.
     * </pre>
     *
     * <code>string operation_id = 6;</code>
     * @param value The operationId to set.
     * @return This builder for chaining.
     */
    public Builder setOperationId(
        String value) {
      if (value == null) { throw new NullPointerException(); }
      interruptCase_ = 6;
      interrupt_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * if interrupt_tag == INTERRUPT_TYPE_OPERATION_ID, interrupt operation with this operation_id.
     * </pre>
     *
     * <code>string operation_id = 6;</code>
     * @return This builder for chaining.
     */
    public Builder clearOperationId() {
      if (interruptCase_ == 6) {
        interruptCase_ = 0;
        interrupt_ = null;
        onChanged();
      }
      return this;
    }
    /**
     * <pre>
     * if interrupt_tag == INTERRUPT_TYPE_OPERATION_ID, interrupt operation with this operation_id.
     * </pre>
     *
     * <code>string operation_id = 6;</code>
     * @param value The bytes for operationId to set.
     * @return This builder for chaining.
     */
    public Builder setOperationIdBytes(
        com.google.protobuf.ByteString value) {
      if (value == null) { throw new NullPointerException(); }
      checkByteStringIsUtf8(value);
      interruptCase_ = 6;
      interrupt_ = value;
      onChanged();
      return this;
    }
    @Override
    public final Builder setUnknownFields(
        final com.google.protobuf.UnknownFieldSet unknownFields) {
      return super.setUnknownFields(unknownFields);
    }

    @Override
    public final Builder mergeUnknownFields(
        final com.google.protobuf.UnknownFieldSet unknownFields) {
      return super.mergeUnknownFields(unknownFields);
    }


    // @@protoc_insertion_point(builder_scope:spark.connect.InterruptRequest)
  }

  // @@protoc_insertion_point(class_scope:spark.connect.InterruptRequest)
  private static final org.apache.spark.connect.proto.InterruptRequest DEFAULT_INSTANCE;
  static {
    DEFAULT_INSTANCE = new org.apache.spark.connect.proto.InterruptRequest();
  }

  public static org.apache.spark.connect.proto.InterruptRequest getDefaultInstance() {
    return DEFAULT_INSTANCE;
  }

  private static final com.google.protobuf.Parser<InterruptRequest>
      PARSER = new com.google.protobuf.AbstractParser<InterruptRequest>() {
    @Override
    public InterruptRequest parsePartialFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      Builder builder = newBuilder();
      try {
        builder.mergeFrom(input, extensionRegistry);
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(builder.buildPartial());
      } catch (com.google.protobuf.UninitializedMessageException e) {
        throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(e)
            .setUnfinishedMessage(builder.buildPartial());
      }
      return builder.buildPartial();
    }
  };

  public static com.google.protobuf.Parser<InterruptRequest> parser() {
    return PARSER;
  }

  @Override
  public com.google.protobuf.Parser<InterruptRequest> getParserForType() {
    return PARSER;
  }

  @Override
  public org.apache.spark.connect.proto.InterruptRequest getDefaultInstanceForType() {
    return DEFAULT_INSTANCE;
  }

}

