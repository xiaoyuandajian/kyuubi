// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: spark/connect/base.proto

package org.apache.kyuubi.engine.spark.connect.proto;

public interface ExecutePlanResponseOrBuilder extends
    // @@protoc_insertion_point(interface_extends:spark.connect.ExecutePlanResponse)
    com.google.protobuf.MessageOrBuilder {

  /**
   * <code>string session_id = 1;</code>
   * @return The sessionId.
   */
  String getSessionId();
  /**
   * <code>string session_id = 1;</code>
   * @return The bytes for sessionId.
   */
  com.google.protobuf.ByteString
      getSessionIdBytes();

  /**
   * <pre>
   * Identifies the ExecutePlan execution.
   * If set by the client in ExecutePlanRequest.operationId, that value is returned.
   * Otherwise generated by the server.
   * It is an UUID string of the format `00112233-4455-6677-8899-aabbccddeeff`
   * </pre>
   *
   * <code>string operation_id = 12;</code>
   * @return The operationId.
   */
  String getOperationId();
  /**
   * <pre>
   * Identifies the ExecutePlan execution.
   * If set by the client in ExecutePlanRequest.operationId, that value is returned.
   * Otherwise generated by the server.
   * It is an UUID string of the format `00112233-4455-6677-8899-aabbccddeeff`
   * </pre>
   *
   * <code>string operation_id = 12;</code>
   * @return The bytes for operationId.
   */
  com.google.protobuf.ByteString
      getOperationIdBytes();

  /**
   * <pre>
   * Identified the response in the stream.
   * The id is an UUID string of the format `00112233-4455-6677-8899-aabbccddeeff`
   * </pre>
   *
   * <code>string response_id = 13;</code>
   * @return The responseId.
   */
  String getResponseId();
  /**
   * <pre>
   * Identified the response in the stream.
   * The id is an UUID string of the format `00112233-4455-6677-8899-aabbccddeeff`
   * </pre>
   *
   * <code>string response_id = 13;</code>
   * @return The bytes for responseId.
   */
  com.google.protobuf.ByteString
      getResponseIdBytes();

  /**
   * <code>.spark.connect.ExecutePlanResponse.ArrowBatch arrow_batch = 2;</code>
   * @return Whether the arrowBatch field is set.
   */
  boolean hasArrowBatch();
  /**
   * <code>.spark.connect.ExecutePlanResponse.ArrowBatch arrow_batch = 2;</code>
   * @return The arrowBatch.
   */
  org.apache.spark.connect.proto.ExecutePlanResponse.ArrowBatch getArrowBatch();
  /**
   * <code>.spark.connect.ExecutePlanResponse.ArrowBatch arrow_batch = 2;</code>
   */
  org.apache.spark.connect.proto.ExecutePlanResponse.ArrowBatchOrBuilder getArrowBatchOrBuilder();

  /**
   * <pre>
   * Special case for executing SQL commands.
   * </pre>
   *
   * <code>.spark.connect.ExecutePlanResponse.SqlCommandResult sql_command_result = 5;</code>
   * @return Whether the sqlCommandResult field is set.
   */
  boolean hasSqlCommandResult();
  /**
   * <pre>
   * Special case for executing SQL commands.
   * </pre>
   *
   * <code>.spark.connect.ExecutePlanResponse.SqlCommandResult sql_command_result = 5;</code>
   * @return The sqlCommandResult.
   */
  org.apache.spark.connect.proto.ExecutePlanResponse.SqlCommandResult getSqlCommandResult();
  /**
   * <pre>
   * Special case for executing SQL commands.
   * </pre>
   *
   * <code>.spark.connect.ExecutePlanResponse.SqlCommandResult sql_command_result = 5;</code>
   */
  org.apache.spark.connect.proto.ExecutePlanResponse.SqlCommandResultOrBuilder getSqlCommandResultOrBuilder();

  /**
   * <pre>
   * Response for a streaming query.
   * </pre>
   *
   * <code>.spark.connect.WriteStreamOperationStartResult write_stream_operation_start_result = 8;</code>
   * @return Whether the writeStreamOperationStartResult field is set.
   */
  boolean hasWriteStreamOperationStartResult();
  /**
   * <pre>
   * Response for a streaming query.
   * </pre>
   *
   * <code>.spark.connect.WriteStreamOperationStartResult write_stream_operation_start_result = 8;</code>
   * @return The writeStreamOperationStartResult.
   */
  org.apache.spark.connect.proto.WriteStreamOperationStartResult getWriteStreamOperationStartResult();
  /**
   * <pre>
   * Response for a streaming query.
   * </pre>
   *
   * <code>.spark.connect.WriteStreamOperationStartResult write_stream_operation_start_result = 8;</code>
   */
  org.apache.spark.connect.proto.WriteStreamOperationStartResultOrBuilder getWriteStreamOperationStartResultOrBuilder();

  /**
   * <pre>
   * Response for commands on a streaming query.
   * </pre>
   *
   * <code>.spark.connect.StreamingQueryCommandResult streaming_query_command_result = 9;</code>
   * @return Whether the streamingQueryCommandResult field is set.
   */
  boolean hasStreamingQueryCommandResult();
  /**
   * <pre>
   * Response for commands on a streaming query.
   * </pre>
   *
   * <code>.spark.connect.StreamingQueryCommandResult streaming_query_command_result = 9;</code>
   * @return The streamingQueryCommandResult.
   */
  org.apache.spark.connect.proto.StreamingQueryCommandResult getStreamingQueryCommandResult();
  /**
   * <pre>
   * Response for commands on a streaming query.
   * </pre>
   *
   * <code>.spark.connect.StreamingQueryCommandResult streaming_query_command_result = 9;</code>
   */
  org.apache.spark.connect.proto.StreamingQueryCommandResultOrBuilder getStreamingQueryCommandResultOrBuilder();

  /**
   * <pre>
   * Response for 'SparkContext.resources'.
   * </pre>
   *
   * <code>.spark.connect.GetResourcesCommandResult get_resources_command_result = 10;</code>
   * @return Whether the getResourcesCommandResult field is set.
   */
  boolean hasGetResourcesCommandResult();
  /**
   * <pre>
   * Response for 'SparkContext.resources'.
   * </pre>
   *
   * <code>.spark.connect.GetResourcesCommandResult get_resources_command_result = 10;</code>
   * @return The getResourcesCommandResult.
   */
  org.apache.spark.connect.proto.GetResourcesCommandResult getGetResourcesCommandResult();
  /**
   * <pre>
   * Response for 'SparkContext.resources'.
   * </pre>
   *
   * <code>.spark.connect.GetResourcesCommandResult get_resources_command_result = 10;</code>
   */
  org.apache.spark.connect.proto.GetResourcesCommandResultOrBuilder getGetResourcesCommandResultOrBuilder();

  /**
   * <pre>
   * Response for commands on the streaming query manager.
   * </pre>
   *
   * <code>.spark.connect.StreamingQueryManagerCommandResult streaming_query_manager_command_result = 11;</code>
   * @return Whether the streamingQueryManagerCommandResult field is set.
   */
  boolean hasStreamingQueryManagerCommandResult();
  /**
   * <pre>
   * Response for commands on the streaming query manager.
   * </pre>
   *
   * <code>.spark.connect.StreamingQueryManagerCommandResult streaming_query_manager_command_result = 11;</code>
   * @return The streamingQueryManagerCommandResult.
   */
  org.apache.spark.connect.proto.StreamingQueryManagerCommandResult getStreamingQueryManagerCommandResult();
  /**
   * <pre>
   * Response for commands on the streaming query manager.
   * </pre>
   *
   * <code>.spark.connect.StreamingQueryManagerCommandResult streaming_query_manager_command_result = 11;</code>
   */
  org.apache.spark.connect.proto.StreamingQueryManagerCommandResultOrBuilder getStreamingQueryManagerCommandResultOrBuilder();

  /**
   * <pre>
   * Response type informing if the stream is complete in reattachable execution.
   * </pre>
   *
   * <code>.spark.connect.ExecutePlanResponse.ResultComplete result_complete = 14;</code>
   * @return Whether the resultComplete field is set.
   */
  boolean hasResultComplete();
  /**
   * <pre>
   * Response type informing if the stream is complete in reattachable execution.
   * </pre>
   *
   * <code>.spark.connect.ExecutePlanResponse.ResultComplete result_complete = 14;</code>
   * @return The resultComplete.
   */
  org.apache.spark.connect.proto.ExecutePlanResponse.ResultComplete getResultComplete();
  /**
   * <pre>
   * Response type informing if the stream is complete in reattachable execution.
   * </pre>
   *
   * <code>.spark.connect.ExecutePlanResponse.ResultComplete result_complete = 14;</code>
   */
  org.apache.spark.connect.proto.ExecutePlanResponse.ResultCompleteOrBuilder getResultCompleteOrBuilder();

  /**
   * <pre>
   * Support arbitrary result objects.
   * </pre>
   *
   * <code>.google.protobuf.Any extension = 999;</code>
   * @return Whether the extension field is set.
   */
  boolean hasExtension();
  /**
   * <pre>
   * Support arbitrary result objects.
   * </pre>
   *
   * <code>.google.protobuf.Any extension = 999;</code>
   * @return The extension.
   */
  com.google.protobuf.Any getExtension();
  /**
   * <pre>
   * Support arbitrary result objects.
   * </pre>
   *
   * <code>.google.protobuf.Any extension = 999;</code>
   */
  com.google.protobuf.AnyOrBuilder getExtensionOrBuilder();

  /**
   * <pre>
   * Metrics for the query execution. Typically, this field is only present in the last
   * batch of results and then represent the overall state of the query execution.
   * </pre>
   *
   * <code>.spark.connect.ExecutePlanResponse.Metrics metrics = 4;</code>
   * @return Whether the metrics field is set.
   */
  boolean hasMetrics();
  /**
   * <pre>
   * Metrics for the query execution. Typically, this field is only present in the last
   * batch of results and then represent the overall state of the query execution.
   * </pre>
   *
   * <code>.spark.connect.ExecutePlanResponse.Metrics metrics = 4;</code>
   * @return The metrics.
   */
  org.apache.spark.connect.proto.ExecutePlanResponse.Metrics getMetrics();
  /**
   * <pre>
   * Metrics for the query execution. Typically, this field is only present in the last
   * batch of results and then represent the overall state of the query execution.
   * </pre>
   *
   * <code>.spark.connect.ExecutePlanResponse.Metrics metrics = 4;</code>
   */
  org.apache.spark.connect.proto.ExecutePlanResponse.MetricsOrBuilder getMetricsOrBuilder();

  /**
   * <pre>
   * The metrics observed during the execution of the query plan.
   * </pre>
   *
   * <code>repeated .spark.connect.ExecutePlanResponse.ObservedMetrics observed_metrics = 6;</code>
   */
  java.util.List<org.apache.spark.connect.proto.ExecutePlanResponse.ObservedMetrics> 
      getObservedMetricsList();
  /**
   * <pre>
   * The metrics observed during the execution of the query plan.
   * </pre>
   *
   * <code>repeated .spark.connect.ExecutePlanResponse.ObservedMetrics observed_metrics = 6;</code>
   */
  org.apache.spark.connect.proto.ExecutePlanResponse.ObservedMetrics getObservedMetrics(int index);
  /**
   * <pre>
   * The metrics observed during the execution of the query plan.
   * </pre>
   *
   * <code>repeated .spark.connect.ExecutePlanResponse.ObservedMetrics observed_metrics = 6;</code>
   */
  int getObservedMetricsCount();
  /**
   * <pre>
   * The metrics observed during the execution of the query plan.
   * </pre>
   *
   * <code>repeated .spark.connect.ExecutePlanResponse.ObservedMetrics observed_metrics = 6;</code>
   */
  java.util.List<? extends org.apache.spark.connect.proto.ExecutePlanResponse.ObservedMetricsOrBuilder> 
      getObservedMetricsOrBuilderList();
  /**
   * <pre>
   * The metrics observed during the execution of the query plan.
   * </pre>
   *
   * <code>repeated .spark.connect.ExecutePlanResponse.ObservedMetrics observed_metrics = 6;</code>
   */
  org.apache.spark.connect.proto.ExecutePlanResponse.ObservedMetricsOrBuilder getObservedMetricsOrBuilder(
      int index);

  /**
   * <pre>
   * (Optional) The Spark schema. This field is available when `collect` is called.
   * </pre>
   *
   * <code>.spark.connect.DataType schema = 7;</code>
   * @return Whether the schema field is set.
   */
  boolean hasSchema();
  /**
   * <pre>
   * (Optional) The Spark schema. This field is available when `collect` is called.
   * </pre>
   *
   * <code>.spark.connect.DataType schema = 7;</code>
   * @return The schema.
   */
  org.apache.spark.connect.proto.DataType getSchema();
  /**
   * <pre>
   * (Optional) The Spark schema. This field is available when `collect` is called.
   * </pre>
   *
   * <code>.spark.connect.DataType schema = 7;</code>
   */
  org.apache.spark.connect.proto.DataTypeOrBuilder getSchemaOrBuilder();

  org.apache.spark.connect.proto.ExecutePlanResponse.ResponseTypeCase getResponseTypeCase();
}
