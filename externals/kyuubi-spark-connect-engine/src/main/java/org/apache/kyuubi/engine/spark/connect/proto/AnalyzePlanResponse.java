// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: spark/connect/base.proto

package org.apache.kyuubi.engine.spark.connect.proto;

/**
 * <pre>
 * Response to performing analysis of the query. Contains relevant metadata to be able to
 * reason about the performance.
 * </pre>
 *
 * Protobuf type {@code spark.connect.AnalyzePlanResponse}
 */
public final class AnalyzePlanResponse extends
    com.google.protobuf.GeneratedMessageV3 implements
    // @@protoc_insertion_point(message_implements:spark.connect.AnalyzePlanResponse)
    AnalyzePlanResponseOrBuilder {
private static final long serialVersionUID = 0L;
  // Use AnalyzePlanResponse.newBuilder() to construct.
  private AnalyzePlanResponse(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
    super(builder);
  }
  private AnalyzePlanResponse() {
    sessionId_ = "";
  }

  @java.lang.Override
  @SuppressWarnings({"unused"})
  protected java.lang.Object newInstance(
      UnusedPrivateParameter unused) {
    return new AnalyzePlanResponse();
  }

  @java.lang.Override
  public final com.google.protobuf.UnknownFieldSet
  getUnknownFields() {
    return this.unknownFields;
  }
  public static final com.google.protobuf.Descriptors.Descriptor
      getDescriptor() {
    return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_descriptor;
  }

  @java.lang.Override
  protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internalGetFieldAccessorTable() {
    return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_fieldAccessorTable
        .ensureFieldAccessorsInitialized(
            org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.class, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Builder.class);
  }

  public interface SchemaOrBuilder extends
      // @@protoc_insertion_point(interface_extends:spark.connect.AnalyzePlanResponse.Schema)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>.spark.connect.DataType schema = 1;</code>
     * @return Whether the schema field is set.
     */
    boolean hasSchema();
    /**
     * <code>.spark.connect.DataType schema = 1;</code>
     * @return The schema.
     */
    org.apache.kyuubi.engine.spark.connect.proto.DataType getSchema();
    /**
     * <code>.spark.connect.DataType schema = 1;</code>
     */
    org.apache.kyuubi.engine.spark.connect.proto.DataTypeOrBuilder getSchemaOrBuilder();
  }
  /**
   * Protobuf type {@code spark.connect.AnalyzePlanResponse.Schema}
   */
  public static final class Schema extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:spark.connect.AnalyzePlanResponse.Schema)
      SchemaOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use Schema.newBuilder() to construct.
    private Schema(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private Schema() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new Schema();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_Schema_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_Schema_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema.class, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema.Builder.class);
    }

    public static final int SCHEMA_FIELD_NUMBER = 1;
    private org.apache.kyuubi.engine.spark.connect.proto.DataType schema_;
    /**
     * <code>.spark.connect.DataType schema = 1;</code>
     * @return Whether the schema field is set.
     */
    @java.lang.Override
    public boolean hasSchema() {
      return schema_ != null;
    }
    /**
     * <code>.spark.connect.DataType schema = 1;</code>
     * @return The schema.
     */
    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.DataType getSchema() {
      return schema_ == null ? org.apache.kyuubi.engine.spark.connect.proto.DataType.getDefaultInstance() : schema_;
    }
    /**
     * <code>.spark.connect.DataType schema = 1;</code>
     */
    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.DataTypeOrBuilder getSchemaOrBuilder() {
      return getSchema();
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (schema_ != null) {
        output.writeMessage(1, getSchema());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (schema_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getSchema());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema)) {
        return super.equals(obj);
      }
      org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema other = (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema) obj;

      if (hasSchema() != other.hasSchema()) return false;
      if (hasSchema()) {
        if (!getSchema()
            .equals(other.getSchema())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasSchema()) {
        hash = (37 * hash) + SCHEMA_FIELD_NUMBER;
        hash = (53 * hash) + getSchema().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code spark.connect.AnalyzePlanResponse.Schema}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:spark.connect.AnalyzePlanResponse.Schema)
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SchemaOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_Schema_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_Schema_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema.class, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema.Builder.class);
      }

      // Construct using org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema.newBuilder()
      private Builder() {

      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        if (schemaBuilder_ == null) {
          schema_ = null;
        } else {
          schema_ = null;
          schemaBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_Schema_descriptor;
      }

      @java.lang.Override
      public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema getDefaultInstanceForType() {
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema build() {
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema buildPartial() {
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema result = new org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema(this);
        if (schemaBuilder_ == null) {
          result.schema_ = schema_;
        } else {
          result.schema_ = schemaBuilder_.build();
        }
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema) {
          return mergeFrom((org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema other) {
        if (other == org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema.getDefaultInstance()) return this;
        if (other.hasSchema()) {
          mergeSchema(other.getSchema());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getSchemaFieldBuilder().getBuilder(),
                    extensionRegistry);

                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }

      private org.apache.kyuubi.engine.spark.connect.proto.DataType schema_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.kyuubi.engine.spark.connect.proto.DataType, org.apache.kyuubi.engine.spark.connect.proto.DataType.Builder, org.apache.kyuubi.engine.spark.connect.proto.DataTypeOrBuilder> schemaBuilder_;
      /**
       * <code>.spark.connect.DataType schema = 1;</code>
       * @return Whether the schema field is set.
       */
      public boolean hasSchema() {
        return schemaBuilder_ != null || schema_ != null;
      }
      /**
       * <code>.spark.connect.DataType schema = 1;</code>
       * @return The schema.
       */
      public org.apache.kyuubi.engine.spark.connect.proto.DataType getSchema() {
        if (schemaBuilder_ == null) {
          return schema_ == null ? org.apache.kyuubi.engine.spark.connect.proto.DataType.getDefaultInstance() : schema_;
        } else {
          return schemaBuilder_.getMessage();
        }
      }
      /**
       * <code>.spark.connect.DataType schema = 1;</code>
       */
      public Builder setSchema(org.apache.kyuubi.engine.spark.connect.proto.DataType value) {
        if (schemaBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          schema_ = value;
          onChanged();
        } else {
          schemaBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <code>.spark.connect.DataType schema = 1;</code>
       */
      public Builder setSchema(
          org.apache.kyuubi.engine.spark.connect.proto.DataType.Builder builderForValue) {
        if (schemaBuilder_ == null) {
          schema_ = builderForValue.build();
          onChanged();
        } else {
          schemaBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <code>.spark.connect.DataType schema = 1;</code>
       */
      public Builder mergeSchema(org.apache.kyuubi.engine.spark.connect.proto.DataType value) {
        if (schemaBuilder_ == null) {
          if (schema_ != null) {
            schema_ =
              org.apache.kyuubi.engine.spark.connect.proto.DataType.newBuilder(schema_).mergeFrom(value).buildPartial();
          } else {
            schema_ = value;
          }
          onChanged();
        } else {
          schemaBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <code>.spark.connect.DataType schema = 1;</code>
       */
      public Builder clearSchema() {
        if (schemaBuilder_ == null) {
          schema_ = null;
          onChanged();
        } else {
          schema_ = null;
          schemaBuilder_ = null;
        }

        return this;
      }
      /**
       * <code>.spark.connect.DataType schema = 1;</code>
       */
      public org.apache.kyuubi.engine.spark.connect.proto.DataType.Builder getSchemaBuilder() {
        
        onChanged();
        return getSchemaFieldBuilder().getBuilder();
      }
      /**
       * <code>.spark.connect.DataType schema = 1;</code>
       */
      public org.apache.kyuubi.engine.spark.connect.proto.DataTypeOrBuilder getSchemaOrBuilder() {
        if (schemaBuilder_ != null) {
          return schemaBuilder_.getMessageOrBuilder();
        } else {
          return schema_ == null ?
              org.apache.kyuubi.engine.spark.connect.proto.DataType.getDefaultInstance() : schema_;
        }
      }
      /**
       * <code>.spark.connect.DataType schema = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.kyuubi.engine.spark.connect.proto.DataType, org.apache.kyuubi.engine.spark.connect.proto.DataType.Builder, org.apache.kyuubi.engine.spark.connect.proto.DataTypeOrBuilder> 
          getSchemaFieldBuilder() {
        if (schemaBuilder_ == null) {
          schemaBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.kyuubi.engine.spark.connect.proto.DataType, org.apache.kyuubi.engine.spark.connect.proto.DataType.Builder, org.apache.kyuubi.engine.spark.connect.proto.DataTypeOrBuilder>(
                  getSchema(),
                  getParentForChildren(),
                  isClean());
          schema_ = null;
        }
        return schemaBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:spark.connect.AnalyzePlanResponse.Schema)
    }

    // @@protoc_insertion_point(class_scope:spark.connect.AnalyzePlanResponse.Schema)
    private static final org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema();
    }

    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<Schema>
        PARSER = new com.google.protobuf.AbstractParser<Schema>() {
      @java.lang.Override
      public Schema parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<Schema> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<Schema> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ExplainOrBuilder extends
      // @@protoc_insertion_point(interface_extends:spark.connect.AnalyzePlanResponse.Explain)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>string explain_string = 1;</code>
     * @return The explainString.
     */
    java.lang.String getExplainString();
    /**
     * <code>string explain_string = 1;</code>
     * @return The bytes for explainString.
     */
    com.google.protobuf.ByteString
        getExplainStringBytes();
  }
  /**
   * Protobuf type {@code spark.connect.AnalyzePlanResponse.Explain}
   */
  public static final class Explain extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:spark.connect.AnalyzePlanResponse.Explain)
      ExplainOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use Explain.newBuilder() to construct.
    private Explain(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private Explain() {
      explainString_ = "";
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new Explain();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_Explain_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_Explain_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain.class, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain.Builder.class);
    }

    public static final int EXPLAIN_STRING_FIELD_NUMBER = 1;
    private volatile java.lang.Object explainString_;
    /**
     * <code>string explain_string = 1;</code>
     * @return The explainString.
     */
    @java.lang.Override
    public java.lang.String getExplainString() {
      java.lang.Object ref = explainString_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        explainString_ = s;
        return s;
      }
    }
    /**
     * <code>string explain_string = 1;</code>
     * @return The bytes for explainString.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getExplainStringBytes() {
      java.lang.Object ref = explainString_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        explainString_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(explainString_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, explainString_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(explainString_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, explainString_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain)) {
        return super.equals(obj);
      }
      org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain other = (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain) obj;

      if (!getExplainString()
          .equals(other.getExplainString())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + EXPLAIN_STRING_FIELD_NUMBER;
      hash = (53 * hash) + getExplainString().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code spark.connect.AnalyzePlanResponse.Explain}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:spark.connect.AnalyzePlanResponse.Explain)
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.ExplainOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_Explain_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_Explain_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain.class, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain.Builder.class);
      }

      // Construct using org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain.newBuilder()
      private Builder() {

      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        explainString_ = "";

        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_Explain_descriptor;
      }

      @java.lang.Override
      public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain getDefaultInstanceForType() {
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain build() {
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain buildPartial() {
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain result = new org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain(this);
        result.explainString_ = explainString_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain) {
          return mergeFrom((org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain other) {
        if (other == org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain.getDefaultInstance()) return this;
        if (!other.getExplainString().isEmpty()) {
          explainString_ = other.explainString_;
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                explainString_ = input.readStringRequireUtf8();

                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }

      private java.lang.Object explainString_ = "";
      /**
       * <code>string explain_string = 1;</code>
       * @return The explainString.
       */
      public java.lang.String getExplainString() {
        java.lang.Object ref = explainString_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          explainString_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>string explain_string = 1;</code>
       * @return The bytes for explainString.
       */
      public com.google.protobuf.ByteString
          getExplainStringBytes() {
        java.lang.Object ref = explainString_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          explainString_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>string explain_string = 1;</code>
       * @param value The explainString to set.
       * @return This builder for chaining.
       */
      public Builder setExplainString(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        explainString_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>string explain_string = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearExplainString() {
        
        explainString_ = getDefaultInstance().getExplainString();
        onChanged();
        return this;
      }
      /**
       * <code>string explain_string = 1;</code>
       * @param value The bytes for explainString to set.
       * @return This builder for chaining.
       */
      public Builder setExplainStringBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        explainString_ = value;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:spark.connect.AnalyzePlanResponse.Explain)
    }

    // @@protoc_insertion_point(class_scope:spark.connect.AnalyzePlanResponse.Explain)
    private static final org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain();
    }

    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<Explain>
        PARSER = new com.google.protobuf.AbstractParser<Explain>() {
      @java.lang.Override
      public Explain parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<Explain> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<Explain> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface TreeStringOrBuilder extends
      // @@protoc_insertion_point(interface_extends:spark.connect.AnalyzePlanResponse.TreeString)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>string tree_string = 1;</code>
     * @return The treeString.
     */
    java.lang.String getTreeString();
    /**
     * <code>string tree_string = 1;</code>
     * @return The bytes for treeString.
     */
    com.google.protobuf.ByteString
        getTreeStringBytes();
  }
  /**
   * Protobuf type {@code spark.connect.AnalyzePlanResponse.TreeString}
   */
  public static final class TreeString extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:spark.connect.AnalyzePlanResponse.TreeString)
      TreeStringOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use TreeString.newBuilder() to construct.
    private TreeString(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private TreeString() {
      treeString_ = "";
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new TreeString();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_TreeString_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_TreeString_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString.class, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString.Builder.class);
    }

    public static final int TREE_STRING_FIELD_NUMBER = 1;
    private volatile java.lang.Object treeString_;
    /**
     * <code>string tree_string = 1;</code>
     * @return The treeString.
     */
    @java.lang.Override
    public java.lang.String getTreeString() {
      java.lang.Object ref = treeString_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        treeString_ = s;
        return s;
      }
    }
    /**
     * <code>string tree_string = 1;</code>
     * @return The bytes for treeString.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getTreeStringBytes() {
      java.lang.Object ref = treeString_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        treeString_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(treeString_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, treeString_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(treeString_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, treeString_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString)) {
        return super.equals(obj);
      }
      org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString other = (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString) obj;

      if (!getTreeString()
          .equals(other.getTreeString())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + TREE_STRING_FIELD_NUMBER;
      hash = (53 * hash) + getTreeString().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code spark.connect.AnalyzePlanResponse.TreeString}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:spark.connect.AnalyzePlanResponse.TreeString)
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeStringOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_TreeString_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_TreeString_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString.class, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString.Builder.class);
      }

      // Construct using org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString.newBuilder()
      private Builder() {

      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        treeString_ = "";

        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_TreeString_descriptor;
      }

      @java.lang.Override
      public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString getDefaultInstanceForType() {
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString build() {
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString buildPartial() {
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString result = new org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString(this);
        result.treeString_ = treeString_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString) {
          return mergeFrom((org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString other) {
        if (other == org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString.getDefaultInstance()) return this;
        if (!other.getTreeString().isEmpty()) {
          treeString_ = other.treeString_;
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                treeString_ = input.readStringRequireUtf8();

                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }

      private java.lang.Object treeString_ = "";
      /**
       * <code>string tree_string = 1;</code>
       * @return The treeString.
       */
      public java.lang.String getTreeString() {
        java.lang.Object ref = treeString_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          treeString_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>string tree_string = 1;</code>
       * @return The bytes for treeString.
       */
      public com.google.protobuf.ByteString
          getTreeStringBytes() {
        java.lang.Object ref = treeString_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          treeString_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>string tree_string = 1;</code>
       * @param value The treeString to set.
       * @return This builder for chaining.
       */
      public Builder setTreeString(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        treeString_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>string tree_string = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearTreeString() {
        
        treeString_ = getDefaultInstance().getTreeString();
        onChanged();
        return this;
      }
      /**
       * <code>string tree_string = 1;</code>
       * @param value The bytes for treeString to set.
       * @return This builder for chaining.
       */
      public Builder setTreeStringBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        treeString_ = value;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:spark.connect.AnalyzePlanResponse.TreeString)
    }

    // @@protoc_insertion_point(class_scope:spark.connect.AnalyzePlanResponse.TreeString)
    private static final org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString();
    }

    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<TreeString>
        PARSER = new com.google.protobuf.AbstractParser<TreeString>() {
      @java.lang.Override
      public TreeString parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<TreeString> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<TreeString> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface IsLocalOrBuilder extends
      // @@protoc_insertion_point(interface_extends:spark.connect.AnalyzePlanResponse.IsLocal)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>bool is_local = 1;</code>
     * @return The isLocal.
     */
    boolean getIsLocal();
  }
  /**
   * Protobuf type {@code spark.connect.AnalyzePlanResponse.IsLocal}
   */
  public static final class IsLocal extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:spark.connect.AnalyzePlanResponse.IsLocal)
      IsLocalOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use IsLocal.newBuilder() to construct.
    private IsLocal(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private IsLocal() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new IsLocal();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_IsLocal_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_IsLocal_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal.class, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal.Builder.class);
    }

    public static final int IS_LOCAL_FIELD_NUMBER = 1;
    private boolean isLocal_;
    /**
     * <code>bool is_local = 1;</code>
     * @return The isLocal.
     */
    @java.lang.Override
    public boolean getIsLocal() {
      return isLocal_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (isLocal_ != false) {
        output.writeBool(1, isLocal_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (isLocal_ != false) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(1, isLocal_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal)) {
        return super.equals(obj);
      }
      org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal other = (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal) obj;

      if (getIsLocal()
          != other.getIsLocal()) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + IS_LOCAL_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
          getIsLocal());
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code spark.connect.AnalyzePlanResponse.IsLocal}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:spark.connect.AnalyzePlanResponse.IsLocal)
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocalOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_IsLocal_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_IsLocal_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal.class, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal.Builder.class);
      }

      // Construct using org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal.newBuilder()
      private Builder() {

      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        isLocal_ = false;

        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_IsLocal_descriptor;
      }

      @java.lang.Override
      public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal getDefaultInstanceForType() {
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal build() {
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal buildPartial() {
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal result = new org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal(this);
        result.isLocal_ = isLocal_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal) {
          return mergeFrom((org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal other) {
        if (other == org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal.getDefaultInstance()) return this;
        if (other.getIsLocal() != false) {
          setIsLocal(other.getIsLocal());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8: {
                isLocal_ = input.readBool();

                break;
              } // case 8
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }

      private boolean isLocal_ ;
      /**
       * <code>bool is_local = 1;</code>
       * @return The isLocal.
       */
      @java.lang.Override
      public boolean getIsLocal() {
        return isLocal_;
      }
      /**
       * <code>bool is_local = 1;</code>
       * @param value The isLocal to set.
       * @return This builder for chaining.
       */
      public Builder setIsLocal(boolean value) {
        
        isLocal_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>bool is_local = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearIsLocal() {
        
        isLocal_ = false;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:spark.connect.AnalyzePlanResponse.IsLocal)
    }

    // @@protoc_insertion_point(class_scope:spark.connect.AnalyzePlanResponse.IsLocal)
    private static final org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal();
    }

    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<IsLocal>
        PARSER = new com.google.protobuf.AbstractParser<IsLocal>() {
      @java.lang.Override
      public IsLocal parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<IsLocal> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<IsLocal> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface IsStreamingOrBuilder extends
      // @@protoc_insertion_point(interface_extends:spark.connect.AnalyzePlanResponse.IsStreaming)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>bool is_streaming = 1;</code>
     * @return The isStreaming.
     */
    boolean getIsStreaming();
  }
  /**
   * Protobuf type {@code spark.connect.AnalyzePlanResponse.IsStreaming}
   */
  public static final class IsStreaming extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:spark.connect.AnalyzePlanResponse.IsStreaming)
      IsStreamingOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use IsStreaming.newBuilder() to construct.
    private IsStreaming(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private IsStreaming() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new IsStreaming();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_IsStreaming_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_IsStreaming_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming.class, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming.Builder.class);
    }

    public static final int IS_STREAMING_FIELD_NUMBER = 1;
    private boolean isStreaming_;
    /**
     * <code>bool is_streaming = 1;</code>
     * @return The isStreaming.
     */
    @java.lang.Override
    public boolean getIsStreaming() {
      return isStreaming_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (isStreaming_ != false) {
        output.writeBool(1, isStreaming_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (isStreaming_ != false) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(1, isStreaming_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming)) {
        return super.equals(obj);
      }
      org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming other = (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming) obj;

      if (getIsStreaming()
          != other.getIsStreaming()) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + IS_STREAMING_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
          getIsStreaming());
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code spark.connect.AnalyzePlanResponse.IsStreaming}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:spark.connect.AnalyzePlanResponse.IsStreaming)
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreamingOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_IsStreaming_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_IsStreaming_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming.class, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming.Builder.class);
      }

      // Construct using org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming.newBuilder()
      private Builder() {

      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        isStreaming_ = false;

        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_IsStreaming_descriptor;
      }

      @java.lang.Override
      public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming getDefaultInstanceForType() {
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming build() {
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming buildPartial() {
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming result = new org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming(this);
        result.isStreaming_ = isStreaming_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming) {
          return mergeFrom((org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming other) {
        if (other == org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming.getDefaultInstance()) return this;
        if (other.getIsStreaming() != false) {
          setIsStreaming(other.getIsStreaming());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8: {
                isStreaming_ = input.readBool();

                break;
              } // case 8
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }

      private boolean isStreaming_ ;
      /**
       * <code>bool is_streaming = 1;</code>
       * @return The isStreaming.
       */
      @java.lang.Override
      public boolean getIsStreaming() {
        return isStreaming_;
      }
      /**
       * <code>bool is_streaming = 1;</code>
       * @param value The isStreaming to set.
       * @return This builder for chaining.
       */
      public Builder setIsStreaming(boolean value) {
        
        isStreaming_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>bool is_streaming = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearIsStreaming() {
        
        isStreaming_ = false;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:spark.connect.AnalyzePlanResponse.IsStreaming)
    }

    // @@protoc_insertion_point(class_scope:spark.connect.AnalyzePlanResponse.IsStreaming)
    private static final org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming();
    }

    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<IsStreaming>
        PARSER = new com.google.protobuf.AbstractParser<IsStreaming>() {
      @java.lang.Override
      public IsStreaming parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<IsStreaming> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<IsStreaming> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface InputFilesOrBuilder extends
      // @@protoc_insertion_point(interface_extends:spark.connect.AnalyzePlanResponse.InputFiles)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * A best-effort snapshot of the files that compose this Dataset
     * </pre>
     *
     * <code>repeated string files = 1;</code>
     * @return A list containing the files.
     */
    java.util.List<java.lang.String>
        getFilesList();
    /**
     * <pre>
     * A best-effort snapshot of the files that compose this Dataset
     * </pre>
     *
     * <code>repeated string files = 1;</code>
     * @return The count of files.
     */
    int getFilesCount();
    /**
     * <pre>
     * A best-effort snapshot of the files that compose this Dataset
     * </pre>
     *
     * <code>repeated string files = 1;</code>
     * @param index The index of the element to return.
     * @return The files at the given index.
     */
    java.lang.String getFiles(int index);
    /**
     * <pre>
     * A best-effort snapshot of the files that compose this Dataset
     * </pre>
     *
     * <code>repeated string files = 1;</code>
     * @param index The index of the value to return.
     * @return The bytes of the files at the given index.
     */
    com.google.protobuf.ByteString
        getFilesBytes(int index);
  }
  /**
   * Protobuf type {@code spark.connect.AnalyzePlanResponse.InputFiles}
   */
  public static final class InputFiles extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:spark.connect.AnalyzePlanResponse.InputFiles)
      InputFilesOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use InputFiles.newBuilder() to construct.
    private InputFiles(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private InputFiles() {
      files_ = com.google.protobuf.LazyStringArrayList.EMPTY;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new InputFiles();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_InputFiles_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_InputFiles_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles.class, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles.Builder.class);
    }

    public static final int FILES_FIELD_NUMBER = 1;
    private com.google.protobuf.LazyStringList files_;
    /**
     * <pre>
     * A best-effort snapshot of the files that compose this Dataset
     * </pre>
     *
     * <code>repeated string files = 1;</code>
     * @return A list containing the files.
     */
    public com.google.protobuf.ProtocolStringList
        getFilesList() {
      return files_;
    }
    /**
     * <pre>
     * A best-effort snapshot of the files that compose this Dataset
     * </pre>
     *
     * <code>repeated string files = 1;</code>
     * @return The count of files.
     */
    public int getFilesCount() {
      return files_.size();
    }
    /**
     * <pre>
     * A best-effort snapshot of the files that compose this Dataset
     * </pre>
     *
     * <code>repeated string files = 1;</code>
     * @param index The index of the element to return.
     * @return The files at the given index.
     */
    public java.lang.String getFiles(int index) {
      return files_.get(index);
    }
    /**
     * <pre>
     * A best-effort snapshot of the files that compose this Dataset
     * </pre>
     *
     * <code>repeated string files = 1;</code>
     * @param index The index of the value to return.
     * @return The bytes of the files at the given index.
     */
    public com.google.protobuf.ByteString
        getFilesBytes(int index) {
      return files_.getByteString(index);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < files_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, files_.getRaw(i));
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      {
        int dataSize = 0;
        for (int i = 0; i < files_.size(); i++) {
          dataSize += computeStringSizeNoTag(files_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getFilesList().size();
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles)) {
        return super.equals(obj);
      }
      org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles other = (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles) obj;

      if (!getFilesList()
          .equals(other.getFilesList())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getFilesCount() > 0) {
        hash = (37 * hash) + FILES_FIELD_NUMBER;
        hash = (53 * hash) + getFilesList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code spark.connect.AnalyzePlanResponse.InputFiles}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:spark.connect.AnalyzePlanResponse.InputFiles)
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFilesOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_InputFiles_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_InputFiles_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles.class, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles.Builder.class);
      }

      // Construct using org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles.newBuilder()
      private Builder() {

      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        files_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_InputFiles_descriptor;
      }

      @java.lang.Override
      public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles getDefaultInstanceForType() {
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles build() {
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles buildPartial() {
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles result = new org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles(this);
        int from_bitField0_ = bitField0_;
        if (((bitField0_ & 0x00000001) != 0)) {
          files_ = files_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00000001);
        }
        result.files_ = files_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles) {
          return mergeFrom((org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles other) {
        if (other == org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles.getDefaultInstance()) return this;
        if (!other.files_.isEmpty()) {
          if (files_.isEmpty()) {
            files_ = other.files_;
            bitField0_ = (bitField0_ & ~0x00000001);
          } else {
            ensureFilesIsMutable();
            files_.addAll(other.files_);
          }
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                java.lang.String s = input.readStringRequireUtf8();
                ensureFilesIsMutable();
                files_.add(s);
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private com.google.protobuf.LazyStringList files_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureFilesIsMutable() {
        if (!((bitField0_ & 0x00000001) != 0)) {
          files_ = new com.google.protobuf.LazyStringArrayList(files_);
          bitField0_ |= 0x00000001;
         }
      }
      /**
       * <pre>
       * A best-effort snapshot of the files that compose this Dataset
       * </pre>
       *
       * <code>repeated string files = 1;</code>
       * @return A list containing the files.
       */
      public com.google.protobuf.ProtocolStringList
          getFilesList() {
        return files_.getUnmodifiableView();
      }
      /**
       * <pre>
       * A best-effort snapshot of the files that compose this Dataset
       * </pre>
       *
       * <code>repeated string files = 1;</code>
       * @return The count of files.
       */
      public int getFilesCount() {
        return files_.size();
      }
      /**
       * <pre>
       * A best-effort snapshot of the files that compose this Dataset
       * </pre>
       *
       * <code>repeated string files = 1;</code>
       * @param index The index of the element to return.
       * @return The files at the given index.
       */
      public java.lang.String getFiles(int index) {
        return files_.get(index);
      }
      /**
       * <pre>
       * A best-effort snapshot of the files that compose this Dataset
       * </pre>
       *
       * <code>repeated string files = 1;</code>
       * @param index The index of the value to return.
       * @return The bytes of the files at the given index.
       */
      public com.google.protobuf.ByteString
          getFilesBytes(int index) {
        return files_.getByteString(index);
      }
      /**
       * <pre>
       * A best-effort snapshot of the files that compose this Dataset
       * </pre>
       *
       * <code>repeated string files = 1;</code>
       * @param index The index to set the value at.
       * @param value The files to set.
       * @return This builder for chaining.
       */
      public Builder setFiles(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureFilesIsMutable();
        files_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * A best-effort snapshot of the files that compose this Dataset
       * </pre>
       *
       * <code>repeated string files = 1;</code>
       * @param value The files to add.
       * @return This builder for chaining.
       */
      public Builder addFiles(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureFilesIsMutable();
        files_.add(value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * A best-effort snapshot of the files that compose this Dataset
       * </pre>
       *
       * <code>repeated string files = 1;</code>
       * @param values The files to add.
       * @return This builder for chaining.
       */
      public Builder addAllFiles(
          java.lang.Iterable<java.lang.String> values) {
        ensureFilesIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, files_);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * A best-effort snapshot of the files that compose this Dataset
       * </pre>
       *
       * <code>repeated string files = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearFiles() {
        files_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * A best-effort snapshot of the files that compose this Dataset
       * </pre>
       *
       * <code>repeated string files = 1;</code>
       * @param value The bytes of the files to add.
       * @return This builder for chaining.
       */
      public Builder addFilesBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        ensureFilesIsMutable();
        files_.add(value);
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:spark.connect.AnalyzePlanResponse.InputFiles)
    }

    // @@protoc_insertion_point(class_scope:spark.connect.AnalyzePlanResponse.InputFiles)
    private static final org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles();
    }

    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<InputFiles>
        PARSER = new com.google.protobuf.AbstractParser<InputFiles>() {
      @java.lang.Override
      public InputFiles parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<InputFiles> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<InputFiles> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface SparkVersionOrBuilder extends
      // @@protoc_insertion_point(interface_extends:spark.connect.AnalyzePlanResponse.SparkVersion)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>string version = 1;</code>
     * @return The version.
     */
    java.lang.String getVersion();
    /**
     * <code>string version = 1;</code>
     * @return The bytes for version.
     */
    com.google.protobuf.ByteString
        getVersionBytes();
  }
  /**
   * Protobuf type {@code spark.connect.AnalyzePlanResponse.SparkVersion}
   */
  public static final class SparkVersion extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:spark.connect.AnalyzePlanResponse.SparkVersion)
      SparkVersionOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use SparkVersion.newBuilder() to construct.
    private SparkVersion(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private SparkVersion() {
      version_ = "";
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new SparkVersion();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_SparkVersion_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_SparkVersion_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion.class, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion.Builder.class);
    }

    public static final int VERSION_FIELD_NUMBER = 1;
    private volatile java.lang.Object version_;
    /**
     * <code>string version = 1;</code>
     * @return The version.
     */
    @java.lang.Override
    public java.lang.String getVersion() {
      java.lang.Object ref = version_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        version_ = s;
        return s;
      }
    }
    /**
     * <code>string version = 1;</code>
     * @return The bytes for version.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getVersionBytes() {
      java.lang.Object ref = version_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        version_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(version_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, version_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(version_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, version_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion)) {
        return super.equals(obj);
      }
      org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion other = (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion) obj;

      if (!getVersion()
          .equals(other.getVersion())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + VERSION_FIELD_NUMBER;
      hash = (53 * hash) + getVersion().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code spark.connect.AnalyzePlanResponse.SparkVersion}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:spark.connect.AnalyzePlanResponse.SparkVersion)
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersionOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_SparkVersion_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_SparkVersion_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion.class, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion.Builder.class);
      }

      // Construct using org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion.newBuilder()
      private Builder() {

      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        version_ = "";

        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_SparkVersion_descriptor;
      }

      @java.lang.Override
      public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion getDefaultInstanceForType() {
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion build() {
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion buildPartial() {
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion result = new org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion(this);
        result.version_ = version_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion) {
          return mergeFrom((org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion other) {
        if (other == org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion.getDefaultInstance()) return this;
        if (!other.getVersion().isEmpty()) {
          version_ = other.version_;
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                version_ = input.readStringRequireUtf8();

                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }

      private java.lang.Object version_ = "";
      /**
       * <code>string version = 1;</code>
       * @return The version.
       */
      public java.lang.String getVersion() {
        java.lang.Object ref = version_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          version_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>string version = 1;</code>
       * @return The bytes for version.
       */
      public com.google.protobuf.ByteString
          getVersionBytes() {
        java.lang.Object ref = version_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          version_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>string version = 1;</code>
       * @param value The version to set.
       * @return This builder for chaining.
       */
      public Builder setVersion(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        version_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>string version = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearVersion() {
        
        version_ = getDefaultInstance().getVersion();
        onChanged();
        return this;
      }
      /**
       * <code>string version = 1;</code>
       * @param value The bytes for version to set.
       * @return This builder for chaining.
       */
      public Builder setVersionBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        version_ = value;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:spark.connect.AnalyzePlanResponse.SparkVersion)
    }

    // @@protoc_insertion_point(class_scope:spark.connect.AnalyzePlanResponse.SparkVersion)
    private static final org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion();
    }

    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<SparkVersion>
        PARSER = new com.google.protobuf.AbstractParser<SparkVersion>() {
      @java.lang.Override
      public SparkVersion parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<SparkVersion> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<SparkVersion> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface DDLParseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:spark.connect.AnalyzePlanResponse.DDLParse)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>.spark.connect.DataType parsed = 1;</code>
     * @return Whether the parsed field is set.
     */
    boolean hasParsed();
    /**
     * <code>.spark.connect.DataType parsed = 1;</code>
     * @return The parsed.
     */
    org.apache.kyuubi.engine.spark.connect.proto.DataType getParsed();
    /**
     * <code>.spark.connect.DataType parsed = 1;</code>
     */
    org.apache.kyuubi.engine.spark.connect.proto.DataTypeOrBuilder getParsedOrBuilder();
  }
  /**
   * Protobuf type {@code spark.connect.AnalyzePlanResponse.DDLParse}
   */
  public static final class DDLParse extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:spark.connect.AnalyzePlanResponse.DDLParse)
      DDLParseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use DDLParse.newBuilder() to construct.
    private DDLParse(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private DDLParse() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new DDLParse();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_DDLParse_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_DDLParse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse.class, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse.Builder.class);
    }

    public static final int PARSED_FIELD_NUMBER = 1;
    private org.apache.kyuubi.engine.spark.connect.proto.DataType parsed_;
    /**
     * <code>.spark.connect.DataType parsed = 1;</code>
     * @return Whether the parsed field is set.
     */
    @java.lang.Override
    public boolean hasParsed() {
      return parsed_ != null;
    }
    /**
     * <code>.spark.connect.DataType parsed = 1;</code>
     * @return The parsed.
     */
    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.DataType getParsed() {
      return parsed_ == null ? org.apache.kyuubi.engine.spark.connect.proto.DataType.getDefaultInstance() : parsed_;
    }
    /**
     * <code>.spark.connect.DataType parsed = 1;</code>
     */
    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.DataTypeOrBuilder getParsedOrBuilder() {
      return getParsed();
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (parsed_ != null) {
        output.writeMessage(1, getParsed());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (parsed_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getParsed());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse)) {
        return super.equals(obj);
      }
      org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse other = (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse) obj;

      if (hasParsed() != other.hasParsed()) return false;
      if (hasParsed()) {
        if (!getParsed()
            .equals(other.getParsed())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasParsed()) {
        hash = (37 * hash) + PARSED_FIELD_NUMBER;
        hash = (53 * hash) + getParsed().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code spark.connect.AnalyzePlanResponse.DDLParse}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:spark.connect.AnalyzePlanResponse.DDLParse)
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParseOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_DDLParse_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_DDLParse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse.class, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse.Builder.class);
      }

      // Construct using org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse.newBuilder()
      private Builder() {

      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        if (parsedBuilder_ == null) {
          parsed_ = null;
        } else {
          parsed_ = null;
          parsedBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_DDLParse_descriptor;
      }

      @java.lang.Override
      public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse getDefaultInstanceForType() {
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse build() {
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse buildPartial() {
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse result = new org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse(this);
        if (parsedBuilder_ == null) {
          result.parsed_ = parsed_;
        } else {
          result.parsed_ = parsedBuilder_.build();
        }
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse) {
          return mergeFrom((org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse other) {
        if (other == org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse.getDefaultInstance()) return this;
        if (other.hasParsed()) {
          mergeParsed(other.getParsed());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getParsedFieldBuilder().getBuilder(),
                    extensionRegistry);

                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }

      private org.apache.kyuubi.engine.spark.connect.proto.DataType parsed_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.kyuubi.engine.spark.connect.proto.DataType, org.apache.kyuubi.engine.spark.connect.proto.DataType.Builder, org.apache.kyuubi.engine.spark.connect.proto.DataTypeOrBuilder> parsedBuilder_;
      /**
       * <code>.spark.connect.DataType parsed = 1;</code>
       * @return Whether the parsed field is set.
       */
      public boolean hasParsed() {
        return parsedBuilder_ != null || parsed_ != null;
      }
      /**
       * <code>.spark.connect.DataType parsed = 1;</code>
       * @return The parsed.
       */
      public org.apache.kyuubi.engine.spark.connect.proto.DataType getParsed() {
        if (parsedBuilder_ == null) {
          return parsed_ == null ? org.apache.kyuubi.engine.spark.connect.proto.DataType.getDefaultInstance() : parsed_;
        } else {
          return parsedBuilder_.getMessage();
        }
      }
      /**
       * <code>.spark.connect.DataType parsed = 1;</code>
       */
      public Builder setParsed(org.apache.kyuubi.engine.spark.connect.proto.DataType value) {
        if (parsedBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          parsed_ = value;
          onChanged();
        } else {
          parsedBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <code>.spark.connect.DataType parsed = 1;</code>
       */
      public Builder setParsed(
          org.apache.kyuubi.engine.spark.connect.proto.DataType.Builder builderForValue) {
        if (parsedBuilder_ == null) {
          parsed_ = builderForValue.build();
          onChanged();
        } else {
          parsedBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <code>.spark.connect.DataType parsed = 1;</code>
       */
      public Builder mergeParsed(org.apache.kyuubi.engine.spark.connect.proto.DataType value) {
        if (parsedBuilder_ == null) {
          if (parsed_ != null) {
            parsed_ =
              org.apache.kyuubi.engine.spark.connect.proto.DataType.newBuilder(parsed_).mergeFrom(value).buildPartial();
          } else {
            parsed_ = value;
          }
          onChanged();
        } else {
          parsedBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <code>.spark.connect.DataType parsed = 1;</code>
       */
      public Builder clearParsed() {
        if (parsedBuilder_ == null) {
          parsed_ = null;
          onChanged();
        } else {
          parsed_ = null;
          parsedBuilder_ = null;
        }

        return this;
      }
      /**
       * <code>.spark.connect.DataType parsed = 1;</code>
       */
      public org.apache.kyuubi.engine.spark.connect.proto.DataType.Builder getParsedBuilder() {
        
        onChanged();
        return getParsedFieldBuilder().getBuilder();
      }
      /**
       * <code>.spark.connect.DataType parsed = 1;</code>
       */
      public org.apache.kyuubi.engine.spark.connect.proto.DataTypeOrBuilder getParsedOrBuilder() {
        if (parsedBuilder_ != null) {
          return parsedBuilder_.getMessageOrBuilder();
        } else {
          return parsed_ == null ?
              org.apache.kyuubi.engine.spark.connect.proto.DataType.getDefaultInstance() : parsed_;
        }
      }
      /**
       * <code>.spark.connect.DataType parsed = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.kyuubi.engine.spark.connect.proto.DataType, org.apache.kyuubi.engine.spark.connect.proto.DataType.Builder, org.apache.kyuubi.engine.spark.connect.proto.DataTypeOrBuilder> 
          getParsedFieldBuilder() {
        if (parsedBuilder_ == null) {
          parsedBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.kyuubi.engine.spark.connect.proto.DataType, org.apache.kyuubi.engine.spark.connect.proto.DataType.Builder, org.apache.kyuubi.engine.spark.connect.proto.DataTypeOrBuilder>(
                  getParsed(),
                  getParentForChildren(),
                  isClean());
          parsed_ = null;
        }
        return parsedBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:spark.connect.AnalyzePlanResponse.DDLParse)
    }

    // @@protoc_insertion_point(class_scope:spark.connect.AnalyzePlanResponse.DDLParse)
    private static final org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse();
    }

    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<DDLParse>
        PARSER = new com.google.protobuf.AbstractParser<DDLParse>() {
      @java.lang.Override
      public DDLParse parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<DDLParse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<DDLParse> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface SameSemanticsOrBuilder extends
      // @@protoc_insertion_point(interface_extends:spark.connect.AnalyzePlanResponse.SameSemantics)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>bool result = 1;</code>
     * @return The result.
     */
    boolean getResult();
  }
  /**
   * Protobuf type {@code spark.connect.AnalyzePlanResponse.SameSemantics}
   */
  public static final class SameSemantics extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:spark.connect.AnalyzePlanResponse.SameSemantics)
      SameSemanticsOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use SameSemantics.newBuilder() to construct.
    private SameSemantics(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private SameSemantics() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new SameSemantics();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_SameSemantics_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_SameSemantics_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics.class, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics.Builder.class);
    }

    public static final int RESULT_FIELD_NUMBER = 1;
    private boolean result_;
    /**
     * <code>bool result = 1;</code>
     * @return The result.
     */
    @java.lang.Override
    public boolean getResult() {
      return result_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (result_ != false) {
        output.writeBool(1, result_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (result_ != false) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(1, result_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics)) {
        return super.equals(obj);
      }
      org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics other = (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics) obj;

      if (getResult()
          != other.getResult()) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + RESULT_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
          getResult());
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code spark.connect.AnalyzePlanResponse.SameSemantics}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:spark.connect.AnalyzePlanResponse.SameSemantics)
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemanticsOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_SameSemantics_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_SameSemantics_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics.class, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics.Builder.class);
      }

      // Construct using org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics.newBuilder()
      private Builder() {

      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        result_ = false;

        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_SameSemantics_descriptor;
      }

      @java.lang.Override
      public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics getDefaultInstanceForType() {
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics build() {
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics buildPartial() {
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics result = new org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics(this);
        result.result_ = result_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics) {
          return mergeFrom((org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics other) {
        if (other == org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics.getDefaultInstance()) return this;
        if (other.getResult() != false) {
          setResult(other.getResult());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8: {
                result_ = input.readBool();

                break;
              } // case 8
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }

      private boolean result_ ;
      /**
       * <code>bool result = 1;</code>
       * @return The result.
       */
      @java.lang.Override
      public boolean getResult() {
        return result_;
      }
      /**
       * <code>bool result = 1;</code>
       * @param value The result to set.
       * @return This builder for chaining.
       */
      public Builder setResult(boolean value) {
        
        result_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>bool result = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearResult() {
        
        result_ = false;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:spark.connect.AnalyzePlanResponse.SameSemantics)
    }

    // @@protoc_insertion_point(class_scope:spark.connect.AnalyzePlanResponse.SameSemantics)
    private static final org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics();
    }

    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<SameSemantics>
        PARSER = new com.google.protobuf.AbstractParser<SameSemantics>() {
      @java.lang.Override
      public SameSemantics parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<SameSemantics> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<SameSemantics> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface SemanticHashOrBuilder extends
      // @@protoc_insertion_point(interface_extends:spark.connect.AnalyzePlanResponse.SemanticHash)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>int32 result = 1;</code>
     * @return The result.
     */
    int getResult();
  }
  /**
   * Protobuf type {@code spark.connect.AnalyzePlanResponse.SemanticHash}
   */
  public static final class SemanticHash extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:spark.connect.AnalyzePlanResponse.SemanticHash)
      SemanticHashOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use SemanticHash.newBuilder() to construct.
    private SemanticHash(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private SemanticHash() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new SemanticHash();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_SemanticHash_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_SemanticHash_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash.class, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash.Builder.class);
    }

    public static final int RESULT_FIELD_NUMBER = 1;
    private int result_;
    /**
     * <code>int32 result = 1;</code>
     * @return The result.
     */
    @java.lang.Override
    public int getResult() {
      return result_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (result_ != 0) {
        output.writeInt32(1, result_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (result_ != 0) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(1, result_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash)) {
        return super.equals(obj);
      }
      org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash other = (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash) obj;

      if (getResult()
          != other.getResult()) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + RESULT_FIELD_NUMBER;
      hash = (53 * hash) + getResult();
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code spark.connect.AnalyzePlanResponse.SemanticHash}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:spark.connect.AnalyzePlanResponse.SemanticHash)
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHashOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_SemanticHash_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_SemanticHash_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash.class, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash.Builder.class);
      }

      // Construct using org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash.newBuilder()
      private Builder() {

      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        result_ = 0;

        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_SemanticHash_descriptor;
      }

      @java.lang.Override
      public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash getDefaultInstanceForType() {
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash build() {
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash buildPartial() {
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash result = new org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash(this);
        result.result_ = result_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash) {
          return mergeFrom((org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash other) {
        if (other == org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash.getDefaultInstance()) return this;
        if (other.getResult() != 0) {
          setResult(other.getResult());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8: {
                result_ = input.readInt32();

                break;
              } // case 8
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }

      private int result_ ;
      /**
       * <code>int32 result = 1;</code>
       * @return The result.
       */
      @java.lang.Override
      public int getResult() {
        return result_;
      }
      /**
       * <code>int32 result = 1;</code>
       * @param value The result to set.
       * @return This builder for chaining.
       */
      public Builder setResult(int value) {
        
        result_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>int32 result = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearResult() {
        
        result_ = 0;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:spark.connect.AnalyzePlanResponse.SemanticHash)
    }

    // @@protoc_insertion_point(class_scope:spark.connect.AnalyzePlanResponse.SemanticHash)
    private static final org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash();
    }

    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<SemanticHash>
        PARSER = new com.google.protobuf.AbstractParser<SemanticHash>() {
      @java.lang.Override
      public SemanticHash parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<SemanticHash> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<SemanticHash> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface PersistOrBuilder extends
      // @@protoc_insertion_point(interface_extends:spark.connect.AnalyzePlanResponse.Persist)
      com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code spark.connect.AnalyzePlanResponse.Persist}
   */
  public static final class Persist extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:spark.connect.AnalyzePlanResponse.Persist)
      PersistOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use Persist.newBuilder() to construct.
    private Persist(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private Persist() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new Persist();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_Persist_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_Persist_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist.class, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist)) {
        return super.equals(obj);
      }
      org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist other = (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist) obj;

      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code spark.connect.AnalyzePlanResponse.Persist}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:spark.connect.AnalyzePlanResponse.Persist)
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.PersistOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_Persist_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_Persist_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist.class, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist.Builder.class);
      }

      // Construct using org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist.newBuilder()
      private Builder() {

      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_Persist_descriptor;
      }

      @java.lang.Override
      public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist getDefaultInstanceForType() {
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist build() {
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist buildPartial() {
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist result = new org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist(this);
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist) {
          return mergeFrom((org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist other) {
        if (other == org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:spark.connect.AnalyzePlanResponse.Persist)
    }

    // @@protoc_insertion_point(class_scope:spark.connect.AnalyzePlanResponse.Persist)
    private static final org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist();
    }

    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<Persist>
        PARSER = new com.google.protobuf.AbstractParser<Persist>() {
      @java.lang.Override
      public Persist parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<Persist> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<Persist> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface UnpersistOrBuilder extends
      // @@protoc_insertion_point(interface_extends:spark.connect.AnalyzePlanResponse.Unpersist)
      com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code spark.connect.AnalyzePlanResponse.Unpersist}
   */
  public static final class Unpersist extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:spark.connect.AnalyzePlanResponse.Unpersist)
      UnpersistOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use Unpersist.newBuilder() to construct.
    private Unpersist(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private Unpersist() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new Unpersist();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_Unpersist_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_Unpersist_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist.class, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist.Builder.class);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist)) {
        return super.equals(obj);
      }
      org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist other = (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist) obj;

      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code spark.connect.AnalyzePlanResponse.Unpersist}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:spark.connect.AnalyzePlanResponse.Unpersist)
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.UnpersistOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_Unpersist_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_Unpersist_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist.class, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist.Builder.class);
      }

      // Construct using org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist.newBuilder()
      private Builder() {

      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_Unpersist_descriptor;
      }

      @java.lang.Override
      public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist getDefaultInstanceForType() {
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist build() {
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist buildPartial() {
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist result = new org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist(this);
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist) {
          return mergeFrom((org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist other) {
        if (other == org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:spark.connect.AnalyzePlanResponse.Unpersist)
    }

    // @@protoc_insertion_point(class_scope:spark.connect.AnalyzePlanResponse.Unpersist)
    private static final org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist();
    }

    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<Unpersist>
        PARSER = new com.google.protobuf.AbstractParser<Unpersist>() {
      @java.lang.Override
      public Unpersist parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<Unpersist> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<Unpersist> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface GetStorageLevelOrBuilder extends
      // @@protoc_insertion_point(interface_extends:spark.connect.AnalyzePlanResponse.GetStorageLevel)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * (Required) The StorageLevel as a result of get_storage_level request.
     * </pre>
     *
     * <code>.spark.connect.StorageLevel storage_level = 1;</code>
     * @return Whether the storageLevel field is set.
     */
    boolean hasStorageLevel();
    /**
     * <pre>
     * (Required) The StorageLevel as a result of get_storage_level request.
     * </pre>
     *
     * <code>.spark.connect.StorageLevel storage_level = 1;</code>
     * @return The storageLevel.
     */
    org.apache.kyuubi.engine.spark.connect.proto.StorageLevel getStorageLevel();
    /**
     * <pre>
     * (Required) The StorageLevel as a result of get_storage_level request.
     * </pre>
     *
     * <code>.spark.connect.StorageLevel storage_level = 1;</code>
     */
    org.apache.kyuubi.engine.spark.connect.proto.StorageLevelOrBuilder getStorageLevelOrBuilder();
  }
  /**
   * Protobuf type {@code spark.connect.AnalyzePlanResponse.GetStorageLevel}
   */
  public static final class GetStorageLevel extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:spark.connect.AnalyzePlanResponse.GetStorageLevel)
      GetStorageLevelOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use GetStorageLevel.newBuilder() to construct.
    private GetStorageLevel(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetStorageLevel() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new GetStorageLevel();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_GetStorageLevel_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_GetStorageLevel_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel.class, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel.Builder.class);
    }

    public static final int STORAGE_LEVEL_FIELD_NUMBER = 1;
    private org.apache.kyuubi.engine.spark.connect.proto.StorageLevel storageLevel_;
    /**
     * <pre>
     * (Required) The StorageLevel as a result of get_storage_level request.
     * </pre>
     *
     * <code>.spark.connect.StorageLevel storage_level = 1;</code>
     * @return Whether the storageLevel field is set.
     */
    @java.lang.Override
    public boolean hasStorageLevel() {
      return storageLevel_ != null;
    }
    /**
     * <pre>
     * (Required) The StorageLevel as a result of get_storage_level request.
     * </pre>
     *
     * <code>.spark.connect.StorageLevel storage_level = 1;</code>
     * @return The storageLevel.
     */
    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.StorageLevel getStorageLevel() {
      return storageLevel_ == null ? org.apache.kyuubi.engine.spark.connect.proto.StorageLevel.getDefaultInstance() : storageLevel_;
    }
    /**
     * <pre>
     * (Required) The StorageLevel as a result of get_storage_level request.
     * </pre>
     *
     * <code>.spark.connect.StorageLevel storage_level = 1;</code>
     */
    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.StorageLevelOrBuilder getStorageLevelOrBuilder() {
      return getStorageLevel();
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (storageLevel_ != null) {
        output.writeMessage(1, getStorageLevel());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (storageLevel_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getStorageLevel());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel)) {
        return super.equals(obj);
      }
      org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel other = (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel) obj;

      if (hasStorageLevel() != other.hasStorageLevel()) return false;
      if (hasStorageLevel()) {
        if (!getStorageLevel()
            .equals(other.getStorageLevel())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasStorageLevel()) {
        hash = (37 * hash) + STORAGE_LEVEL_FIELD_NUMBER;
        hash = (53 * hash) + getStorageLevel().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code spark.connect.AnalyzePlanResponse.GetStorageLevel}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:spark.connect.AnalyzePlanResponse.GetStorageLevel)
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevelOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_GetStorageLevel_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_GetStorageLevel_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel.class, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel.Builder.class);
      }

      // Construct using org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel.newBuilder()
      private Builder() {

      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        if (storageLevelBuilder_ == null) {
          storageLevel_ = null;
        } else {
          storageLevel_ = null;
          storageLevelBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_GetStorageLevel_descriptor;
      }

      @java.lang.Override
      public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel getDefaultInstanceForType() {
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel.getDefaultInstance();
      }

      @java.lang.Override
      public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel build() {
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel buildPartial() {
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel result = new org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel(this);
        if (storageLevelBuilder_ == null) {
          result.storageLevel_ = storageLevel_;
        } else {
          result.storageLevel_ = storageLevelBuilder_.build();
        }
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel) {
          return mergeFrom((org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel other) {
        if (other == org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel.getDefaultInstance()) return this;
        if (other.hasStorageLevel()) {
          mergeStorageLevel(other.getStorageLevel());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getStorageLevelFieldBuilder().getBuilder(),
                    extensionRegistry);

                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }

      private org.apache.kyuubi.engine.spark.connect.proto.StorageLevel storageLevel_;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.kyuubi.engine.spark.connect.proto.StorageLevel, org.apache.kyuubi.engine.spark.connect.proto.StorageLevel.Builder, org.apache.kyuubi.engine.spark.connect.proto.StorageLevelOrBuilder> storageLevelBuilder_;
      /**
       * <pre>
       * (Required) The StorageLevel as a result of get_storage_level request.
       * </pre>
       *
       * <code>.spark.connect.StorageLevel storage_level = 1;</code>
       * @return Whether the storageLevel field is set.
       */
      public boolean hasStorageLevel() {
        return storageLevelBuilder_ != null || storageLevel_ != null;
      }
      /**
       * <pre>
       * (Required) The StorageLevel as a result of get_storage_level request.
       * </pre>
       *
       * <code>.spark.connect.StorageLevel storage_level = 1;</code>
       * @return The storageLevel.
       */
      public org.apache.kyuubi.engine.spark.connect.proto.StorageLevel getStorageLevel() {
        if (storageLevelBuilder_ == null) {
          return storageLevel_ == null ? org.apache.kyuubi.engine.spark.connect.proto.StorageLevel.getDefaultInstance() : storageLevel_;
        } else {
          return storageLevelBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * (Required) The StorageLevel as a result of get_storage_level request.
       * </pre>
       *
       * <code>.spark.connect.StorageLevel storage_level = 1;</code>
       */
      public Builder setStorageLevel(org.apache.kyuubi.engine.spark.connect.proto.StorageLevel value) {
        if (storageLevelBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          storageLevel_ = value;
          onChanged();
        } else {
          storageLevelBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * (Required) The StorageLevel as a result of get_storage_level request.
       * </pre>
       *
       * <code>.spark.connect.StorageLevel storage_level = 1;</code>
       */
      public Builder setStorageLevel(
          org.apache.kyuubi.engine.spark.connect.proto.StorageLevel.Builder builderForValue) {
        if (storageLevelBuilder_ == null) {
          storageLevel_ = builderForValue.build();
          onChanged();
        } else {
          storageLevelBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * (Required) The StorageLevel as a result of get_storage_level request.
       * </pre>
       *
       * <code>.spark.connect.StorageLevel storage_level = 1;</code>
       */
      public Builder mergeStorageLevel(org.apache.kyuubi.engine.spark.connect.proto.StorageLevel value) {
        if (storageLevelBuilder_ == null) {
          if (storageLevel_ != null) {
            storageLevel_ =
              org.apache.kyuubi.engine.spark.connect.proto.StorageLevel.newBuilder(storageLevel_).mergeFrom(value).buildPartial();
          } else {
            storageLevel_ = value;
          }
          onChanged();
        } else {
          storageLevelBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * (Required) The StorageLevel as a result of get_storage_level request.
       * </pre>
       *
       * <code>.spark.connect.StorageLevel storage_level = 1;</code>
       */
      public Builder clearStorageLevel() {
        if (storageLevelBuilder_ == null) {
          storageLevel_ = null;
          onChanged();
        } else {
          storageLevel_ = null;
          storageLevelBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * (Required) The StorageLevel as a result of get_storage_level request.
       * </pre>
       *
       * <code>.spark.connect.StorageLevel storage_level = 1;</code>
       */
      public org.apache.kyuubi.engine.spark.connect.proto.StorageLevel.Builder getStorageLevelBuilder() {
        
        onChanged();
        return getStorageLevelFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * (Required) The StorageLevel as a result of get_storage_level request.
       * </pre>
       *
       * <code>.spark.connect.StorageLevel storage_level = 1;</code>
       */
      public org.apache.kyuubi.engine.spark.connect.proto.StorageLevelOrBuilder getStorageLevelOrBuilder() {
        if (storageLevelBuilder_ != null) {
          return storageLevelBuilder_.getMessageOrBuilder();
        } else {
          return storageLevel_ == null ?
              org.apache.kyuubi.engine.spark.connect.proto.StorageLevel.getDefaultInstance() : storageLevel_;
        }
      }
      /**
       * <pre>
       * (Required) The StorageLevel as a result of get_storage_level request.
       * </pre>
       *
       * <code>.spark.connect.StorageLevel storage_level = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.kyuubi.engine.spark.connect.proto.StorageLevel, org.apache.kyuubi.engine.spark.connect.proto.StorageLevel.Builder, org.apache.kyuubi.engine.spark.connect.proto.StorageLevelOrBuilder> 
          getStorageLevelFieldBuilder() {
        if (storageLevelBuilder_ == null) {
          storageLevelBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.kyuubi.engine.spark.connect.proto.StorageLevel, org.apache.kyuubi.engine.spark.connect.proto.StorageLevel.Builder, org.apache.kyuubi.engine.spark.connect.proto.StorageLevelOrBuilder>(
                  getStorageLevel(),
                  getParentForChildren(),
                  isClean());
          storageLevel_ = null;
        }
        return storageLevelBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:spark.connect.AnalyzePlanResponse.GetStorageLevel)
    }

    // @@protoc_insertion_point(class_scope:spark.connect.AnalyzePlanResponse.GetStorageLevel)
    private static final org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel();
    }

    public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<GetStorageLevel>
        PARSER = new com.google.protobuf.AbstractParser<GetStorageLevel>() {
      @java.lang.Override
      public GetStorageLevel parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<GetStorageLevel> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<GetStorageLevel> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  private int resultCase_ = 0;
  private java.lang.Object result_;
  public enum ResultCase
      implements com.google.protobuf.Internal.EnumLite,
          com.google.protobuf.AbstractMessage.InternalOneOfEnum {
    SCHEMA(2),
    EXPLAIN(3),
    TREE_STRING(4),
    IS_LOCAL(5),
    IS_STREAMING(6),
    INPUT_FILES(7),
    SPARK_VERSION(8),
    DDL_PARSE(9),
    SAME_SEMANTICS(10),
    SEMANTIC_HASH(11),
    PERSIST(12),
    UNPERSIST(13),
    GET_STORAGE_LEVEL(14),
    RESULT_NOT_SET(0);
    private final int value;
    private ResultCase(int value) {
      this.value = value;
    }
    /**
     * @param value The number of the enum to look for.
     * @return The enum associated with the given number.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static ResultCase valueOf(int value) {
      return forNumber(value);
    }

    public static ResultCase forNumber(int value) {
      switch (value) {
        case 2: return SCHEMA;
        case 3: return EXPLAIN;
        case 4: return TREE_STRING;
        case 5: return IS_LOCAL;
        case 6: return IS_STREAMING;
        case 7: return INPUT_FILES;
        case 8: return SPARK_VERSION;
        case 9: return DDL_PARSE;
        case 10: return SAME_SEMANTICS;
        case 11: return SEMANTIC_HASH;
        case 12: return PERSIST;
        case 13: return UNPERSIST;
        case 14: return GET_STORAGE_LEVEL;
        case 0: return RESULT_NOT_SET;
        default: return null;
      }
    }
    public int getNumber() {
      return this.value;
    }
  };

  public ResultCase
  getResultCase() {
    return ResultCase.forNumber(
        resultCase_);
  }

  public static final int SESSION_ID_FIELD_NUMBER = 1;
  private volatile java.lang.Object sessionId_;
  /**
   * <code>string session_id = 1;</code>
   * @return The sessionId.
   */
  @java.lang.Override
  public java.lang.String getSessionId() {
    java.lang.Object ref = sessionId_;
    if (ref instanceof java.lang.String) {
      return (java.lang.String) ref;
    } else {
      com.google.protobuf.ByteString bs = 
          (com.google.protobuf.ByteString) ref;
      java.lang.String s = bs.toStringUtf8();
      sessionId_ = s;
      return s;
    }
  }
  /**
   * <code>string session_id = 1;</code>
   * @return The bytes for sessionId.
   */
  @java.lang.Override
  public com.google.protobuf.ByteString
      getSessionIdBytes() {
    java.lang.Object ref = sessionId_;
    if (ref instanceof java.lang.String) {
      com.google.protobuf.ByteString b = 
          com.google.protobuf.ByteString.copyFromUtf8(
              (java.lang.String) ref);
      sessionId_ = b;
      return b;
    } else {
      return (com.google.protobuf.ByteString) ref;
    }
  }

  public static final int SCHEMA_FIELD_NUMBER = 2;
  /**
   * <code>.spark.connect.AnalyzePlanResponse.Schema schema = 2;</code>
   * @return Whether the schema field is set.
   */
  @java.lang.Override
  public boolean hasSchema() {
    return resultCase_ == 2;
  }
  /**
   * <code>.spark.connect.AnalyzePlanResponse.Schema schema = 2;</code>
   * @return The schema.
   */
  @java.lang.Override
  public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema getSchema() {
    if (resultCase_ == 2) {
       return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema) result_;
    }
    return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema.getDefaultInstance();
  }
  /**
   * <code>.spark.connect.AnalyzePlanResponse.Schema schema = 2;</code>
   */
  @java.lang.Override
  public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SchemaOrBuilder getSchemaOrBuilder() {
    if (resultCase_ == 2) {
       return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema) result_;
    }
    return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema.getDefaultInstance();
  }

  public static final int EXPLAIN_FIELD_NUMBER = 3;
  /**
   * <code>.spark.connect.AnalyzePlanResponse.Explain explain = 3;</code>
   * @return Whether the explain field is set.
   */
  @java.lang.Override
  public boolean hasExplain() {
    return resultCase_ == 3;
  }
  /**
   * <code>.spark.connect.AnalyzePlanResponse.Explain explain = 3;</code>
   * @return The explain.
   */
  @java.lang.Override
  public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain getExplain() {
    if (resultCase_ == 3) {
       return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain) result_;
    }
    return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain.getDefaultInstance();
  }
  /**
   * <code>.spark.connect.AnalyzePlanResponse.Explain explain = 3;</code>
   */
  @java.lang.Override
  public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.ExplainOrBuilder getExplainOrBuilder() {
    if (resultCase_ == 3) {
       return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain) result_;
    }
    return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain.getDefaultInstance();
  }

  public static final int TREE_STRING_FIELD_NUMBER = 4;
  /**
   * <code>.spark.connect.AnalyzePlanResponse.TreeString tree_string = 4;</code>
   * @return Whether the treeString field is set.
   */
  @java.lang.Override
  public boolean hasTreeString() {
    return resultCase_ == 4;
  }
  /**
   * <code>.spark.connect.AnalyzePlanResponse.TreeString tree_string = 4;</code>
   * @return The treeString.
   */
  @java.lang.Override
  public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString getTreeString() {
    if (resultCase_ == 4) {
       return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString) result_;
    }
    return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString.getDefaultInstance();
  }
  /**
   * <code>.spark.connect.AnalyzePlanResponse.TreeString tree_string = 4;</code>
   */
  @java.lang.Override
  public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeStringOrBuilder getTreeStringOrBuilder() {
    if (resultCase_ == 4) {
       return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString) result_;
    }
    return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString.getDefaultInstance();
  }

  public static final int IS_LOCAL_FIELD_NUMBER = 5;
  /**
   * <code>.spark.connect.AnalyzePlanResponse.IsLocal is_local = 5;</code>
   * @return Whether the isLocal field is set.
   */
  @java.lang.Override
  public boolean hasIsLocal() {
    return resultCase_ == 5;
  }
  /**
   * <code>.spark.connect.AnalyzePlanResponse.IsLocal is_local = 5;</code>
   * @return The isLocal.
   */
  @java.lang.Override
  public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal getIsLocal() {
    if (resultCase_ == 5) {
       return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal) result_;
    }
    return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal.getDefaultInstance();
  }
  /**
   * <code>.spark.connect.AnalyzePlanResponse.IsLocal is_local = 5;</code>
   */
  @java.lang.Override
  public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocalOrBuilder getIsLocalOrBuilder() {
    if (resultCase_ == 5) {
       return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal) result_;
    }
    return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal.getDefaultInstance();
  }

  public static final int IS_STREAMING_FIELD_NUMBER = 6;
  /**
   * <code>.spark.connect.AnalyzePlanResponse.IsStreaming is_streaming = 6;</code>
   * @return Whether the isStreaming field is set.
   */
  @java.lang.Override
  public boolean hasIsStreaming() {
    return resultCase_ == 6;
  }
  /**
   * <code>.spark.connect.AnalyzePlanResponse.IsStreaming is_streaming = 6;</code>
   * @return The isStreaming.
   */
  @java.lang.Override
  public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming getIsStreaming() {
    if (resultCase_ == 6) {
       return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming) result_;
    }
    return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming.getDefaultInstance();
  }
  /**
   * <code>.spark.connect.AnalyzePlanResponse.IsStreaming is_streaming = 6;</code>
   */
  @java.lang.Override
  public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreamingOrBuilder getIsStreamingOrBuilder() {
    if (resultCase_ == 6) {
       return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming) result_;
    }
    return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming.getDefaultInstance();
  }

  public static final int INPUT_FILES_FIELD_NUMBER = 7;
  /**
   * <code>.spark.connect.AnalyzePlanResponse.InputFiles input_files = 7;</code>
   * @return Whether the inputFiles field is set.
   */
  @java.lang.Override
  public boolean hasInputFiles() {
    return resultCase_ == 7;
  }
  /**
   * <code>.spark.connect.AnalyzePlanResponse.InputFiles input_files = 7;</code>
   * @return The inputFiles.
   */
  @java.lang.Override
  public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles getInputFiles() {
    if (resultCase_ == 7) {
       return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles) result_;
    }
    return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles.getDefaultInstance();
  }
  /**
   * <code>.spark.connect.AnalyzePlanResponse.InputFiles input_files = 7;</code>
   */
  @java.lang.Override
  public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFilesOrBuilder getInputFilesOrBuilder() {
    if (resultCase_ == 7) {
       return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles) result_;
    }
    return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles.getDefaultInstance();
  }

  public static final int SPARK_VERSION_FIELD_NUMBER = 8;
  /**
   * <code>.spark.connect.AnalyzePlanResponse.SparkVersion spark_version = 8;</code>
   * @return Whether the sparkVersion field is set.
   */
  @java.lang.Override
  public boolean hasSparkVersion() {
    return resultCase_ == 8;
  }
  /**
   * <code>.spark.connect.AnalyzePlanResponse.SparkVersion spark_version = 8;</code>
   * @return The sparkVersion.
   */
  @java.lang.Override
  public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion getSparkVersion() {
    if (resultCase_ == 8) {
       return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion) result_;
    }
    return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion.getDefaultInstance();
  }
  /**
   * <code>.spark.connect.AnalyzePlanResponse.SparkVersion spark_version = 8;</code>
   */
  @java.lang.Override
  public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersionOrBuilder getSparkVersionOrBuilder() {
    if (resultCase_ == 8) {
       return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion) result_;
    }
    return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion.getDefaultInstance();
  }

  public static final int DDL_PARSE_FIELD_NUMBER = 9;
  /**
   * <code>.spark.connect.AnalyzePlanResponse.DDLParse ddl_parse = 9;</code>
   * @return Whether the ddlParse field is set.
   */
  @java.lang.Override
  public boolean hasDdlParse() {
    return resultCase_ == 9;
  }
  /**
   * <code>.spark.connect.AnalyzePlanResponse.DDLParse ddl_parse = 9;</code>
   * @return The ddlParse.
   */
  @java.lang.Override
  public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse getDdlParse() {
    if (resultCase_ == 9) {
       return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse) result_;
    }
    return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse.getDefaultInstance();
  }
  /**
   * <code>.spark.connect.AnalyzePlanResponse.DDLParse ddl_parse = 9;</code>
   */
  @java.lang.Override
  public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParseOrBuilder getDdlParseOrBuilder() {
    if (resultCase_ == 9) {
       return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse) result_;
    }
    return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse.getDefaultInstance();
  }

  public static final int SAME_SEMANTICS_FIELD_NUMBER = 10;
  /**
   * <code>.spark.connect.AnalyzePlanResponse.SameSemantics same_semantics = 10;</code>
   * @return Whether the sameSemantics field is set.
   */
  @java.lang.Override
  public boolean hasSameSemantics() {
    return resultCase_ == 10;
  }
  /**
   * <code>.spark.connect.AnalyzePlanResponse.SameSemantics same_semantics = 10;</code>
   * @return The sameSemantics.
   */
  @java.lang.Override
  public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics getSameSemantics() {
    if (resultCase_ == 10) {
       return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics) result_;
    }
    return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics.getDefaultInstance();
  }
  /**
   * <code>.spark.connect.AnalyzePlanResponse.SameSemantics same_semantics = 10;</code>
   */
  @java.lang.Override
  public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemanticsOrBuilder getSameSemanticsOrBuilder() {
    if (resultCase_ == 10) {
       return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics) result_;
    }
    return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics.getDefaultInstance();
  }

  public static final int SEMANTIC_HASH_FIELD_NUMBER = 11;
  /**
   * <code>.spark.connect.AnalyzePlanResponse.SemanticHash semantic_hash = 11;</code>
   * @return Whether the semanticHash field is set.
   */
  @java.lang.Override
  public boolean hasSemanticHash() {
    return resultCase_ == 11;
  }
  /**
   * <code>.spark.connect.AnalyzePlanResponse.SemanticHash semantic_hash = 11;</code>
   * @return The semanticHash.
   */
  @java.lang.Override
  public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash getSemanticHash() {
    if (resultCase_ == 11) {
       return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash) result_;
    }
    return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash.getDefaultInstance();
  }
  /**
   * <code>.spark.connect.AnalyzePlanResponse.SemanticHash semantic_hash = 11;</code>
   */
  @java.lang.Override
  public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHashOrBuilder getSemanticHashOrBuilder() {
    if (resultCase_ == 11) {
       return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash) result_;
    }
    return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash.getDefaultInstance();
  }

  public static final int PERSIST_FIELD_NUMBER = 12;
  /**
   * <code>.spark.connect.AnalyzePlanResponse.Persist persist = 12;</code>
   * @return Whether the persist field is set.
   */
  @java.lang.Override
  public boolean hasPersist() {
    return resultCase_ == 12;
  }
  /**
   * <code>.spark.connect.AnalyzePlanResponse.Persist persist = 12;</code>
   * @return The persist.
   */
  @java.lang.Override
  public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist getPersist() {
    if (resultCase_ == 12) {
       return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist) result_;
    }
    return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist.getDefaultInstance();
  }
  /**
   * <code>.spark.connect.AnalyzePlanResponse.Persist persist = 12;</code>
   */
  @java.lang.Override
  public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.PersistOrBuilder getPersistOrBuilder() {
    if (resultCase_ == 12) {
       return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist) result_;
    }
    return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist.getDefaultInstance();
  }

  public static final int UNPERSIST_FIELD_NUMBER = 13;
  /**
   * <code>.spark.connect.AnalyzePlanResponse.Unpersist unpersist = 13;</code>
   * @return Whether the unpersist field is set.
   */
  @java.lang.Override
  public boolean hasUnpersist() {
    return resultCase_ == 13;
  }
  /**
   * <code>.spark.connect.AnalyzePlanResponse.Unpersist unpersist = 13;</code>
   * @return The unpersist.
   */
  @java.lang.Override
  public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist getUnpersist() {
    if (resultCase_ == 13) {
       return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist) result_;
    }
    return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist.getDefaultInstance();
  }
  /**
   * <code>.spark.connect.AnalyzePlanResponse.Unpersist unpersist = 13;</code>
   */
  @java.lang.Override
  public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.UnpersistOrBuilder getUnpersistOrBuilder() {
    if (resultCase_ == 13) {
       return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist) result_;
    }
    return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist.getDefaultInstance();
  }

  public static final int GET_STORAGE_LEVEL_FIELD_NUMBER = 14;
  /**
   * <code>.spark.connect.AnalyzePlanResponse.GetStorageLevel get_storage_level = 14;</code>
   * @return Whether the getStorageLevel field is set.
   */
  @java.lang.Override
  public boolean hasGetStorageLevel() {
    return resultCase_ == 14;
  }
  /**
   * <code>.spark.connect.AnalyzePlanResponse.GetStorageLevel get_storage_level = 14;</code>
   * @return The getStorageLevel.
   */
  @java.lang.Override
  public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel getGetStorageLevel() {
    if (resultCase_ == 14) {
       return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel) result_;
    }
    return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel.getDefaultInstance();
  }
  /**
   * <code>.spark.connect.AnalyzePlanResponse.GetStorageLevel get_storage_level = 14;</code>
   */
  @java.lang.Override
  public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevelOrBuilder getGetStorageLevelOrBuilder() {
    if (resultCase_ == 14) {
       return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel) result_;
    }
    return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel.getDefaultInstance();
  }

  private byte memoizedIsInitialized = -1;
  @java.lang.Override
  public final boolean isInitialized() {
    byte isInitialized = memoizedIsInitialized;
    if (isInitialized == 1) return true;
    if (isInitialized == 0) return false;

    memoizedIsInitialized = 1;
    return true;
  }

  @java.lang.Override
  public void writeTo(com.google.protobuf.CodedOutputStream output)
                      throws java.io.IOException {
    if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(sessionId_)) {
      com.google.protobuf.GeneratedMessageV3.writeString(output, 1, sessionId_);
    }
    if (resultCase_ == 2) {
      output.writeMessage(2, (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema) result_);
    }
    if (resultCase_ == 3) {
      output.writeMessage(3, (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain) result_);
    }
    if (resultCase_ == 4) {
      output.writeMessage(4, (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString) result_);
    }
    if (resultCase_ == 5) {
      output.writeMessage(5, (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal) result_);
    }
    if (resultCase_ == 6) {
      output.writeMessage(6, (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming) result_);
    }
    if (resultCase_ == 7) {
      output.writeMessage(7, (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles) result_);
    }
    if (resultCase_ == 8) {
      output.writeMessage(8, (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion) result_);
    }
    if (resultCase_ == 9) {
      output.writeMessage(9, (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse) result_);
    }
    if (resultCase_ == 10) {
      output.writeMessage(10, (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics) result_);
    }
    if (resultCase_ == 11) {
      output.writeMessage(11, (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash) result_);
    }
    if (resultCase_ == 12) {
      output.writeMessage(12, (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist) result_);
    }
    if (resultCase_ == 13) {
      output.writeMessage(13, (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist) result_);
    }
    if (resultCase_ == 14) {
      output.writeMessage(14, (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel) result_);
    }
    getUnknownFields().writeTo(output);
  }

  @java.lang.Override
  public int getSerializedSize() {
    int size = memoizedSize;
    if (size != -1) return size;

    size = 0;
    if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(sessionId_)) {
      size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, sessionId_);
    }
    if (resultCase_ == 2) {
      size += com.google.protobuf.CodedOutputStream
        .computeMessageSize(2, (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema) result_);
    }
    if (resultCase_ == 3) {
      size += com.google.protobuf.CodedOutputStream
        .computeMessageSize(3, (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain) result_);
    }
    if (resultCase_ == 4) {
      size += com.google.protobuf.CodedOutputStream
        .computeMessageSize(4, (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString) result_);
    }
    if (resultCase_ == 5) {
      size += com.google.protobuf.CodedOutputStream
        .computeMessageSize(5, (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal) result_);
    }
    if (resultCase_ == 6) {
      size += com.google.protobuf.CodedOutputStream
        .computeMessageSize(6, (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming) result_);
    }
    if (resultCase_ == 7) {
      size += com.google.protobuf.CodedOutputStream
        .computeMessageSize(7, (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles) result_);
    }
    if (resultCase_ == 8) {
      size += com.google.protobuf.CodedOutputStream
        .computeMessageSize(8, (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion) result_);
    }
    if (resultCase_ == 9) {
      size += com.google.protobuf.CodedOutputStream
        .computeMessageSize(9, (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse) result_);
    }
    if (resultCase_ == 10) {
      size += com.google.protobuf.CodedOutputStream
        .computeMessageSize(10, (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics) result_);
    }
    if (resultCase_ == 11) {
      size += com.google.protobuf.CodedOutputStream
        .computeMessageSize(11, (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash) result_);
    }
    if (resultCase_ == 12) {
      size += com.google.protobuf.CodedOutputStream
        .computeMessageSize(12, (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist) result_);
    }
    if (resultCase_ == 13) {
      size += com.google.protobuf.CodedOutputStream
        .computeMessageSize(13, (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist) result_);
    }
    if (resultCase_ == 14) {
      size += com.google.protobuf.CodedOutputStream
        .computeMessageSize(14, (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel) result_);
    }
    size += getUnknownFields().getSerializedSize();
    memoizedSize = size;
    return size;
  }

  @java.lang.Override
  public boolean equals(final java.lang.Object obj) {
    if (obj == this) {
     return true;
    }
    if (!(obj instanceof org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse)) {
      return super.equals(obj);
    }
    org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse other = (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse) obj;

    if (!getSessionId()
        .equals(other.getSessionId())) return false;
    if (!getResultCase().equals(other.getResultCase())) return false;
    switch (resultCase_) {
      case 2:
        if (!getSchema()
            .equals(other.getSchema())) return false;
        break;
      case 3:
        if (!getExplain()
            .equals(other.getExplain())) return false;
        break;
      case 4:
        if (!getTreeString()
            .equals(other.getTreeString())) return false;
        break;
      case 5:
        if (!getIsLocal()
            .equals(other.getIsLocal())) return false;
        break;
      case 6:
        if (!getIsStreaming()
            .equals(other.getIsStreaming())) return false;
        break;
      case 7:
        if (!getInputFiles()
            .equals(other.getInputFiles())) return false;
        break;
      case 8:
        if (!getSparkVersion()
            .equals(other.getSparkVersion())) return false;
        break;
      case 9:
        if (!getDdlParse()
            .equals(other.getDdlParse())) return false;
        break;
      case 10:
        if (!getSameSemantics()
            .equals(other.getSameSemantics())) return false;
        break;
      case 11:
        if (!getSemanticHash()
            .equals(other.getSemanticHash())) return false;
        break;
      case 12:
        if (!getPersist()
            .equals(other.getPersist())) return false;
        break;
      case 13:
        if (!getUnpersist()
            .equals(other.getUnpersist())) return false;
        break;
      case 14:
        if (!getGetStorageLevel()
            .equals(other.getGetStorageLevel())) return false;
        break;
      case 0:
      default:
    }
    if (!getUnknownFields().equals(other.getUnknownFields())) return false;
    return true;
  }

  @java.lang.Override
  public int hashCode() {
    if (memoizedHashCode != 0) {
      return memoizedHashCode;
    }
    int hash = 41;
    hash = (19 * hash) + getDescriptor().hashCode();
    hash = (37 * hash) + SESSION_ID_FIELD_NUMBER;
    hash = (53 * hash) + getSessionId().hashCode();
    switch (resultCase_) {
      case 2:
        hash = (37 * hash) + SCHEMA_FIELD_NUMBER;
        hash = (53 * hash) + getSchema().hashCode();
        break;
      case 3:
        hash = (37 * hash) + EXPLAIN_FIELD_NUMBER;
        hash = (53 * hash) + getExplain().hashCode();
        break;
      case 4:
        hash = (37 * hash) + TREE_STRING_FIELD_NUMBER;
        hash = (53 * hash) + getTreeString().hashCode();
        break;
      case 5:
        hash = (37 * hash) + IS_LOCAL_FIELD_NUMBER;
        hash = (53 * hash) + getIsLocal().hashCode();
        break;
      case 6:
        hash = (37 * hash) + IS_STREAMING_FIELD_NUMBER;
        hash = (53 * hash) + getIsStreaming().hashCode();
        break;
      case 7:
        hash = (37 * hash) + INPUT_FILES_FIELD_NUMBER;
        hash = (53 * hash) + getInputFiles().hashCode();
        break;
      case 8:
        hash = (37 * hash) + SPARK_VERSION_FIELD_NUMBER;
        hash = (53 * hash) + getSparkVersion().hashCode();
        break;
      case 9:
        hash = (37 * hash) + DDL_PARSE_FIELD_NUMBER;
        hash = (53 * hash) + getDdlParse().hashCode();
        break;
      case 10:
        hash = (37 * hash) + SAME_SEMANTICS_FIELD_NUMBER;
        hash = (53 * hash) + getSameSemantics().hashCode();
        break;
      case 11:
        hash = (37 * hash) + SEMANTIC_HASH_FIELD_NUMBER;
        hash = (53 * hash) + getSemanticHash().hashCode();
        break;
      case 12:
        hash = (37 * hash) + PERSIST_FIELD_NUMBER;
        hash = (53 * hash) + getPersist().hashCode();
        break;
      case 13:
        hash = (37 * hash) + UNPERSIST_FIELD_NUMBER;
        hash = (53 * hash) + getUnpersist().hashCode();
        break;
      case 14:
        hash = (37 * hash) + GET_STORAGE_LEVEL_FIELD_NUMBER;
        hash = (53 * hash) + getGetStorageLevel().hashCode();
        break;
      case 0:
      default:
    }
    hash = (29 * hash) + getUnknownFields().hashCode();
    memoizedHashCode = hash;
    return hash;
  }

  public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse parseFrom(
      java.nio.ByteBuffer data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }
  public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse parseFrom(
      java.nio.ByteBuffer data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }
  public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse parseFrom(
      com.google.protobuf.ByteString data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }
  public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse parseFrom(
      com.google.protobuf.ByteString data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }
  public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse parseFrom(byte[] data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }
  public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse parseFrom(
      byte[] data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }
  public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse parseFrom(java.io.InputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input);
  }
  public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse parseFrom(
      java.io.InputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input, extensionRegistry);
  }
  public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse parseDelimitedFrom(java.io.InputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseDelimitedWithIOException(PARSER, input);
  }
  public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse parseDelimitedFrom(
      java.io.InputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
  }
  public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse parseFrom(
      com.google.protobuf.CodedInputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input);
  }
  public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse parseFrom(
      com.google.protobuf.CodedInputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input, extensionRegistry);
  }

  @java.lang.Override
  public Builder newBuilderForType() { return newBuilder(); }
  public static Builder newBuilder() {
    return DEFAULT_INSTANCE.toBuilder();
  }
  public static Builder newBuilder(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse prototype) {
    return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
  }
  @java.lang.Override
  public Builder toBuilder() {
    return this == DEFAULT_INSTANCE
        ? new Builder() : new Builder().mergeFrom(this);
  }

  @java.lang.Override
  protected Builder newBuilderForType(
      com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
    Builder builder = new Builder(parent);
    return builder;
  }
  /**
   * <pre>
   * Response to performing analysis of the query. Contains relevant metadata to be able to
   * reason about the performance.
   * </pre>
   *
   * Protobuf type {@code spark.connect.AnalyzePlanResponse}
   */
  public static final class Builder extends
      com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
      // @@protoc_insertion_point(builder_implements:spark.connect.AnalyzePlanResponse)
      org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponseOrBuilder {
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.class, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Builder.class);
    }

    // Construct using org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.newBuilder()
    private Builder() {

    }

    private Builder(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      super(parent);

    }
    @java.lang.Override
    public Builder clear() {
      super.clear();
      sessionId_ = "";

      if (schemaBuilder_ != null) {
        schemaBuilder_.clear();
      }
      if (explainBuilder_ != null) {
        explainBuilder_.clear();
      }
      if (treeStringBuilder_ != null) {
        treeStringBuilder_.clear();
      }
      if (isLocalBuilder_ != null) {
        isLocalBuilder_.clear();
      }
      if (isStreamingBuilder_ != null) {
        isStreamingBuilder_.clear();
      }
      if (inputFilesBuilder_ != null) {
        inputFilesBuilder_.clear();
      }
      if (sparkVersionBuilder_ != null) {
        sparkVersionBuilder_.clear();
      }
      if (ddlParseBuilder_ != null) {
        ddlParseBuilder_.clear();
      }
      if (sameSemanticsBuilder_ != null) {
        sameSemanticsBuilder_.clear();
      }
      if (semanticHashBuilder_ != null) {
        semanticHashBuilder_.clear();
      }
      if (persistBuilder_ != null) {
        persistBuilder_.clear();
      }
      if (unpersistBuilder_ != null) {
        unpersistBuilder_.clear();
      }
      if (getStorageLevelBuilder_ != null) {
        getStorageLevelBuilder_.clear();
      }
      resultCase_ = 0;
      result_ = null;
      return this;
    }

    @java.lang.Override
    public com.google.protobuf.Descriptors.Descriptor
        getDescriptorForType() {
      return org.apache.kyuubi.engine.spark.connect.proto.Base.internal_static_spark_connect_AnalyzePlanResponse_descriptor;
    }

    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse getDefaultInstanceForType() {
      return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.getDefaultInstance();
    }

    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse build() {
      org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse result = buildPartial();
      if (!result.isInitialized()) {
        throw newUninitializedMessageException(result);
      }
      return result;
    }

    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse buildPartial() {
      org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse result = new org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse(this);
      result.sessionId_ = sessionId_;
      if (resultCase_ == 2) {
        if (schemaBuilder_ == null) {
          result.result_ = result_;
        } else {
          result.result_ = schemaBuilder_.build();
        }
      }
      if (resultCase_ == 3) {
        if (explainBuilder_ == null) {
          result.result_ = result_;
        } else {
          result.result_ = explainBuilder_.build();
        }
      }
      if (resultCase_ == 4) {
        if (treeStringBuilder_ == null) {
          result.result_ = result_;
        } else {
          result.result_ = treeStringBuilder_.build();
        }
      }
      if (resultCase_ == 5) {
        if (isLocalBuilder_ == null) {
          result.result_ = result_;
        } else {
          result.result_ = isLocalBuilder_.build();
        }
      }
      if (resultCase_ == 6) {
        if (isStreamingBuilder_ == null) {
          result.result_ = result_;
        } else {
          result.result_ = isStreamingBuilder_.build();
        }
      }
      if (resultCase_ == 7) {
        if (inputFilesBuilder_ == null) {
          result.result_ = result_;
        } else {
          result.result_ = inputFilesBuilder_.build();
        }
      }
      if (resultCase_ == 8) {
        if (sparkVersionBuilder_ == null) {
          result.result_ = result_;
        } else {
          result.result_ = sparkVersionBuilder_.build();
        }
      }
      if (resultCase_ == 9) {
        if (ddlParseBuilder_ == null) {
          result.result_ = result_;
        } else {
          result.result_ = ddlParseBuilder_.build();
        }
      }
      if (resultCase_ == 10) {
        if (sameSemanticsBuilder_ == null) {
          result.result_ = result_;
        } else {
          result.result_ = sameSemanticsBuilder_.build();
        }
      }
      if (resultCase_ == 11) {
        if (semanticHashBuilder_ == null) {
          result.result_ = result_;
        } else {
          result.result_ = semanticHashBuilder_.build();
        }
      }
      if (resultCase_ == 12) {
        if (persistBuilder_ == null) {
          result.result_ = result_;
        } else {
          result.result_ = persistBuilder_.build();
        }
      }
      if (resultCase_ == 13) {
        if (unpersistBuilder_ == null) {
          result.result_ = result_;
        } else {
          result.result_ = unpersistBuilder_.build();
        }
      }
      if (resultCase_ == 14) {
        if (getStorageLevelBuilder_ == null) {
          result.result_ = result_;
        } else {
          result.result_ = getStorageLevelBuilder_.build();
        }
      }
      result.resultCase_ = resultCase_;
      onBuilt();
      return result;
    }

    @java.lang.Override
    public Builder clone() {
      return super.clone();
    }
    @java.lang.Override
    public Builder setField(
        com.google.protobuf.Descriptors.FieldDescriptor field,
        java.lang.Object value) {
      return super.setField(field, value);
    }
    @java.lang.Override
    public Builder clearField(
        com.google.protobuf.Descriptors.FieldDescriptor field) {
      return super.clearField(field);
    }
    @java.lang.Override
    public Builder clearOneof(
        com.google.protobuf.Descriptors.OneofDescriptor oneof) {
      return super.clearOneof(oneof);
    }
    @java.lang.Override
    public Builder setRepeatedField(
        com.google.protobuf.Descriptors.FieldDescriptor field,
        int index, java.lang.Object value) {
      return super.setRepeatedField(field, index, value);
    }
    @java.lang.Override
    public Builder addRepeatedField(
        com.google.protobuf.Descriptors.FieldDescriptor field,
        java.lang.Object value) {
      return super.addRepeatedField(field, value);
    }
    @java.lang.Override
    public Builder mergeFrom(com.google.protobuf.Message other) {
      if (other instanceof org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse) {
        return mergeFrom((org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse)other);
      } else {
        super.mergeFrom(other);
        return this;
      }
    }

    public Builder mergeFrom(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse other) {
      if (other == org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.getDefaultInstance()) return this;
      if (!other.getSessionId().isEmpty()) {
        sessionId_ = other.sessionId_;
        onChanged();
      }
      switch (other.getResultCase()) {
        case SCHEMA: {
          mergeSchema(other.getSchema());
          break;
        }
        case EXPLAIN: {
          mergeExplain(other.getExplain());
          break;
        }
        case TREE_STRING: {
          mergeTreeString(other.getTreeString());
          break;
        }
        case IS_LOCAL: {
          mergeIsLocal(other.getIsLocal());
          break;
        }
        case IS_STREAMING: {
          mergeIsStreaming(other.getIsStreaming());
          break;
        }
        case INPUT_FILES: {
          mergeInputFiles(other.getInputFiles());
          break;
        }
        case SPARK_VERSION: {
          mergeSparkVersion(other.getSparkVersion());
          break;
        }
        case DDL_PARSE: {
          mergeDdlParse(other.getDdlParse());
          break;
        }
        case SAME_SEMANTICS: {
          mergeSameSemantics(other.getSameSemantics());
          break;
        }
        case SEMANTIC_HASH: {
          mergeSemanticHash(other.getSemanticHash());
          break;
        }
        case PERSIST: {
          mergePersist(other.getPersist());
          break;
        }
        case UNPERSIST: {
          mergeUnpersist(other.getUnpersist());
          break;
        }
        case GET_STORAGE_LEVEL: {
          mergeGetStorageLevel(other.getGetStorageLevel());
          break;
        }
        case RESULT_NOT_SET: {
          break;
        }
      }
      this.mergeUnknownFields(other.getUnknownFields());
      onChanged();
      return this;
    }

    @java.lang.Override
    public final boolean isInitialized() {
      return true;
    }

    @java.lang.Override
    public Builder mergeFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              sessionId_ = input.readStringRequireUtf8();

              break;
            } // case 10
            case 18: {
              input.readMessage(
                  getSchemaFieldBuilder().getBuilder(),
                  extensionRegistry);
              resultCase_ = 2;
              break;
            } // case 18
            case 26: {
              input.readMessage(
                  getExplainFieldBuilder().getBuilder(),
                  extensionRegistry);
              resultCase_ = 3;
              break;
            } // case 26
            case 34: {
              input.readMessage(
                  getTreeStringFieldBuilder().getBuilder(),
                  extensionRegistry);
              resultCase_ = 4;
              break;
            } // case 34
            case 42: {
              input.readMessage(
                  getIsLocalFieldBuilder().getBuilder(),
                  extensionRegistry);
              resultCase_ = 5;
              break;
            } // case 42
            case 50: {
              input.readMessage(
                  getIsStreamingFieldBuilder().getBuilder(),
                  extensionRegistry);
              resultCase_ = 6;
              break;
            } // case 50
            case 58: {
              input.readMessage(
                  getInputFilesFieldBuilder().getBuilder(),
                  extensionRegistry);
              resultCase_ = 7;
              break;
            } // case 58
            case 66: {
              input.readMessage(
                  getSparkVersionFieldBuilder().getBuilder(),
                  extensionRegistry);
              resultCase_ = 8;
              break;
            } // case 66
            case 74: {
              input.readMessage(
                  getDdlParseFieldBuilder().getBuilder(),
                  extensionRegistry);
              resultCase_ = 9;
              break;
            } // case 74
            case 82: {
              input.readMessage(
                  getSameSemanticsFieldBuilder().getBuilder(),
                  extensionRegistry);
              resultCase_ = 10;
              break;
            } // case 82
            case 90: {
              input.readMessage(
                  getSemanticHashFieldBuilder().getBuilder(),
                  extensionRegistry);
              resultCase_ = 11;
              break;
            } // case 90
            case 98: {
              input.readMessage(
                  getPersistFieldBuilder().getBuilder(),
                  extensionRegistry);
              resultCase_ = 12;
              break;
            } // case 98
            case 106: {
              input.readMessage(
                  getUnpersistFieldBuilder().getBuilder(),
                  extensionRegistry);
              resultCase_ = 13;
              break;
            } // case 106
            case 114: {
              input.readMessage(
                  getGetStorageLevelFieldBuilder().getBuilder(),
                  extensionRegistry);
              resultCase_ = 14;
              break;
            } // case 114
            default: {
              if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                done = true; // was an endgroup tag
              }
              break;
            } // default:
          } // switch (tag)
        } // while (!done)
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.unwrapIOException();
      } finally {
        onChanged();
      } // finally
      return this;
    }
    private int resultCase_ = 0;
    private java.lang.Object result_;
    public ResultCase
        getResultCase() {
      return ResultCase.forNumber(
          resultCase_);
    }

    public Builder clearResult() {
      resultCase_ = 0;
      result_ = null;
      onChanged();
      return this;
    }


    private java.lang.Object sessionId_ = "";
    /**
     * <code>string session_id = 1;</code>
     * @return The sessionId.
     */
    public java.lang.String getSessionId() {
      java.lang.Object ref = sessionId_;
      if (!(ref instanceof java.lang.String)) {
        com.google.protobuf.ByteString bs =
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        sessionId_ = s;
        return s;
      } else {
        return (java.lang.String) ref;
      }
    }
    /**
     * <code>string session_id = 1;</code>
     * @return The bytes for sessionId.
     */
    public com.google.protobuf.ByteString
        getSessionIdBytes() {
      java.lang.Object ref = sessionId_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        sessionId_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }
    /**
     * <code>string session_id = 1;</code>
     * @param value The sessionId to set.
     * @return This builder for chaining.
     */
    public Builder setSessionId(
        java.lang.String value) {
      if (value == null) {
    throw new NullPointerException();
  }
  
      sessionId_ = value;
      onChanged();
      return this;
    }
    /**
     * <code>string session_id = 1;</code>
     * @return This builder for chaining.
     */
    public Builder clearSessionId() {
      
      sessionId_ = getDefaultInstance().getSessionId();
      onChanged();
      return this;
    }
    /**
     * <code>string session_id = 1;</code>
     * @param value The bytes for sessionId to set.
     * @return This builder for chaining.
     */
    public Builder setSessionIdBytes(
        com.google.protobuf.ByteString value) {
      if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
      
      sessionId_ = value;
      onChanged();
      return this;
    }

    private com.google.protobuf.SingleFieldBuilderV3<
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema.Builder, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SchemaOrBuilder> schemaBuilder_;
    /**
     * <code>.spark.connect.AnalyzePlanResponse.Schema schema = 2;</code>
     * @return Whether the schema field is set.
     */
    @java.lang.Override
    public boolean hasSchema() {
      return resultCase_ == 2;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.Schema schema = 2;</code>
     * @return The schema.
     */
    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema getSchema() {
      if (schemaBuilder_ == null) {
        if (resultCase_ == 2) {
          return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema) result_;
        }
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema.getDefaultInstance();
      } else {
        if (resultCase_ == 2) {
          return schemaBuilder_.getMessage();
        }
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema.getDefaultInstance();
      }
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.Schema schema = 2;</code>
     */
    public Builder setSchema(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema value) {
      if (schemaBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        result_ = value;
        onChanged();
      } else {
        schemaBuilder_.setMessage(value);
      }
      resultCase_ = 2;
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.Schema schema = 2;</code>
     */
    public Builder setSchema(
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema.Builder builderForValue) {
      if (schemaBuilder_ == null) {
        result_ = builderForValue.build();
        onChanged();
      } else {
        schemaBuilder_.setMessage(builderForValue.build());
      }
      resultCase_ = 2;
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.Schema schema = 2;</code>
     */
    public Builder mergeSchema(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema value) {
      if (schemaBuilder_ == null) {
        if (resultCase_ == 2 &&
            result_ != org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema.getDefaultInstance()) {
          result_ = org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema.newBuilder((org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema) result_)
              .mergeFrom(value).buildPartial();
        } else {
          result_ = value;
        }
        onChanged();
      } else {
        if (resultCase_ == 2) {
          schemaBuilder_.mergeFrom(value);
        } else {
          schemaBuilder_.setMessage(value);
        }
      }
      resultCase_ = 2;
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.Schema schema = 2;</code>
     */
    public Builder clearSchema() {
      if (schemaBuilder_ == null) {
        if (resultCase_ == 2) {
          resultCase_ = 0;
          result_ = null;
          onChanged();
        }
      } else {
        if (resultCase_ == 2) {
          resultCase_ = 0;
          result_ = null;
        }
        schemaBuilder_.clear();
      }
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.Schema schema = 2;</code>
     */
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema.Builder getSchemaBuilder() {
      return getSchemaFieldBuilder().getBuilder();
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.Schema schema = 2;</code>
     */
    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SchemaOrBuilder getSchemaOrBuilder() {
      if ((resultCase_ == 2) && (schemaBuilder_ != null)) {
        return schemaBuilder_.getMessageOrBuilder();
      } else {
        if (resultCase_ == 2) {
          return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema) result_;
        }
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema.getDefaultInstance();
      }
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.Schema schema = 2;</code>
     */
    private com.google.protobuf.SingleFieldBuilderV3<
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema.Builder, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SchemaOrBuilder> 
        getSchemaFieldBuilder() {
      if (schemaBuilder_ == null) {
        if (!(resultCase_ == 2)) {
          result_ = org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema.getDefaultInstance();
        }
        schemaBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
            org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema.Builder, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SchemaOrBuilder>(
                (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Schema) result_,
                getParentForChildren(),
                isClean());
        result_ = null;
      }
      resultCase_ = 2;
      onChanged();;
      return schemaBuilder_;
    }

    private com.google.protobuf.SingleFieldBuilderV3<
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain.Builder, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.ExplainOrBuilder> explainBuilder_;
    /**
     * <code>.spark.connect.AnalyzePlanResponse.Explain explain = 3;</code>
     * @return Whether the explain field is set.
     */
    @java.lang.Override
    public boolean hasExplain() {
      return resultCase_ == 3;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.Explain explain = 3;</code>
     * @return The explain.
     */
    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain getExplain() {
      if (explainBuilder_ == null) {
        if (resultCase_ == 3) {
          return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain) result_;
        }
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain.getDefaultInstance();
      } else {
        if (resultCase_ == 3) {
          return explainBuilder_.getMessage();
        }
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain.getDefaultInstance();
      }
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.Explain explain = 3;</code>
     */
    public Builder setExplain(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain value) {
      if (explainBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        result_ = value;
        onChanged();
      } else {
        explainBuilder_.setMessage(value);
      }
      resultCase_ = 3;
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.Explain explain = 3;</code>
     */
    public Builder setExplain(
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain.Builder builderForValue) {
      if (explainBuilder_ == null) {
        result_ = builderForValue.build();
        onChanged();
      } else {
        explainBuilder_.setMessage(builderForValue.build());
      }
      resultCase_ = 3;
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.Explain explain = 3;</code>
     */
    public Builder mergeExplain(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain value) {
      if (explainBuilder_ == null) {
        if (resultCase_ == 3 &&
            result_ != org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain.getDefaultInstance()) {
          result_ = org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain.newBuilder((org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain) result_)
              .mergeFrom(value).buildPartial();
        } else {
          result_ = value;
        }
        onChanged();
      } else {
        if (resultCase_ == 3) {
          explainBuilder_.mergeFrom(value);
        } else {
          explainBuilder_.setMessage(value);
        }
      }
      resultCase_ = 3;
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.Explain explain = 3;</code>
     */
    public Builder clearExplain() {
      if (explainBuilder_ == null) {
        if (resultCase_ == 3) {
          resultCase_ = 0;
          result_ = null;
          onChanged();
        }
      } else {
        if (resultCase_ == 3) {
          resultCase_ = 0;
          result_ = null;
        }
        explainBuilder_.clear();
      }
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.Explain explain = 3;</code>
     */
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain.Builder getExplainBuilder() {
      return getExplainFieldBuilder().getBuilder();
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.Explain explain = 3;</code>
     */
    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.ExplainOrBuilder getExplainOrBuilder() {
      if ((resultCase_ == 3) && (explainBuilder_ != null)) {
        return explainBuilder_.getMessageOrBuilder();
      } else {
        if (resultCase_ == 3) {
          return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain) result_;
        }
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain.getDefaultInstance();
      }
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.Explain explain = 3;</code>
     */
    private com.google.protobuf.SingleFieldBuilderV3<
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain.Builder, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.ExplainOrBuilder> 
        getExplainFieldBuilder() {
      if (explainBuilder_ == null) {
        if (!(resultCase_ == 3)) {
          result_ = org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain.getDefaultInstance();
        }
        explainBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
            org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain.Builder, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.ExplainOrBuilder>(
                (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Explain) result_,
                getParentForChildren(),
                isClean());
        result_ = null;
      }
      resultCase_ = 3;
      onChanged();;
      return explainBuilder_;
    }

    private com.google.protobuf.SingleFieldBuilderV3<
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString.Builder, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeStringOrBuilder> treeStringBuilder_;
    /**
     * <code>.spark.connect.AnalyzePlanResponse.TreeString tree_string = 4;</code>
     * @return Whether the treeString field is set.
     */
    @java.lang.Override
    public boolean hasTreeString() {
      return resultCase_ == 4;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.TreeString tree_string = 4;</code>
     * @return The treeString.
     */
    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString getTreeString() {
      if (treeStringBuilder_ == null) {
        if (resultCase_ == 4) {
          return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString) result_;
        }
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString.getDefaultInstance();
      } else {
        if (resultCase_ == 4) {
          return treeStringBuilder_.getMessage();
        }
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString.getDefaultInstance();
      }
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.TreeString tree_string = 4;</code>
     */
    public Builder setTreeString(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString value) {
      if (treeStringBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        result_ = value;
        onChanged();
      } else {
        treeStringBuilder_.setMessage(value);
      }
      resultCase_ = 4;
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.TreeString tree_string = 4;</code>
     */
    public Builder setTreeString(
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString.Builder builderForValue) {
      if (treeStringBuilder_ == null) {
        result_ = builderForValue.build();
        onChanged();
      } else {
        treeStringBuilder_.setMessage(builderForValue.build());
      }
      resultCase_ = 4;
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.TreeString tree_string = 4;</code>
     */
    public Builder mergeTreeString(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString value) {
      if (treeStringBuilder_ == null) {
        if (resultCase_ == 4 &&
            result_ != org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString.getDefaultInstance()) {
          result_ = org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString.newBuilder((org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString) result_)
              .mergeFrom(value).buildPartial();
        } else {
          result_ = value;
        }
        onChanged();
      } else {
        if (resultCase_ == 4) {
          treeStringBuilder_.mergeFrom(value);
        } else {
          treeStringBuilder_.setMessage(value);
        }
      }
      resultCase_ = 4;
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.TreeString tree_string = 4;</code>
     */
    public Builder clearTreeString() {
      if (treeStringBuilder_ == null) {
        if (resultCase_ == 4) {
          resultCase_ = 0;
          result_ = null;
          onChanged();
        }
      } else {
        if (resultCase_ == 4) {
          resultCase_ = 0;
          result_ = null;
        }
        treeStringBuilder_.clear();
      }
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.TreeString tree_string = 4;</code>
     */
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString.Builder getTreeStringBuilder() {
      return getTreeStringFieldBuilder().getBuilder();
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.TreeString tree_string = 4;</code>
     */
    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeStringOrBuilder getTreeStringOrBuilder() {
      if ((resultCase_ == 4) && (treeStringBuilder_ != null)) {
        return treeStringBuilder_.getMessageOrBuilder();
      } else {
        if (resultCase_ == 4) {
          return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString) result_;
        }
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString.getDefaultInstance();
      }
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.TreeString tree_string = 4;</code>
     */
    private com.google.protobuf.SingleFieldBuilderV3<
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString.Builder, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeStringOrBuilder> 
        getTreeStringFieldBuilder() {
      if (treeStringBuilder_ == null) {
        if (!(resultCase_ == 4)) {
          result_ = org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString.getDefaultInstance();
        }
        treeStringBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
            org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString.Builder, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeStringOrBuilder>(
                (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.TreeString) result_,
                getParentForChildren(),
                isClean());
        result_ = null;
      }
      resultCase_ = 4;
      onChanged();;
      return treeStringBuilder_;
    }

    private com.google.protobuf.SingleFieldBuilderV3<
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal.Builder, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocalOrBuilder> isLocalBuilder_;
    /**
     * <code>.spark.connect.AnalyzePlanResponse.IsLocal is_local = 5;</code>
     * @return Whether the isLocal field is set.
     */
    @java.lang.Override
    public boolean hasIsLocal() {
      return resultCase_ == 5;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.IsLocal is_local = 5;</code>
     * @return The isLocal.
     */
    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal getIsLocal() {
      if (isLocalBuilder_ == null) {
        if (resultCase_ == 5) {
          return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal) result_;
        }
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal.getDefaultInstance();
      } else {
        if (resultCase_ == 5) {
          return isLocalBuilder_.getMessage();
        }
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal.getDefaultInstance();
      }
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.IsLocal is_local = 5;</code>
     */
    public Builder setIsLocal(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal value) {
      if (isLocalBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        result_ = value;
        onChanged();
      } else {
        isLocalBuilder_.setMessage(value);
      }
      resultCase_ = 5;
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.IsLocal is_local = 5;</code>
     */
    public Builder setIsLocal(
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal.Builder builderForValue) {
      if (isLocalBuilder_ == null) {
        result_ = builderForValue.build();
        onChanged();
      } else {
        isLocalBuilder_.setMessage(builderForValue.build());
      }
      resultCase_ = 5;
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.IsLocal is_local = 5;</code>
     */
    public Builder mergeIsLocal(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal value) {
      if (isLocalBuilder_ == null) {
        if (resultCase_ == 5 &&
            result_ != org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal.getDefaultInstance()) {
          result_ = org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal.newBuilder((org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal) result_)
              .mergeFrom(value).buildPartial();
        } else {
          result_ = value;
        }
        onChanged();
      } else {
        if (resultCase_ == 5) {
          isLocalBuilder_.mergeFrom(value);
        } else {
          isLocalBuilder_.setMessage(value);
        }
      }
      resultCase_ = 5;
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.IsLocal is_local = 5;</code>
     */
    public Builder clearIsLocal() {
      if (isLocalBuilder_ == null) {
        if (resultCase_ == 5) {
          resultCase_ = 0;
          result_ = null;
          onChanged();
        }
      } else {
        if (resultCase_ == 5) {
          resultCase_ = 0;
          result_ = null;
        }
        isLocalBuilder_.clear();
      }
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.IsLocal is_local = 5;</code>
     */
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal.Builder getIsLocalBuilder() {
      return getIsLocalFieldBuilder().getBuilder();
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.IsLocal is_local = 5;</code>
     */
    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocalOrBuilder getIsLocalOrBuilder() {
      if ((resultCase_ == 5) && (isLocalBuilder_ != null)) {
        return isLocalBuilder_.getMessageOrBuilder();
      } else {
        if (resultCase_ == 5) {
          return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal) result_;
        }
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal.getDefaultInstance();
      }
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.IsLocal is_local = 5;</code>
     */
    private com.google.protobuf.SingleFieldBuilderV3<
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal.Builder, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocalOrBuilder> 
        getIsLocalFieldBuilder() {
      if (isLocalBuilder_ == null) {
        if (!(resultCase_ == 5)) {
          result_ = org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal.getDefaultInstance();
        }
        isLocalBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
            org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal.Builder, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocalOrBuilder>(
                (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsLocal) result_,
                getParentForChildren(),
                isClean());
        result_ = null;
      }
      resultCase_ = 5;
      onChanged();;
      return isLocalBuilder_;
    }

    private com.google.protobuf.SingleFieldBuilderV3<
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming.Builder, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreamingOrBuilder> isStreamingBuilder_;
    /**
     * <code>.spark.connect.AnalyzePlanResponse.IsStreaming is_streaming = 6;</code>
     * @return Whether the isStreaming field is set.
     */
    @java.lang.Override
    public boolean hasIsStreaming() {
      return resultCase_ == 6;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.IsStreaming is_streaming = 6;</code>
     * @return The isStreaming.
     */
    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming getIsStreaming() {
      if (isStreamingBuilder_ == null) {
        if (resultCase_ == 6) {
          return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming) result_;
        }
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming.getDefaultInstance();
      } else {
        if (resultCase_ == 6) {
          return isStreamingBuilder_.getMessage();
        }
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming.getDefaultInstance();
      }
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.IsStreaming is_streaming = 6;</code>
     */
    public Builder setIsStreaming(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming value) {
      if (isStreamingBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        result_ = value;
        onChanged();
      } else {
        isStreamingBuilder_.setMessage(value);
      }
      resultCase_ = 6;
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.IsStreaming is_streaming = 6;</code>
     */
    public Builder setIsStreaming(
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming.Builder builderForValue) {
      if (isStreamingBuilder_ == null) {
        result_ = builderForValue.build();
        onChanged();
      } else {
        isStreamingBuilder_.setMessage(builderForValue.build());
      }
      resultCase_ = 6;
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.IsStreaming is_streaming = 6;</code>
     */
    public Builder mergeIsStreaming(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming value) {
      if (isStreamingBuilder_ == null) {
        if (resultCase_ == 6 &&
            result_ != org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming.getDefaultInstance()) {
          result_ = org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming.newBuilder((org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming) result_)
              .mergeFrom(value).buildPartial();
        } else {
          result_ = value;
        }
        onChanged();
      } else {
        if (resultCase_ == 6) {
          isStreamingBuilder_.mergeFrom(value);
        } else {
          isStreamingBuilder_.setMessage(value);
        }
      }
      resultCase_ = 6;
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.IsStreaming is_streaming = 6;</code>
     */
    public Builder clearIsStreaming() {
      if (isStreamingBuilder_ == null) {
        if (resultCase_ == 6) {
          resultCase_ = 0;
          result_ = null;
          onChanged();
        }
      } else {
        if (resultCase_ == 6) {
          resultCase_ = 0;
          result_ = null;
        }
        isStreamingBuilder_.clear();
      }
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.IsStreaming is_streaming = 6;</code>
     */
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming.Builder getIsStreamingBuilder() {
      return getIsStreamingFieldBuilder().getBuilder();
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.IsStreaming is_streaming = 6;</code>
     */
    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreamingOrBuilder getIsStreamingOrBuilder() {
      if ((resultCase_ == 6) && (isStreamingBuilder_ != null)) {
        return isStreamingBuilder_.getMessageOrBuilder();
      } else {
        if (resultCase_ == 6) {
          return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming) result_;
        }
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming.getDefaultInstance();
      }
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.IsStreaming is_streaming = 6;</code>
     */
    private com.google.protobuf.SingleFieldBuilderV3<
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming.Builder, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreamingOrBuilder> 
        getIsStreamingFieldBuilder() {
      if (isStreamingBuilder_ == null) {
        if (!(resultCase_ == 6)) {
          result_ = org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming.getDefaultInstance();
        }
        isStreamingBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
            org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming.Builder, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreamingOrBuilder>(
                (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.IsStreaming) result_,
                getParentForChildren(),
                isClean());
        result_ = null;
      }
      resultCase_ = 6;
      onChanged();;
      return isStreamingBuilder_;
    }

    private com.google.protobuf.SingleFieldBuilderV3<
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles.Builder, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFilesOrBuilder> inputFilesBuilder_;
    /**
     * <code>.spark.connect.AnalyzePlanResponse.InputFiles input_files = 7;</code>
     * @return Whether the inputFiles field is set.
     */
    @java.lang.Override
    public boolean hasInputFiles() {
      return resultCase_ == 7;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.InputFiles input_files = 7;</code>
     * @return The inputFiles.
     */
    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles getInputFiles() {
      if (inputFilesBuilder_ == null) {
        if (resultCase_ == 7) {
          return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles) result_;
        }
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles.getDefaultInstance();
      } else {
        if (resultCase_ == 7) {
          return inputFilesBuilder_.getMessage();
        }
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles.getDefaultInstance();
      }
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.InputFiles input_files = 7;</code>
     */
    public Builder setInputFiles(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles value) {
      if (inputFilesBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        result_ = value;
        onChanged();
      } else {
        inputFilesBuilder_.setMessage(value);
      }
      resultCase_ = 7;
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.InputFiles input_files = 7;</code>
     */
    public Builder setInputFiles(
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles.Builder builderForValue) {
      if (inputFilesBuilder_ == null) {
        result_ = builderForValue.build();
        onChanged();
      } else {
        inputFilesBuilder_.setMessage(builderForValue.build());
      }
      resultCase_ = 7;
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.InputFiles input_files = 7;</code>
     */
    public Builder mergeInputFiles(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles value) {
      if (inputFilesBuilder_ == null) {
        if (resultCase_ == 7 &&
            result_ != org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles.getDefaultInstance()) {
          result_ = org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles.newBuilder((org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles) result_)
              .mergeFrom(value).buildPartial();
        } else {
          result_ = value;
        }
        onChanged();
      } else {
        if (resultCase_ == 7) {
          inputFilesBuilder_.mergeFrom(value);
        } else {
          inputFilesBuilder_.setMessage(value);
        }
      }
      resultCase_ = 7;
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.InputFiles input_files = 7;</code>
     */
    public Builder clearInputFiles() {
      if (inputFilesBuilder_ == null) {
        if (resultCase_ == 7) {
          resultCase_ = 0;
          result_ = null;
          onChanged();
        }
      } else {
        if (resultCase_ == 7) {
          resultCase_ = 0;
          result_ = null;
        }
        inputFilesBuilder_.clear();
      }
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.InputFiles input_files = 7;</code>
     */
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles.Builder getInputFilesBuilder() {
      return getInputFilesFieldBuilder().getBuilder();
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.InputFiles input_files = 7;</code>
     */
    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFilesOrBuilder getInputFilesOrBuilder() {
      if ((resultCase_ == 7) && (inputFilesBuilder_ != null)) {
        return inputFilesBuilder_.getMessageOrBuilder();
      } else {
        if (resultCase_ == 7) {
          return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles) result_;
        }
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles.getDefaultInstance();
      }
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.InputFiles input_files = 7;</code>
     */
    private com.google.protobuf.SingleFieldBuilderV3<
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles.Builder, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFilesOrBuilder> 
        getInputFilesFieldBuilder() {
      if (inputFilesBuilder_ == null) {
        if (!(resultCase_ == 7)) {
          result_ = org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles.getDefaultInstance();
        }
        inputFilesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
            org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles.Builder, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFilesOrBuilder>(
                (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.InputFiles) result_,
                getParentForChildren(),
                isClean());
        result_ = null;
      }
      resultCase_ = 7;
      onChanged();;
      return inputFilesBuilder_;
    }

    private com.google.protobuf.SingleFieldBuilderV3<
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion.Builder, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersionOrBuilder> sparkVersionBuilder_;
    /**
     * <code>.spark.connect.AnalyzePlanResponse.SparkVersion spark_version = 8;</code>
     * @return Whether the sparkVersion field is set.
     */
    @java.lang.Override
    public boolean hasSparkVersion() {
      return resultCase_ == 8;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.SparkVersion spark_version = 8;</code>
     * @return The sparkVersion.
     */
    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion getSparkVersion() {
      if (sparkVersionBuilder_ == null) {
        if (resultCase_ == 8) {
          return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion) result_;
        }
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion.getDefaultInstance();
      } else {
        if (resultCase_ == 8) {
          return sparkVersionBuilder_.getMessage();
        }
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion.getDefaultInstance();
      }
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.SparkVersion spark_version = 8;</code>
     */
    public Builder setSparkVersion(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion value) {
      if (sparkVersionBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        result_ = value;
        onChanged();
      } else {
        sparkVersionBuilder_.setMessage(value);
      }
      resultCase_ = 8;
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.SparkVersion spark_version = 8;</code>
     */
    public Builder setSparkVersion(
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion.Builder builderForValue) {
      if (sparkVersionBuilder_ == null) {
        result_ = builderForValue.build();
        onChanged();
      } else {
        sparkVersionBuilder_.setMessage(builderForValue.build());
      }
      resultCase_ = 8;
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.SparkVersion spark_version = 8;</code>
     */
    public Builder mergeSparkVersion(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion value) {
      if (sparkVersionBuilder_ == null) {
        if (resultCase_ == 8 &&
            result_ != org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion.getDefaultInstance()) {
          result_ = org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion.newBuilder((org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion) result_)
              .mergeFrom(value).buildPartial();
        } else {
          result_ = value;
        }
        onChanged();
      } else {
        if (resultCase_ == 8) {
          sparkVersionBuilder_.mergeFrom(value);
        } else {
          sparkVersionBuilder_.setMessage(value);
        }
      }
      resultCase_ = 8;
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.SparkVersion spark_version = 8;</code>
     */
    public Builder clearSparkVersion() {
      if (sparkVersionBuilder_ == null) {
        if (resultCase_ == 8) {
          resultCase_ = 0;
          result_ = null;
          onChanged();
        }
      } else {
        if (resultCase_ == 8) {
          resultCase_ = 0;
          result_ = null;
        }
        sparkVersionBuilder_.clear();
      }
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.SparkVersion spark_version = 8;</code>
     */
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion.Builder getSparkVersionBuilder() {
      return getSparkVersionFieldBuilder().getBuilder();
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.SparkVersion spark_version = 8;</code>
     */
    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersionOrBuilder getSparkVersionOrBuilder() {
      if ((resultCase_ == 8) && (sparkVersionBuilder_ != null)) {
        return sparkVersionBuilder_.getMessageOrBuilder();
      } else {
        if (resultCase_ == 8) {
          return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion) result_;
        }
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion.getDefaultInstance();
      }
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.SparkVersion spark_version = 8;</code>
     */
    private com.google.protobuf.SingleFieldBuilderV3<
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion.Builder, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersionOrBuilder> 
        getSparkVersionFieldBuilder() {
      if (sparkVersionBuilder_ == null) {
        if (!(resultCase_ == 8)) {
          result_ = org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion.getDefaultInstance();
        }
        sparkVersionBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
            org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion.Builder, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersionOrBuilder>(
                (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SparkVersion) result_,
                getParentForChildren(),
                isClean());
        result_ = null;
      }
      resultCase_ = 8;
      onChanged();;
      return sparkVersionBuilder_;
    }

    private com.google.protobuf.SingleFieldBuilderV3<
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse.Builder, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParseOrBuilder> ddlParseBuilder_;
    /**
     * <code>.spark.connect.AnalyzePlanResponse.DDLParse ddl_parse = 9;</code>
     * @return Whether the ddlParse field is set.
     */
    @java.lang.Override
    public boolean hasDdlParse() {
      return resultCase_ == 9;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.DDLParse ddl_parse = 9;</code>
     * @return The ddlParse.
     */
    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse getDdlParse() {
      if (ddlParseBuilder_ == null) {
        if (resultCase_ == 9) {
          return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse) result_;
        }
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse.getDefaultInstance();
      } else {
        if (resultCase_ == 9) {
          return ddlParseBuilder_.getMessage();
        }
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse.getDefaultInstance();
      }
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.DDLParse ddl_parse = 9;</code>
     */
    public Builder setDdlParse(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse value) {
      if (ddlParseBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        result_ = value;
        onChanged();
      } else {
        ddlParseBuilder_.setMessage(value);
      }
      resultCase_ = 9;
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.DDLParse ddl_parse = 9;</code>
     */
    public Builder setDdlParse(
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse.Builder builderForValue) {
      if (ddlParseBuilder_ == null) {
        result_ = builderForValue.build();
        onChanged();
      } else {
        ddlParseBuilder_.setMessage(builderForValue.build());
      }
      resultCase_ = 9;
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.DDLParse ddl_parse = 9;</code>
     */
    public Builder mergeDdlParse(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse value) {
      if (ddlParseBuilder_ == null) {
        if (resultCase_ == 9 &&
            result_ != org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse.getDefaultInstance()) {
          result_ = org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse.newBuilder((org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse) result_)
              .mergeFrom(value).buildPartial();
        } else {
          result_ = value;
        }
        onChanged();
      } else {
        if (resultCase_ == 9) {
          ddlParseBuilder_.mergeFrom(value);
        } else {
          ddlParseBuilder_.setMessage(value);
        }
      }
      resultCase_ = 9;
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.DDLParse ddl_parse = 9;</code>
     */
    public Builder clearDdlParse() {
      if (ddlParseBuilder_ == null) {
        if (resultCase_ == 9) {
          resultCase_ = 0;
          result_ = null;
          onChanged();
        }
      } else {
        if (resultCase_ == 9) {
          resultCase_ = 0;
          result_ = null;
        }
        ddlParseBuilder_.clear();
      }
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.DDLParse ddl_parse = 9;</code>
     */
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse.Builder getDdlParseBuilder() {
      return getDdlParseFieldBuilder().getBuilder();
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.DDLParse ddl_parse = 9;</code>
     */
    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParseOrBuilder getDdlParseOrBuilder() {
      if ((resultCase_ == 9) && (ddlParseBuilder_ != null)) {
        return ddlParseBuilder_.getMessageOrBuilder();
      } else {
        if (resultCase_ == 9) {
          return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse) result_;
        }
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse.getDefaultInstance();
      }
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.DDLParse ddl_parse = 9;</code>
     */
    private com.google.protobuf.SingleFieldBuilderV3<
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse.Builder, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParseOrBuilder> 
        getDdlParseFieldBuilder() {
      if (ddlParseBuilder_ == null) {
        if (!(resultCase_ == 9)) {
          result_ = org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse.getDefaultInstance();
        }
        ddlParseBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
            org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse.Builder, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParseOrBuilder>(
                (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.DDLParse) result_,
                getParentForChildren(),
                isClean());
        result_ = null;
      }
      resultCase_ = 9;
      onChanged();;
      return ddlParseBuilder_;
    }

    private com.google.protobuf.SingleFieldBuilderV3<
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics.Builder, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemanticsOrBuilder> sameSemanticsBuilder_;
    /**
     * <code>.spark.connect.AnalyzePlanResponse.SameSemantics same_semantics = 10;</code>
     * @return Whether the sameSemantics field is set.
     */
    @java.lang.Override
    public boolean hasSameSemantics() {
      return resultCase_ == 10;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.SameSemantics same_semantics = 10;</code>
     * @return The sameSemantics.
     */
    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics getSameSemantics() {
      if (sameSemanticsBuilder_ == null) {
        if (resultCase_ == 10) {
          return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics) result_;
        }
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics.getDefaultInstance();
      } else {
        if (resultCase_ == 10) {
          return sameSemanticsBuilder_.getMessage();
        }
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics.getDefaultInstance();
      }
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.SameSemantics same_semantics = 10;</code>
     */
    public Builder setSameSemantics(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics value) {
      if (sameSemanticsBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        result_ = value;
        onChanged();
      } else {
        sameSemanticsBuilder_.setMessage(value);
      }
      resultCase_ = 10;
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.SameSemantics same_semantics = 10;</code>
     */
    public Builder setSameSemantics(
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics.Builder builderForValue) {
      if (sameSemanticsBuilder_ == null) {
        result_ = builderForValue.build();
        onChanged();
      } else {
        sameSemanticsBuilder_.setMessage(builderForValue.build());
      }
      resultCase_ = 10;
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.SameSemantics same_semantics = 10;</code>
     */
    public Builder mergeSameSemantics(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics value) {
      if (sameSemanticsBuilder_ == null) {
        if (resultCase_ == 10 &&
            result_ != org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics.getDefaultInstance()) {
          result_ = org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics.newBuilder((org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics) result_)
              .mergeFrom(value).buildPartial();
        } else {
          result_ = value;
        }
        onChanged();
      } else {
        if (resultCase_ == 10) {
          sameSemanticsBuilder_.mergeFrom(value);
        } else {
          sameSemanticsBuilder_.setMessage(value);
        }
      }
      resultCase_ = 10;
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.SameSemantics same_semantics = 10;</code>
     */
    public Builder clearSameSemantics() {
      if (sameSemanticsBuilder_ == null) {
        if (resultCase_ == 10) {
          resultCase_ = 0;
          result_ = null;
          onChanged();
        }
      } else {
        if (resultCase_ == 10) {
          resultCase_ = 0;
          result_ = null;
        }
        sameSemanticsBuilder_.clear();
      }
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.SameSemantics same_semantics = 10;</code>
     */
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics.Builder getSameSemanticsBuilder() {
      return getSameSemanticsFieldBuilder().getBuilder();
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.SameSemantics same_semantics = 10;</code>
     */
    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemanticsOrBuilder getSameSemanticsOrBuilder() {
      if ((resultCase_ == 10) && (sameSemanticsBuilder_ != null)) {
        return sameSemanticsBuilder_.getMessageOrBuilder();
      } else {
        if (resultCase_ == 10) {
          return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics) result_;
        }
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics.getDefaultInstance();
      }
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.SameSemantics same_semantics = 10;</code>
     */
    private com.google.protobuf.SingleFieldBuilderV3<
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics.Builder, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemanticsOrBuilder> 
        getSameSemanticsFieldBuilder() {
      if (sameSemanticsBuilder_ == null) {
        if (!(resultCase_ == 10)) {
          result_ = org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics.getDefaultInstance();
        }
        sameSemanticsBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
            org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics.Builder, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemanticsOrBuilder>(
                (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SameSemantics) result_,
                getParentForChildren(),
                isClean());
        result_ = null;
      }
      resultCase_ = 10;
      onChanged();;
      return sameSemanticsBuilder_;
    }

    private com.google.protobuf.SingleFieldBuilderV3<
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash.Builder, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHashOrBuilder> semanticHashBuilder_;
    /**
     * <code>.spark.connect.AnalyzePlanResponse.SemanticHash semantic_hash = 11;</code>
     * @return Whether the semanticHash field is set.
     */
    @java.lang.Override
    public boolean hasSemanticHash() {
      return resultCase_ == 11;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.SemanticHash semantic_hash = 11;</code>
     * @return The semanticHash.
     */
    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash getSemanticHash() {
      if (semanticHashBuilder_ == null) {
        if (resultCase_ == 11) {
          return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash) result_;
        }
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash.getDefaultInstance();
      } else {
        if (resultCase_ == 11) {
          return semanticHashBuilder_.getMessage();
        }
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash.getDefaultInstance();
      }
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.SemanticHash semantic_hash = 11;</code>
     */
    public Builder setSemanticHash(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash value) {
      if (semanticHashBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        result_ = value;
        onChanged();
      } else {
        semanticHashBuilder_.setMessage(value);
      }
      resultCase_ = 11;
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.SemanticHash semantic_hash = 11;</code>
     */
    public Builder setSemanticHash(
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash.Builder builderForValue) {
      if (semanticHashBuilder_ == null) {
        result_ = builderForValue.build();
        onChanged();
      } else {
        semanticHashBuilder_.setMessage(builderForValue.build());
      }
      resultCase_ = 11;
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.SemanticHash semantic_hash = 11;</code>
     */
    public Builder mergeSemanticHash(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash value) {
      if (semanticHashBuilder_ == null) {
        if (resultCase_ == 11 &&
            result_ != org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash.getDefaultInstance()) {
          result_ = org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash.newBuilder((org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash) result_)
              .mergeFrom(value).buildPartial();
        } else {
          result_ = value;
        }
        onChanged();
      } else {
        if (resultCase_ == 11) {
          semanticHashBuilder_.mergeFrom(value);
        } else {
          semanticHashBuilder_.setMessage(value);
        }
      }
      resultCase_ = 11;
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.SemanticHash semantic_hash = 11;</code>
     */
    public Builder clearSemanticHash() {
      if (semanticHashBuilder_ == null) {
        if (resultCase_ == 11) {
          resultCase_ = 0;
          result_ = null;
          onChanged();
        }
      } else {
        if (resultCase_ == 11) {
          resultCase_ = 0;
          result_ = null;
        }
        semanticHashBuilder_.clear();
      }
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.SemanticHash semantic_hash = 11;</code>
     */
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash.Builder getSemanticHashBuilder() {
      return getSemanticHashFieldBuilder().getBuilder();
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.SemanticHash semantic_hash = 11;</code>
     */
    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHashOrBuilder getSemanticHashOrBuilder() {
      if ((resultCase_ == 11) && (semanticHashBuilder_ != null)) {
        return semanticHashBuilder_.getMessageOrBuilder();
      } else {
        if (resultCase_ == 11) {
          return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash) result_;
        }
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash.getDefaultInstance();
      }
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.SemanticHash semantic_hash = 11;</code>
     */
    private com.google.protobuf.SingleFieldBuilderV3<
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash.Builder, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHashOrBuilder> 
        getSemanticHashFieldBuilder() {
      if (semanticHashBuilder_ == null) {
        if (!(resultCase_ == 11)) {
          result_ = org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash.getDefaultInstance();
        }
        semanticHashBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
            org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash.Builder, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHashOrBuilder>(
                (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.SemanticHash) result_,
                getParentForChildren(),
                isClean());
        result_ = null;
      }
      resultCase_ = 11;
      onChanged();;
      return semanticHashBuilder_;
    }

    private com.google.protobuf.SingleFieldBuilderV3<
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist.Builder, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.PersistOrBuilder> persistBuilder_;
    /**
     * <code>.spark.connect.AnalyzePlanResponse.Persist persist = 12;</code>
     * @return Whether the persist field is set.
     */
    @java.lang.Override
    public boolean hasPersist() {
      return resultCase_ == 12;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.Persist persist = 12;</code>
     * @return The persist.
     */
    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist getPersist() {
      if (persistBuilder_ == null) {
        if (resultCase_ == 12) {
          return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist) result_;
        }
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist.getDefaultInstance();
      } else {
        if (resultCase_ == 12) {
          return persistBuilder_.getMessage();
        }
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist.getDefaultInstance();
      }
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.Persist persist = 12;</code>
     */
    public Builder setPersist(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist value) {
      if (persistBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        result_ = value;
        onChanged();
      } else {
        persistBuilder_.setMessage(value);
      }
      resultCase_ = 12;
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.Persist persist = 12;</code>
     */
    public Builder setPersist(
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist.Builder builderForValue) {
      if (persistBuilder_ == null) {
        result_ = builderForValue.build();
        onChanged();
      } else {
        persistBuilder_.setMessage(builderForValue.build());
      }
      resultCase_ = 12;
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.Persist persist = 12;</code>
     */
    public Builder mergePersist(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist value) {
      if (persistBuilder_ == null) {
        if (resultCase_ == 12 &&
            result_ != org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist.getDefaultInstance()) {
          result_ = org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist.newBuilder((org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist) result_)
              .mergeFrom(value).buildPartial();
        } else {
          result_ = value;
        }
        onChanged();
      } else {
        if (resultCase_ == 12) {
          persistBuilder_.mergeFrom(value);
        } else {
          persistBuilder_.setMessage(value);
        }
      }
      resultCase_ = 12;
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.Persist persist = 12;</code>
     */
    public Builder clearPersist() {
      if (persistBuilder_ == null) {
        if (resultCase_ == 12) {
          resultCase_ = 0;
          result_ = null;
          onChanged();
        }
      } else {
        if (resultCase_ == 12) {
          resultCase_ = 0;
          result_ = null;
        }
        persistBuilder_.clear();
      }
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.Persist persist = 12;</code>
     */
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist.Builder getPersistBuilder() {
      return getPersistFieldBuilder().getBuilder();
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.Persist persist = 12;</code>
     */
    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.PersistOrBuilder getPersistOrBuilder() {
      if ((resultCase_ == 12) && (persistBuilder_ != null)) {
        return persistBuilder_.getMessageOrBuilder();
      } else {
        if (resultCase_ == 12) {
          return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist) result_;
        }
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist.getDefaultInstance();
      }
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.Persist persist = 12;</code>
     */
    private com.google.protobuf.SingleFieldBuilderV3<
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist.Builder, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.PersistOrBuilder> 
        getPersistFieldBuilder() {
      if (persistBuilder_ == null) {
        if (!(resultCase_ == 12)) {
          result_ = org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist.getDefaultInstance();
        }
        persistBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
            org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist.Builder, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.PersistOrBuilder>(
                (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Persist) result_,
                getParentForChildren(),
                isClean());
        result_ = null;
      }
      resultCase_ = 12;
      onChanged();;
      return persistBuilder_;
    }

    private com.google.protobuf.SingleFieldBuilderV3<
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist.Builder, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.UnpersistOrBuilder> unpersistBuilder_;
    /**
     * <code>.spark.connect.AnalyzePlanResponse.Unpersist unpersist = 13;</code>
     * @return Whether the unpersist field is set.
     */
    @java.lang.Override
    public boolean hasUnpersist() {
      return resultCase_ == 13;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.Unpersist unpersist = 13;</code>
     * @return The unpersist.
     */
    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist getUnpersist() {
      if (unpersistBuilder_ == null) {
        if (resultCase_ == 13) {
          return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist) result_;
        }
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist.getDefaultInstance();
      } else {
        if (resultCase_ == 13) {
          return unpersistBuilder_.getMessage();
        }
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist.getDefaultInstance();
      }
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.Unpersist unpersist = 13;</code>
     */
    public Builder setUnpersist(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist value) {
      if (unpersistBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        result_ = value;
        onChanged();
      } else {
        unpersistBuilder_.setMessage(value);
      }
      resultCase_ = 13;
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.Unpersist unpersist = 13;</code>
     */
    public Builder setUnpersist(
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist.Builder builderForValue) {
      if (unpersistBuilder_ == null) {
        result_ = builderForValue.build();
        onChanged();
      } else {
        unpersistBuilder_.setMessage(builderForValue.build());
      }
      resultCase_ = 13;
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.Unpersist unpersist = 13;</code>
     */
    public Builder mergeUnpersist(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist value) {
      if (unpersistBuilder_ == null) {
        if (resultCase_ == 13 &&
            result_ != org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist.getDefaultInstance()) {
          result_ = org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist.newBuilder((org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist) result_)
              .mergeFrom(value).buildPartial();
        } else {
          result_ = value;
        }
        onChanged();
      } else {
        if (resultCase_ == 13) {
          unpersistBuilder_.mergeFrom(value);
        } else {
          unpersistBuilder_.setMessage(value);
        }
      }
      resultCase_ = 13;
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.Unpersist unpersist = 13;</code>
     */
    public Builder clearUnpersist() {
      if (unpersistBuilder_ == null) {
        if (resultCase_ == 13) {
          resultCase_ = 0;
          result_ = null;
          onChanged();
        }
      } else {
        if (resultCase_ == 13) {
          resultCase_ = 0;
          result_ = null;
        }
        unpersistBuilder_.clear();
      }
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.Unpersist unpersist = 13;</code>
     */
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist.Builder getUnpersistBuilder() {
      return getUnpersistFieldBuilder().getBuilder();
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.Unpersist unpersist = 13;</code>
     */
    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.UnpersistOrBuilder getUnpersistOrBuilder() {
      if ((resultCase_ == 13) && (unpersistBuilder_ != null)) {
        return unpersistBuilder_.getMessageOrBuilder();
      } else {
        if (resultCase_ == 13) {
          return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist) result_;
        }
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist.getDefaultInstance();
      }
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.Unpersist unpersist = 13;</code>
     */
    private com.google.protobuf.SingleFieldBuilderV3<
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist.Builder, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.UnpersistOrBuilder> 
        getUnpersistFieldBuilder() {
      if (unpersistBuilder_ == null) {
        if (!(resultCase_ == 13)) {
          result_ = org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist.getDefaultInstance();
        }
        unpersistBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
            org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist.Builder, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.UnpersistOrBuilder>(
                (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.Unpersist) result_,
                getParentForChildren(),
                isClean());
        result_ = null;
      }
      resultCase_ = 13;
      onChanged();;
      return unpersistBuilder_;
    }

    private com.google.protobuf.SingleFieldBuilderV3<
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel.Builder, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevelOrBuilder> getStorageLevelBuilder_;
    /**
     * <code>.spark.connect.AnalyzePlanResponse.GetStorageLevel get_storage_level = 14;</code>
     * @return Whether the getStorageLevel field is set.
     */
    @java.lang.Override
    public boolean hasGetStorageLevel() {
      return resultCase_ == 14;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.GetStorageLevel get_storage_level = 14;</code>
     * @return The getStorageLevel.
     */
    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel getGetStorageLevel() {
      if (getStorageLevelBuilder_ == null) {
        if (resultCase_ == 14) {
          return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel) result_;
        }
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel.getDefaultInstance();
      } else {
        if (resultCase_ == 14) {
          return getStorageLevelBuilder_.getMessage();
        }
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel.getDefaultInstance();
      }
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.GetStorageLevel get_storage_level = 14;</code>
     */
    public Builder setGetStorageLevel(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel value) {
      if (getStorageLevelBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        result_ = value;
        onChanged();
      } else {
        getStorageLevelBuilder_.setMessage(value);
      }
      resultCase_ = 14;
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.GetStorageLevel get_storage_level = 14;</code>
     */
    public Builder setGetStorageLevel(
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel.Builder builderForValue) {
      if (getStorageLevelBuilder_ == null) {
        result_ = builderForValue.build();
        onChanged();
      } else {
        getStorageLevelBuilder_.setMessage(builderForValue.build());
      }
      resultCase_ = 14;
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.GetStorageLevel get_storage_level = 14;</code>
     */
    public Builder mergeGetStorageLevel(org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel value) {
      if (getStorageLevelBuilder_ == null) {
        if (resultCase_ == 14 &&
            result_ != org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel.getDefaultInstance()) {
          result_ = org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel.newBuilder((org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel) result_)
              .mergeFrom(value).buildPartial();
        } else {
          result_ = value;
        }
        onChanged();
      } else {
        if (resultCase_ == 14) {
          getStorageLevelBuilder_.mergeFrom(value);
        } else {
          getStorageLevelBuilder_.setMessage(value);
        }
      }
      resultCase_ = 14;
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.GetStorageLevel get_storage_level = 14;</code>
     */
    public Builder clearGetStorageLevel() {
      if (getStorageLevelBuilder_ == null) {
        if (resultCase_ == 14) {
          resultCase_ = 0;
          result_ = null;
          onChanged();
        }
      } else {
        if (resultCase_ == 14) {
          resultCase_ = 0;
          result_ = null;
        }
        getStorageLevelBuilder_.clear();
      }
      return this;
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.GetStorageLevel get_storage_level = 14;</code>
     */
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel.Builder getGetStorageLevelBuilder() {
      return getGetStorageLevelFieldBuilder().getBuilder();
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.GetStorageLevel get_storage_level = 14;</code>
     */
    @java.lang.Override
    public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevelOrBuilder getGetStorageLevelOrBuilder() {
      if ((resultCase_ == 14) && (getStorageLevelBuilder_ != null)) {
        return getStorageLevelBuilder_.getMessageOrBuilder();
      } else {
        if (resultCase_ == 14) {
          return (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel) result_;
        }
        return org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel.getDefaultInstance();
      }
    }
    /**
     * <code>.spark.connect.AnalyzePlanResponse.GetStorageLevel get_storage_level = 14;</code>
     */
    private com.google.protobuf.SingleFieldBuilderV3<
        org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel.Builder, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevelOrBuilder> 
        getGetStorageLevelFieldBuilder() {
      if (getStorageLevelBuilder_ == null) {
        if (!(resultCase_ == 14)) {
          result_ = org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel.getDefaultInstance();
        }
        getStorageLevelBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
            org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel.Builder, org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevelOrBuilder>(
                (org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse.GetStorageLevel) result_,
                getParentForChildren(),
                isClean());
        result_ = null;
      }
      resultCase_ = 14;
      onChanged();;
      return getStorageLevelBuilder_;
    }
    @java.lang.Override
    public final Builder setUnknownFields(
        final com.google.protobuf.UnknownFieldSet unknownFields) {
      return super.setUnknownFields(unknownFields);
    }

    @java.lang.Override
    public final Builder mergeUnknownFields(
        final com.google.protobuf.UnknownFieldSet unknownFields) {
      return super.mergeUnknownFields(unknownFields);
    }


    // @@protoc_insertion_point(builder_scope:spark.connect.AnalyzePlanResponse)
  }

  // @@protoc_insertion_point(class_scope:spark.connect.AnalyzePlanResponse)
  private static final org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse DEFAULT_INSTANCE;
  static {
    DEFAULT_INSTANCE = new org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse();
  }

  public static org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse getDefaultInstance() {
    return DEFAULT_INSTANCE;
  }

  private static final com.google.protobuf.Parser<AnalyzePlanResponse>
      PARSER = new com.google.protobuf.AbstractParser<AnalyzePlanResponse>() {
    @java.lang.Override
    public AnalyzePlanResponse parsePartialFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      Builder builder = newBuilder();
      try {
        builder.mergeFrom(input, extensionRegistry);
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(builder.buildPartial());
      } catch (com.google.protobuf.UninitializedMessageException e) {
        throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(e)
            .setUnfinishedMessage(builder.buildPartial());
      }
      return builder.buildPartial();
    }
  };

  public static com.google.protobuf.Parser<AnalyzePlanResponse> parser() {
    return PARSER;
  }

  @java.lang.Override
  public com.google.protobuf.Parser<AnalyzePlanResponse> getParserForType() {
    return PARSER;
  }

  @java.lang.Override
  public org.apache.kyuubi.engine.spark.connect.proto.AnalyzePlanResponse getDefaultInstanceForType() {
    return DEFAULT_INSTANCE;
  }

}

