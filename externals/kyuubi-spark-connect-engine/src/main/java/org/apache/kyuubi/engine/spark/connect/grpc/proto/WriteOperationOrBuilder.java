// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: kyuubi/spark/connect/commands.proto

package org.apache.kyuubi.engine.spark.connect.grpc.proto;

public interface WriteOperationOrBuilder
    extends
    // @@protoc_insertion_point(interface_extends:spark.connect.WriteOperation)
    com.google.protobuf.MessageOrBuilder {

  /**
   *
   *
   * <pre>
   * (Required) The output of the `input` relation will be persisted according to the options.
   * </pre>
   *
   * <code>.spark.connect.Relation input = 1;</code>
   *
   * @return Whether the input field is set.
   */
  boolean hasInput();
  /**
   *
   *
   * <pre>
   * (Required) The output of the `input` relation will be persisted according to the options.
   * </pre>
   *
   * <code>.spark.connect.Relation input = 1;</code>
   *
   * @return The input.
   */
  org.apache.kyuubi.engine.spark.connect.grpc.proto.Relation getInput();
  /**
   *
   *
   * <pre>
   * (Required) The output of the `input` relation will be persisted according to the options.
   * </pre>
   *
   * <code>.spark.connect.Relation input = 1;</code>
   */
  org.apache.kyuubi.engine.spark.connect.grpc.proto.RelationOrBuilder getInputOrBuilder();

  /**
   *
   *
   * <pre>
   * (Optional) Format value according to the Spark documentation. Examples are: text, parquet, delta.
   * </pre>
   *
   * <code>optional string source = 2;</code>
   *
   * @return Whether the source field is set.
   */
  boolean hasSource();
  /**
   *
   *
   * <pre>
   * (Optional) Format value according to the Spark documentation. Examples are: text, parquet, delta.
   * </pre>
   *
   * <code>optional string source = 2;</code>
   *
   * @return The source.
   */
  java.lang.String getSource();
  /**
   *
   *
   * <pre>
   * (Optional) Format value according to the Spark documentation. Examples are: text, parquet, delta.
   * </pre>
   *
   * <code>optional string source = 2;</code>
   *
   * @return The bytes for source.
   */
  com.google.protobuf.ByteString getSourceBytes();

  /**
   * <code>string path = 3;</code>
   *
   * @return Whether the path field is set.
   */
  boolean hasPath();
  /**
   * <code>string path = 3;</code>
   *
   * @return The path.
   */
  java.lang.String getPath();
  /**
   * <code>string path = 3;</code>
   *
   * @return The bytes for path.
   */
  com.google.protobuf.ByteString getPathBytes();

  /**
   * <code>.spark.connect.WriteOperation.SaveTable table = 4;</code>
   *
   * @return Whether the table field is set.
   */
  boolean hasTable();
  /**
   * <code>.spark.connect.WriteOperation.SaveTable table = 4;</code>
   *
   * @return The table.
   */
  org.apache.kyuubi.engine.spark.connect.grpc.proto.WriteOperation.SaveTable getTable();
  /** <code>.spark.connect.WriteOperation.SaveTable table = 4;</code> */
  org.apache.kyuubi.engine.spark.connect.grpc.proto.WriteOperation.SaveTableOrBuilder
      getTableOrBuilder();

  /**
   *
   *
   * <pre>
   * (Required) the save mode.
   * </pre>
   *
   * <code>.spark.connect.WriteOperation.SaveMode mode = 5;</code>
   *
   * @return The enum numeric value on the wire for mode.
   */
  int getModeValue();
  /**
   *
   *
   * <pre>
   * (Required) the save mode.
   * </pre>
   *
   * <code>.spark.connect.WriteOperation.SaveMode mode = 5;</code>
   *
   * @return The mode.
   */
  org.apache.kyuubi.engine.spark.connect.grpc.proto.WriteOperation.SaveMode getMode();

  /**
   *
   *
   * <pre>
   * (Optional) List of columns to sort the output by.
   * </pre>
   *
   * <code>repeated string sort_column_names = 6;</code>
   *
   * @return A list containing the sortColumnNames.
   */
  java.util.List<java.lang.String> getSortColumnNamesList();
  /**
   *
   *
   * <pre>
   * (Optional) List of columns to sort the output by.
   * </pre>
   *
   * <code>repeated string sort_column_names = 6;</code>
   *
   * @return The count of sortColumnNames.
   */
  int getSortColumnNamesCount();
  /**
   *
   *
   * <pre>
   * (Optional) List of columns to sort the output by.
   * </pre>
   *
   * <code>repeated string sort_column_names = 6;</code>
   *
   * @param index The index of the element to return.
   * @return The sortColumnNames at the given index.
   */
  java.lang.String getSortColumnNames(int index);
  /**
   *
   *
   * <pre>
   * (Optional) List of columns to sort the output by.
   * </pre>
   *
   * <code>repeated string sort_column_names = 6;</code>
   *
   * @param index The index of the value to return.
   * @return The bytes of the sortColumnNames at the given index.
   */
  com.google.protobuf.ByteString getSortColumnNamesBytes(int index);

  /**
   *
   *
   * <pre>
   * (Optional) List of columns for partitioning.
   * </pre>
   *
   * <code>repeated string partitioning_columns = 7;</code>
   *
   * @return A list containing the partitioningColumns.
   */
  java.util.List<java.lang.String> getPartitioningColumnsList();
  /**
   *
   *
   * <pre>
   * (Optional) List of columns for partitioning.
   * </pre>
   *
   * <code>repeated string partitioning_columns = 7;</code>
   *
   * @return The count of partitioningColumns.
   */
  int getPartitioningColumnsCount();
  /**
   *
   *
   * <pre>
   * (Optional) List of columns for partitioning.
   * </pre>
   *
   * <code>repeated string partitioning_columns = 7;</code>
   *
   * @param index The index of the element to return.
   * @return The partitioningColumns at the given index.
   */
  java.lang.String getPartitioningColumns(int index);
  /**
   *
   *
   * <pre>
   * (Optional) List of columns for partitioning.
   * </pre>
   *
   * <code>repeated string partitioning_columns = 7;</code>
   *
   * @param index The index of the value to return.
   * @return The bytes of the partitioningColumns at the given index.
   */
  com.google.protobuf.ByteString getPartitioningColumnsBytes(int index);

  /**
   *
   *
   * <pre>
   * (Optional) Bucketing specification. Bucketing must set the number of buckets and the columns
   * to bucket by.
   * </pre>
   *
   * <code>.spark.connect.WriteOperation.BucketBy bucket_by = 8;</code>
   *
   * @return Whether the bucketBy field is set.
   */
  boolean hasBucketBy();
  /**
   *
   *
   * <pre>
   * (Optional) Bucketing specification. Bucketing must set the number of buckets and the columns
   * to bucket by.
   * </pre>
   *
   * <code>.spark.connect.WriteOperation.BucketBy bucket_by = 8;</code>
   *
   * @return The bucketBy.
   */
  org.apache.kyuubi.engine.spark.connect.grpc.proto.WriteOperation.BucketBy getBucketBy();
  /**
   *
   *
   * <pre>
   * (Optional) Bucketing specification. Bucketing must set the number of buckets and the columns
   * to bucket by.
   * </pre>
   *
   * <code>.spark.connect.WriteOperation.BucketBy bucket_by = 8;</code>
   */
  org.apache.kyuubi.engine.spark.connect.grpc.proto.WriteOperation.BucketByOrBuilder
      getBucketByOrBuilder();

  /**
   *
   *
   * <pre>
   * (Optional) A list of configuration options.
   * </pre>
   *
   * <code>map&lt;string, string&gt; options = 9;</code>
   */
  int getOptionsCount();
  /**
   *
   *
   * <pre>
   * (Optional) A list of configuration options.
   * </pre>
   *
   * <code>map&lt;string, string&gt; options = 9;</code>
   */
  boolean containsOptions(java.lang.String key);
  /** Use {@link #getOptionsMap()} instead. */
  @java.lang.Deprecated
  java.util.Map<java.lang.String, java.lang.String> getOptions();
  /**
   *
   *
   * <pre>
   * (Optional) A list of configuration options.
   * </pre>
   *
   * <code>map&lt;string, string&gt; options = 9;</code>
   */
  java.util.Map<java.lang.String, java.lang.String> getOptionsMap();
  /**
   *
   *
   * <pre>
   * (Optional) A list of configuration options.
   * </pre>
   *
   * <code>map&lt;string, string&gt; options = 9;</code>
   */

  /* nullable */
  java.lang.String getOptionsOrDefault(
      java.lang.String key,
      /* nullable */
      java.lang.String defaultValue);
  /**
   *
   *
   * <pre>
   * (Optional) A list of configuration options.
   * </pre>
   *
   * <code>map&lt;string, string&gt; options = 9;</code>
   */
  java.lang.String getOptionsOrThrow(java.lang.String key);

  /**
   *
   *
   * <pre>
   * (Optional) Columns used for clustering the table.
   * </pre>
   *
   * <code>repeated string clustering_columns = 10;</code>
   *
   * @return A list containing the clusteringColumns.
   */
  java.util.List<java.lang.String> getClusteringColumnsList();
  /**
   *
   *
   * <pre>
   * (Optional) Columns used for clustering the table.
   * </pre>
   *
   * <code>repeated string clustering_columns = 10;</code>
   *
   * @return The count of clusteringColumns.
   */
  int getClusteringColumnsCount();
  /**
   *
   *
   * <pre>
   * (Optional) Columns used for clustering the table.
   * </pre>
   *
   * <code>repeated string clustering_columns = 10;</code>
   *
   * @param index The index of the element to return.
   * @return The clusteringColumns at the given index.
   */
  java.lang.String getClusteringColumns(int index);
  /**
   *
   *
   * <pre>
   * (Optional) Columns used for clustering the table.
   * </pre>
   *
   * <code>repeated string clustering_columns = 10;</code>
   *
   * @param index The index of the value to return.
   * @return The bytes of the clusteringColumns at the given index.
   */
  com.google.protobuf.ByteString getClusteringColumnsBytes(int index);

  public org.apache.kyuubi.engine.spark.connect.grpc.proto.WriteOperation.SaveTypeCase
      getSaveTypeCase();
}
