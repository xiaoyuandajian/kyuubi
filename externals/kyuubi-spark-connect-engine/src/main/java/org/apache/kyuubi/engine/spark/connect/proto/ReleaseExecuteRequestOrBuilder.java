// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: spark/connect/base.proto

package org.apache.kyuubi.engine.spark.connect.proto;

public interface ReleaseExecuteRequestOrBuilder extends
    // @@protoc_insertion_point(interface_extends:spark.connect.ReleaseExecuteRequest)
    com.google.protobuf.MessageOrBuilder {

  /**
   * <pre>
   * (Required)
   * The session_id of the request to reattach to.
   * This must be an id of existing session.
   * </pre>
   *
   * <code>string session_id = 1;</code>
   * @return The sessionId.
   */
  java.lang.String getSessionId();
  /**
   * <pre>
   * (Required)
   * The session_id of the request to reattach to.
   * This must be an id of existing session.
   * </pre>
   *
   * <code>string session_id = 1;</code>
   * @return The bytes for sessionId.
   */
  com.google.protobuf.ByteString
      getSessionIdBytes();

  /**
   * <pre>
   * (Required) User context
   * user_context.user_id and session+id both identify a unique remote spark session on the
   * server side.
   * </pre>
   *
   * <code>.spark.connect.UserContext user_context = 2;</code>
   * @return Whether the userContext field is set.
   */
  boolean hasUserContext();
  /**
   * <pre>
   * (Required) User context
   * user_context.user_id and session+id both identify a unique remote spark session on the
   * server side.
   * </pre>
   *
   * <code>.spark.connect.UserContext user_context = 2;</code>
   * @return The userContext.
   */
  org.apache.kyuubi.engine.spark.connect.proto.UserContext getUserContext();
  /**
   * <pre>
   * (Required) User context
   * user_context.user_id and session+id both identify a unique remote spark session on the
   * server side.
   * </pre>
   *
   * <code>.spark.connect.UserContext user_context = 2;</code>
   */
  org.apache.kyuubi.engine.spark.connect.proto.UserContextOrBuilder getUserContextOrBuilder();

  /**
   * <pre>
   * (Required)
   * Provide an id of the request to reattach to.
   * This must be an id of existing operation.
   * </pre>
   *
   * <code>string operation_id = 3;</code>
   * @return The operationId.
   */
  java.lang.String getOperationId();
  /**
   * <pre>
   * (Required)
   * Provide an id of the request to reattach to.
   * This must be an id of existing operation.
   * </pre>
   *
   * <code>string operation_id = 3;</code>
   * @return The bytes for operationId.
   */
  com.google.protobuf.ByteString
      getOperationIdBytes();

  /**
   * <pre>
   * Provides optional information about the client sending the request. This field
   * can be used for language or version specific information and is only intended for
   * logging purposes and will not be interpreted by the server.
   * </pre>
   *
   * <code>optional string client_type = 4;</code>
   * @return Whether the clientType field is set.
   */
  boolean hasClientType();
  /**
   * <pre>
   * Provides optional information about the client sending the request. This field
   * can be used for language or version specific information and is only intended for
   * logging purposes and will not be interpreted by the server.
   * </pre>
   *
   * <code>optional string client_type = 4;</code>
   * @return The clientType.
   */
  java.lang.String getClientType();
  /**
   * <pre>
   * Provides optional information about the client sending the request. This field
   * can be used for language or version specific information and is only intended for
   * logging purposes and will not be interpreted by the server.
   * </pre>
   *
   * <code>optional string client_type = 4;</code>
   * @return The bytes for clientType.
   */
  com.google.protobuf.ByteString
      getClientTypeBytes();

  /**
   * <code>.spark.connect.ReleaseExecuteRequest.ReleaseAll release_all = 5;</code>
   * @return Whether the releaseAll field is set.
   */
  boolean hasReleaseAll();
  /**
   * <code>.spark.connect.ReleaseExecuteRequest.ReleaseAll release_all = 5;</code>
   * @return The releaseAll.
   */
  org.apache.kyuubi.engine.spark.connect.proto.ReleaseExecuteRequest.ReleaseAll getReleaseAll();
  /**
   * <code>.spark.connect.ReleaseExecuteRequest.ReleaseAll release_all = 5;</code>
   */
  org.apache.kyuubi.engine.spark.connect.proto.ReleaseExecuteRequest.ReleaseAllOrBuilder getReleaseAllOrBuilder();

  /**
   * <code>.spark.connect.ReleaseExecuteRequest.ReleaseUntil release_until = 6;</code>
   * @return Whether the releaseUntil field is set.
   */
  boolean hasReleaseUntil();
  /**
   * <code>.spark.connect.ReleaseExecuteRequest.ReleaseUntil release_until = 6;</code>
   * @return The releaseUntil.
   */
  org.apache.kyuubi.engine.spark.connect.proto.ReleaseExecuteRequest.ReleaseUntil getReleaseUntil();
  /**
   * <code>.spark.connect.ReleaseExecuteRequest.ReleaseUntil release_until = 6;</code>
   */
  org.apache.kyuubi.engine.spark.connect.proto.ReleaseExecuteRequest.ReleaseUntilOrBuilder getReleaseUntilOrBuilder();

  public org.apache.kyuubi.engine.spark.connect.proto.ReleaseExecuteRequest.ReleaseCase getReleaseCase();
}
