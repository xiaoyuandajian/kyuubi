// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: spark/connect/commands.proto

package org.apache.kyuubi.engine.spark.connect.proto;

public interface WriteStreamOperationStartOrBuilder extends
    // @@protoc_insertion_point(interface_extends:spark.connect.WriteStreamOperationStart)
    com.google.protobuf.MessageOrBuilder {

  /**
   * <pre>
   * (Required) The output of the `input` streaming relation will be written.
   * </pre>
   *
   * <code>.spark.connect.Relation input = 1;</code>
   * @return Whether the input field is set.
   */
  boolean hasInput();
  /**
   * <pre>
   * (Required) The output of the `input` streaming relation will be written.
   * </pre>
   *
   * <code>.spark.connect.Relation input = 1;</code>
   * @return The input.
   */
  org.apache.kyuubi.engine.spark.connect.proto.Relation getInput();
  /**
   * <pre>
   * (Required) The output of the `input` streaming relation will be written.
   * </pre>
   *
   * <code>.spark.connect.Relation input = 1;</code>
   */
  org.apache.kyuubi.engine.spark.connect.proto.RelationOrBuilder getInputOrBuilder();

  /**
   * <code>string format = 2;</code>
   * @return The format.
   */
  java.lang.String getFormat();
  /**
   * <code>string format = 2;</code>
   * @return The bytes for format.
   */
  com.google.protobuf.ByteString
      getFormatBytes();

  /**
   * <code>map&lt;string, string&gt; options = 3;</code>
   */
  int getOptionsCount();
  /**
   * <code>map&lt;string, string&gt; options = 3;</code>
   */
  boolean containsOptions(
      java.lang.String key);
  /**
   * Use {@link #getOptionsMap()} instead.
   */
  @java.lang.Deprecated
  java.util.Map<java.lang.String, java.lang.String>
  getOptions();
  /**
   * <code>map&lt;string, string&gt; options = 3;</code>
   */
  java.util.Map<java.lang.String, java.lang.String>
  getOptionsMap();
  /**
   * <code>map&lt;string, string&gt; options = 3;</code>
   */

  /* nullable */
java.lang.String getOptionsOrDefault(
      java.lang.String key,
      /* nullable */
java.lang.String defaultValue);
  /**
   * <code>map&lt;string, string&gt; options = 3;</code>
   */

  java.lang.String getOptionsOrThrow(
      java.lang.String key);

  /**
   * <code>repeated string partitioning_column_names = 4;</code>
   * @return A list containing the partitioningColumnNames.
   */
  java.util.List<java.lang.String>
      getPartitioningColumnNamesList();
  /**
   * <code>repeated string partitioning_column_names = 4;</code>
   * @return The count of partitioningColumnNames.
   */
  int getPartitioningColumnNamesCount();
  /**
   * <code>repeated string partitioning_column_names = 4;</code>
   * @param index The index of the element to return.
   * @return The partitioningColumnNames at the given index.
   */
  java.lang.String getPartitioningColumnNames(int index);
  /**
   * <code>repeated string partitioning_column_names = 4;</code>
   * @param index The index of the value to return.
   * @return The bytes of the partitioningColumnNames at the given index.
   */
  com.google.protobuf.ByteString
      getPartitioningColumnNamesBytes(int index);

  /**
   * <code>string processing_time_interval = 5;</code>
   * @return Whether the processingTimeInterval field is set.
   */
  boolean hasProcessingTimeInterval();
  /**
   * <code>string processing_time_interval = 5;</code>
   * @return The processingTimeInterval.
   */
  java.lang.String getProcessingTimeInterval();
  /**
   * <code>string processing_time_interval = 5;</code>
   * @return The bytes for processingTimeInterval.
   */
  com.google.protobuf.ByteString
      getProcessingTimeIntervalBytes();

  /**
   * <code>bool available_now = 6;</code>
   * @return Whether the availableNow field is set.
   */
  boolean hasAvailableNow();
  /**
   * <code>bool available_now = 6;</code>
   * @return The availableNow.
   */
  boolean getAvailableNow();

  /**
   * <code>bool once = 7;</code>
   * @return Whether the once field is set.
   */
  boolean hasOnce();
  /**
   * <code>bool once = 7;</code>
   * @return The once.
   */
  boolean getOnce();

  /**
   * <code>string continuous_checkpoint_interval = 8;</code>
   * @return Whether the continuousCheckpointInterval field is set.
   */
  boolean hasContinuousCheckpointInterval();
  /**
   * <code>string continuous_checkpoint_interval = 8;</code>
   * @return The continuousCheckpointInterval.
   */
  java.lang.String getContinuousCheckpointInterval();
  /**
   * <code>string continuous_checkpoint_interval = 8;</code>
   * @return The bytes for continuousCheckpointInterval.
   */
  com.google.protobuf.ByteString
      getContinuousCheckpointIntervalBytes();

  /**
   * <code>string output_mode = 9;</code>
   * @return The outputMode.
   */
  java.lang.String getOutputMode();
  /**
   * <code>string output_mode = 9;</code>
   * @return The bytes for outputMode.
   */
  com.google.protobuf.ByteString
      getOutputModeBytes();

  /**
   * <code>string query_name = 10;</code>
   * @return The queryName.
   */
  java.lang.String getQueryName();
  /**
   * <code>string query_name = 10;</code>
   * @return The bytes for queryName.
   */
  com.google.protobuf.ByteString
      getQueryNameBytes();

  /**
   * <code>string path = 11;</code>
   * @return Whether the path field is set.
   */
  boolean hasPath();
  /**
   * <code>string path = 11;</code>
   * @return The path.
   */
  java.lang.String getPath();
  /**
   * <code>string path = 11;</code>
   * @return The bytes for path.
   */
  com.google.protobuf.ByteString
      getPathBytes();

  /**
   * <code>string table_name = 12;</code>
   * @return Whether the tableName field is set.
   */
  boolean hasTableName();
  /**
   * <code>string table_name = 12;</code>
   * @return The tableName.
   */
  java.lang.String getTableName();
  /**
   * <code>string table_name = 12;</code>
   * @return The bytes for tableName.
   */
  com.google.protobuf.ByteString
      getTableNameBytes();

  /**
   * <code>.spark.connect.StreamingForeachFunction foreach_writer = 13;</code>
   * @return Whether the foreachWriter field is set.
   */
  boolean hasForeachWriter();
  /**
   * <code>.spark.connect.StreamingForeachFunction foreach_writer = 13;</code>
   * @return The foreachWriter.
   */
  org.apache.kyuubi.engine.spark.connect.proto.StreamingForeachFunction getForeachWriter();
  /**
   * <code>.spark.connect.StreamingForeachFunction foreach_writer = 13;</code>
   */
  org.apache.kyuubi.engine.spark.connect.proto.StreamingForeachFunctionOrBuilder getForeachWriterOrBuilder();

  /**
   * <code>.spark.connect.StreamingForeachFunction foreach_batch = 14;</code>
   * @return Whether the foreachBatch field is set.
   */
  boolean hasForeachBatch();
  /**
   * <code>.spark.connect.StreamingForeachFunction foreach_batch = 14;</code>
   * @return The foreachBatch.
   */
  org.apache.kyuubi.engine.spark.connect.proto.StreamingForeachFunction getForeachBatch();
  /**
   * <code>.spark.connect.StreamingForeachFunction foreach_batch = 14;</code>
   */
  org.apache.kyuubi.engine.spark.connect.proto.StreamingForeachFunctionOrBuilder getForeachBatchOrBuilder();

  public org.apache.kyuubi.engine.spark.connect.proto.WriteStreamOperationStart.TriggerCase getTriggerCase();

  public org.apache.kyuubi.engine.spark.connect.proto.WriteStreamOperationStart.SinkDestinationCase getSinkDestinationCase();
}
